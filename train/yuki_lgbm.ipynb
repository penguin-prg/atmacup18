{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    N_FOLD = 5\n",
    "    RANDOM_SATE = 42\n",
    "\n",
    "\n",
    "NB = \"exp1015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/kaggle\")\n",
    "DATA_DIR = ROOT_DIR / Path(\"input/atmaCup#18_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(DATA_DIR / \"train_features.csv\")\n",
    "test_df = pl.read_csv(DATA_DIR / \"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df と test_dfを結合（特徴量エンジニアリングをしやすくするため）\n",
    "_all_df = pl.concat([train_df, test_df], how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    \"vEgo\",\n",
    "    \"aEgo\",\n",
    "    \"steeringAngleDeg\",\n",
    "    \"steeringTorque\",\n",
    "    \"gas\",\n",
    "]  # 同一シーンから集計する値のカラム名\n",
    "\n",
    "# 同一シーンから特徴量作成\n",
    "exprs = []\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(-1).over(\"scene\").alias(f\"{agg_col}_shift-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(1).over(\"scene\").alias(f\"{agg_col}_shift1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(-1).over(\"scene\").alias(f\"{agg_col}_diff-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値との差分\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(1).over(\"scene\").alias(f\"{agg_col}_diff1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値との差分\n",
    "exprs += [pl.col(agg_col).mean().over(\"scene\").alias(f\"{agg_col}_mean\") for agg_col in agg_cols]  # 同一シーンの平均値\n",
    "exprs += [pl.col(agg_col).std().over(\"scene\").alias(f\"{agg_col}_std\") for agg_col in agg_cols]  # 同一シーンの標準偏差\n",
    "exprs += [pl.col(agg_col).max().over(\"scene\").alias(f\"{agg_col}_max\") for agg_col in agg_cols]  # 同一シーンの最大値\n",
    "exprs += [pl.col(agg_col).min().over(\"scene\").alias(f\"{agg_col}_min\") for agg_col in agg_cols]  # 同一シーンの最小値\n",
    "\n",
    "_all_df = (\n",
    "    _all_df.with_columns(\n",
    "        # ID からシーンとデシ秒を作成\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(0).alias(\"scene\"),\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(1).cast(pl.Int32).alias(\"decisecond\"),\n",
    "    )\n",
    "    .sort(\n",
    "        # shiftと diffが時系列順に並んでいる必要があるためシーンごとに時間軸でソート\n",
    "        \"scene\",\n",
    "        \"decisecond\",\n",
    "    )\n",
    "    .with_columns(exprs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aEgo', 'aEgo_diff-1', 'aEgo_diff1', 'aEgo_max', 'aEgo_mean', 'aEgo_min', 'aEgo_shift-1', 'aEgo_shift1', 'aEgo_std', 'brake', 'brakePressed', 'decisecond', 'gas', 'gasPressed', 'gas_diff-1', 'gas_diff1', 'gas_max', 'gas_mean', 'gas_min', 'gas_shift-1', 'gas_shift1', 'gas_std', 'leftBlinker', 'rightBlinker', 'steeringAngleDeg', 'steeringAngleDeg_diff-1', 'steeringAngleDeg_diff1', 'steeringAngleDeg_max', 'steeringAngleDeg_mean', 'steeringAngleDeg_min', 'steeringAngleDeg_shift-1', 'steeringAngleDeg_shift1', 'steeringAngleDeg_std', 'steeringTorque', 'steeringTorque_diff-1', 'steeringTorque_diff1', 'steeringTorque_max', 'steeringTorque_mean', 'steeringTorque_min', 'steeringTorque_shift-1', 'steeringTorque_shift1', 'steeringTorque_std', 'vEgo', 'vEgo_diff-1', 'vEgo_diff1', 'vEgo_max', 'vEgo_mean', 'vEgo_min', 'vEgo_shift-1', 'vEgo_shift1', 'vEgo_std']\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "\n",
    "# 使う特徴量を指定するより使わない特徴量を指定するほうが試行錯誤が楽\n",
    "del_columns = targets + [\"ID\", \"scene\", \"gearShifter\"]\n",
    "\n",
    "features = list(set(_all_df.columns) - set(del_columns))\n",
    "features.sort()\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAEを計算\n",
    "def evaluation(true_values, pred_values):\n",
    "    abs_diff = abs(true_values - pred_values)\n",
    "    mae = np.mean(\n",
    "        abs_diff.reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encdoding\n",
    "categorical_columns = [\"gearShifter\"]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    _all_df = _all_df.with_columns(pl.Series(le.fit_transform(_all_df[col])).alias(f\"{col}_le\"))\n",
    "cate_features = [f\"{col}_le\" for c in categorical_columns]\n",
    "features = list(set(features) | set(cate_features))\n",
    "\n",
    "# count encoding\n",
    "count_enc = [\"gearShifter\"]\n",
    "_all_df = _all_df.with_columns([pl.col(c).count().over(c).alias(f\"{c}_count\") for c in count_enc])\n",
    "count_features = [f\"{c}_count\" for c in count_enc]\n",
    "features = list(set(features) | set(count_features))\n",
    "\n",
    "\n",
    "train_df = train_df.join(_all_df, how=\"left\", on=\"ID\")\n",
    "test_df = test_df.join(_all_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(target):\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"mae\",  # 今回の評価指標がMAEを使用\n",
    "        \"objective\": \"regression\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": Config.RANDOM_SATE,\n",
    "        \"learning_rate\": 0.01,\n",
    "        # \"device\": \"gpu\"\n",
    "    }\n",
    "\n",
    "    oof_pred = np.zeros(len(train_df))\n",
    "    y_pred = np.zeros(len(test_df))\n",
    "    models = []\n",
    "    cv_scores = {}\n",
    "\n",
    "    gkf = GroupKFold(n_splits=Config.N_FOLD)\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(gkf.split(train_df, groups=train_df[\"scene\"])):\n",
    "        print(f\"====== fold {fold} ======\")\n",
    "\n",
    "        # TrainとTestに分割\n",
    "        x_train, x_val = train_df[train_index].select(features), train_df[test_index].select(features)\n",
    "        y_train, y_val = train_df[train_index].select(target), train_df[test_index].select(target)\n",
    "\n",
    "        test = test_df[features]\n",
    "\n",
    "        # create Dataset\n",
    "        train_set = lgb.Dataset(\n",
    "            x_train.to_pandas(),\n",
    "            y_train.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "        val_set = lgb.Dataset(\n",
    "            x_val.to_pandas(),\n",
    "            y_val.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "\n",
    "        # train\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            num_boost_round=10000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100, verbose=True),\n",
    "                lgb.log_evaluation(500),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        fold_pred = model.predict(x_val.to_pandas())\n",
    "\n",
    "        score = evaluation(y_val.to_numpy().reshape(-1), fold_pred)\n",
    "        cv_scores[f\"cv{fold}\"] = score\n",
    "\n",
    "        oof_pred[test_index] = fold_pred\n",
    "\n",
    "        y_pred += model.predict(test.to_pandas()) / Config.N_FOLD\n",
    "\n",
    "        print(f\"cv score is {score}\")\n",
    "\n",
    "    oof_score = evaluation(train_df[target].to_numpy().reshape(-1), oof_pred)\n",
    "    print(f\"OOF score is {oof_score}\")\n",
    "\n",
    "    return oof_pred, y_pred, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "# x_0\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:335: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning('Converting column-vector to 1d array')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's l1: 0.0944305\tvalid_1's l1: 0.101335\n",
      "[1000]\ttraining's l1: 0.0685654\tvalid_1's l1: 0.0753467\n",
      "[1500]\ttraining's l1: 0.0635339\tvalid_1's l1: 0.0716455\n"
     ]
    }
   ],
   "source": [
    "models_dict = {}\n",
    "test_pred = []\n",
    "oof_pred = []\n",
    "for target in targets:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"# {target}\")\n",
    "    print(\"=\" * 50)\n",
    "    oof_preds_partial, y_pred_partial, models_partial = train_lgbm(target)\n",
    "    models_dict[target] = models_partial\n",
    "    oof_pred.append(oof_preds_partial)\n",
    "    test_pred.append(y_pred_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21185031472732527"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(train_df[targets].to_numpy(), np.vstack(oof_pred).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit ファイル作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_727, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.45612</td><td>-0.050807</td><td>0.002389</td><td>3.017458</td><td>-0.117573</td><td>0.005708</td><td>4.552201</td><td>-0.195567</td><td>0.002728</td><td>5.826144</td><td>-0.198686</td><td>0.005409</td><td>7.245767</td><td>-0.127643</td><td>-0.008084</td><td>8.550774</td><td>-0.02874</td><td>-0.013318</td></tr><tr><td>0.93874</td><td>0.389052</td><td>-0.000527</td><td>1.741811</td><td>1.009938</td><td>-0.002193</td><td>2.371443</td><td>1.765806</td><td>-0.008336</td><td>2.813685</td><td>2.62283</td><td>-0.008497</td><td>3.51195</td><td>3.502601</td><td>-0.004901</td><td>4.238286</td><td>4.478624</td><td>0.002362</td></tr><tr><td>1.571503</td><td>0.016573</td><td>0.003865</td><td>3.253146</td><td>0.013525</td><td>0.008019</td><td>4.892635</td><td>0.029848</td><td>0.01301</td><td>6.30592</td><td>0.067152</td><td>0.014728</td><td>7.717493</td><td>0.13308</td><td>0.018196</td><td>9.01833</td><td>0.185266</td><td>0.020942</td></tr><tr><td>0.835832</td><td>0.064877</td><td>-0.001315</td><td>1.650979</td><td>0.214632</td><td>-0.007302</td><td>2.414782</td><td>0.549095</td><td>-0.011152</td><td>2.94753</td><td>0.837604</td><td>-0.017816</td><td>3.605272</td><td>1.479534</td><td>-0.019365</td><td>4.336746</td><td>2.189905</td><td>-0.018245</td></tr><tr><td>0.812953</td><td>0.004572</td><td>-0.001849</td><td>1.415035</td><td>0.000654</td><td>-0.004624</td><td>1.880035</td><td>0.011582</td><td>-0.017626</td><td>2.218841</td><td>-0.000622</td><td>-0.036413</td><td>2.152111</td><td>0.007862</td><td>-0.05392</td><td>1.712793</td><td>-0.019529</td><td>-0.068401</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6.535473</td><td>0.009117</td><td>0.017769</td><td>13.803384</td><td>0.050178</td><td>0.04067</td><td>21.014647</td><td>0.129037</td><td>0.064933</td><td>28.275174</td><td>0.218875</td><td>0.075093</td><td>35.585978</td><td>0.331842</td><td>0.080312</td><td>43.006691</td><td>0.460795</td><td>0.069075</td></tr><tr><td>6.999905</td><td>0.000927</td><td>0.004368</td><td>14.893268</td><td>-0.011176</td><td>0.008717</td><td>22.944056</td><td>-0.028674</td><td>0.012684</td><td>31.102234</td><td>-0.067466</td><td>0.023056</td><td>39.279125</td><td>-0.098898</td><td>0.031083</td><td>47.512481</td><td>-0.141442</td><td>0.035101</td></tr><tr><td>7.415662</td><td>-0.001225</td><td>0.007195</td><td>15.664745</td><td>-0.020854</td><td>0.012552</td><td>23.896748</td><td>-0.057395</td><td>0.02172</td><td>32.060604</td><td>-0.122295</td><td>0.047701</td><td>40.124927</td><td>-0.199787</td><td>0.076695</td><td>48.056512</td><td>-0.255825</td><td>0.094876</td></tr><tr><td>6.523709</td><td>-0.000478</td><td>-0.002016</td><td>13.668654</td><td>-0.009276</td><td>-0.004432</td><td>20.768413</td><td>-0.012114</td><td>-0.00956</td><td>27.817947</td><td>-0.00237</td><td>-0.013802</td><td>34.843368</td><td>-0.010447</td><td>-0.016471</td><td>41.819822</td><td>0.010564</td><td>-0.016242</td></tr><tr><td>5.816298</td><td>-0.248527</td><td>0.009125</td><td>12.327814</td><td>-1.052517</td><td>0.013028</td><td>18.931249</td><td>-2.35057</td><td>0.016978</td><td>25.55723</td><td>-4.145599</td><td>0.004071</td><td>32.012352</td><td>-6.166755</td><td>-0.048089</td><td>38.48815</td><td>-8.566273</td><td>-0.118385</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_727, 18)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ x_0      ┆ y_0       ┆ z_0       ┆ x_1       ┆ … ┆ z_4       ┆ x_5       ┆ y_5       ┆ z_5       │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.45612  ┆ -0.050807 ┆ 0.002389  ┆ 3.017458  ┆ … ┆ -0.008084 ┆ 8.550774  ┆ -0.02874  ┆ -0.013318 │\n",
       "│ 0.93874  ┆ 0.389052  ┆ -0.000527 ┆ 1.741811  ┆ … ┆ -0.004901 ┆ 4.238286  ┆ 4.478624  ┆ 0.002362  │\n",
       "│ 1.571503 ┆ 0.016573  ┆ 0.003865  ┆ 3.253146  ┆ … ┆ 0.018196  ┆ 9.01833   ┆ 0.185266  ┆ 0.020942  │\n",
       "│ 0.835832 ┆ 0.064877  ┆ -0.001315 ┆ 1.650979  ┆ … ┆ -0.019365 ┆ 4.336746  ┆ 2.189905  ┆ -0.018245 │\n",
       "│ 0.812953 ┆ 0.004572  ┆ -0.001849 ┆ 1.415035  ┆ … ┆ -0.05392  ┆ 1.712793  ┆ -0.019529 ┆ -0.068401 │\n",
       "│ …        ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 6.535473 ┆ 0.009117  ┆ 0.017769  ┆ 13.803384 ┆ … ┆ 0.080312  ┆ 43.006691 ┆ 0.460795  ┆ 0.069075  │\n",
       "│ 6.999905 ┆ 0.000927  ┆ 0.004368  ┆ 14.893268 ┆ … ┆ 0.031083  ┆ 47.512481 ┆ -0.141442 ┆ 0.035101  │\n",
       "│ 7.415662 ┆ -0.001225 ┆ 0.007195  ┆ 15.664745 ┆ … ┆ 0.076695  ┆ 48.056512 ┆ -0.255825 ┆ 0.094876  │\n",
       "│ 6.523709 ┆ -0.000478 ┆ -0.002016 ┆ 13.668654 ┆ … ┆ -0.016471 ┆ 41.819822 ┆ 0.010564  ┆ -0.016242 │\n",
       "│ 5.816298 ┆ -0.248527 ┆ 0.009125  ┆ 12.327814 ┆ … ┆ -0.048089 ┆ 38.48815  ┆ -8.566273 ┆ -0.118385 │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_col_names = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "sub_df = pl.DataFrame(np.vstack(test_pred).T, schema=sub_col_names)\n",
    "display(sub_df)\n",
    "sub_df.write_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
