{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/*\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PACKAGE_DIR = \"/kaggle/src\"\n",
    "sys.path.append(PACKAGE_DIR)\n",
    "sys.path.append(os.path.join(PACKAGE_DIR, \"Penguin-ML-Library\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 11:47:18.699124: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 11:47:18.726047: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "set seed: 46\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from penguinml.utils.logger import get_logger, init_logger\n",
    "from penguinml.utils.set_seed import seed_base\n",
    "\n",
    "MODEL_NAME = \"lightgbm\"\n",
    "CFG = yaml.safe_load(open(os.path.join(PACKAGE_DIR, \"config.yaml\"), \"r\"))\n",
    "print(CFG[MODEL_NAME][\"execution\"][\"exp_id\"])\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG[MODEL_NAME]['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "init_logger(f\"{ CFG[MODEL_NAME]['execution']['exp_id']}.log\")\n",
    "logger = get_logger(\"main\")\n",
    "seed_base(CFG[MODEL_NAME][\"execution\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    N_FOLD = 5\n",
    "    RANDOM_SATE = 42\n",
    "\n",
    "\n",
    "NB = \"exp1015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/kaggle\")\n",
    "DATA_DIR = ROOT_DIR / Path(\"input/atmaCup#18_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(DATA_DIR / \"train_features.csv\")\n",
    "test_df = pl.read_csv(DATA_DIR / \"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df と test_dfを結合（特徴量エンジニアリングをしやすくするため）\n",
    "_all_df = pl.concat([train_df, test_df], how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    \"vEgo\",\n",
    "    \"aEgo\",\n",
    "    \"steeringAngleDeg\",\n",
    "    \"steeringTorque\",\n",
    "    \"gas\",\n",
    "]  # 同一シーンから集計する値のカラム名\n",
    "\n",
    "# 同一シーンから特徴量作成\n",
    "exprs = []\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(-1).over(\"scene\").alias(f\"{agg_col}_shift-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(1).over(\"scene\").alias(f\"{agg_col}_shift1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(-1).over(\"scene\").alias(f\"{agg_col}_diff-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値との差分\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(1).over(\"scene\").alias(f\"{agg_col}_diff1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値との差分\n",
    "exprs += [pl.col(agg_col).mean().over(\"scene\").alias(f\"{agg_col}_mean\") for agg_col in agg_cols]  # 同一シーンの平均値\n",
    "exprs += [pl.col(agg_col).std().over(\"scene\").alias(f\"{agg_col}_std\") for agg_col in agg_cols]  # 同一シーンの標準偏差\n",
    "exprs += [pl.col(agg_col).max().over(\"scene\").alias(f\"{agg_col}_max\") for agg_col in agg_cols]  # 同一シーンの最大値\n",
    "exprs += [pl.col(agg_col).min().over(\"scene\").alias(f\"{agg_col}_min\") for agg_col in agg_cols]  # 同一シーンの最小値\n",
    "\n",
    "_all_df = (\n",
    "    _all_df.with_columns(\n",
    "        # ID からシーンとデシ秒を作成\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(0).alias(\"scene\"),\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(1).cast(pl.Int32).alias(\"decisecond\"),\n",
    "    )\n",
    "    .sort(\n",
    "        # shiftと diffが時系列順に並んでいる必要があるためシーンごとに時間軸でソート\n",
    "        \"scene\",\n",
    "        \"decisecond\",\n",
    "    )\n",
    "    .with_columns(exprs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = pl.read_csv(CFG[\"dataset\"][\"train_fold_path\"]).rename({\"sceneID\": \"scene\"})\n",
    "_all_df = _all_df.join(train_folds, how=\"left\", on=\"scene\")\n",
    "# assert train_df[\"fold\"].null_count() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45098/45098 [00:00<00:00, 77109.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# YOLOの検出結果\n",
    "import json\n",
    "\n",
    "yolo_paths = glob.glob(\"/kaggle/input/yolo-det/det/*.json\")\n",
    "yolo_dfs = []\n",
    "for path in tqdm(yolo_paths):\n",
    "    ID = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    yolo_feature = {\n",
    "        \"ID\": ID,\n",
    "        \"num_objects\": len(data),\n",
    "    }\n",
    "    for bbox in data:\n",
    "        if bbox[\"x1\"] == bbox[\"x2\"] or bbox[\"y1\"] == bbox[\"y2\"]:\n",
    "            continue\n",
    "\n",
    "        if bbox[\"cls\"] != \"car\":\n",
    "            continue\n",
    "\n",
    "        # count\n",
    "        if bbox[\"cls\"] not in yolo_feature:\n",
    "            yolo_feature[bbox[\"cls\"]] = 0\n",
    "        yolo_feature[bbox[\"cls\"]] += 1\n",
    "\n",
    "        # 最も横方向が中央にあるものの情報\n",
    "        if f\"center_x_{bbox['cls']}\" not in yolo_feature:\n",
    "            yolo_feature[f\"center_x_{bbox['cls']}\"] = -1\n",
    "        current_dist = abs(yolo_feature[f\"center_x_{bbox['cls']}\"] - 64)\n",
    "        now_center_x = (bbox[\"x1\"] + bbox[\"x2\"]) / 2\n",
    "        now_dist = abs(now_center_x - 64)\n",
    "        if now_dist < current_dist:\n",
    "            yolo_feature[f\"center_x_{bbox['cls']}\"] = now_center_x\n",
    "            yolo_feature[f\"center_y_{bbox['cls']}\"] = (bbox[\"y1\"] + bbox[\"y2\"]) / 2\n",
    "            yolo_feature[f\"width_{bbox['cls']}\"] = bbox[\"x2\"] - bbox[\"x1\"]\n",
    "            yolo_feature[f\"height_{bbox['cls']}\"] = bbox[\"y2\"] - bbox[\"y1\"]\n",
    "            yolo_feature[f\"bottom_{bbox['cls']}\"] = bbox[\"y2\"]\n",
    "            yolo_feature[f\"area_{bbox['cls']}\"] = (bbox[\"x2\"] - bbox[\"x1\"]) * (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "            yolo_feature[f\"aspect_ratio_{bbox['cls']}\"] = (bbox[\"x2\"] - bbox[\"x1\"]) / (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "            yolo_feature[f\"conf_{bbox['cls']}\"] = bbox[\"conf\"]\n",
    "    yolo_dfs.append(yolo_feature)\n",
    "yolo_df = pl.DataFrame(yolo_dfs)\n",
    "\n",
    "_all_df = _all_df.join(yolo_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aEgo', 'aEgo_diff-1', 'aEgo_diff1', 'aEgo_max', 'aEgo_mean', 'aEgo_min', 'aEgo_shift-1', 'aEgo_shift1', 'aEgo_std', 'area_car', 'aspect_ratio_car', 'bottom_car', 'brake', 'brakePressed', 'car', 'center_x_car', 'center_y_car', 'conf_car', 'decisecond', 'fold', 'gas', 'gasPressed', 'gas_diff-1', 'gas_diff1', 'gas_max', 'gas_mean', 'gas_min', 'gas_shift-1', 'gas_shift1', 'gas_std', 'height_car', 'leftBlinker', 'num_objects', 'rightBlinker', 'steeringAngleDeg', 'steeringAngleDeg_diff-1', 'steeringAngleDeg_diff1', 'steeringAngleDeg_max', 'steeringAngleDeg_mean', 'steeringAngleDeg_min', 'steeringAngleDeg_shift-1', 'steeringAngleDeg_shift1', 'steeringAngleDeg_std', 'steeringTorque', 'steeringTorque_diff-1', 'steeringTorque_diff1', 'steeringTorque_max', 'steeringTorque_mean', 'steeringTorque_min', 'steeringTorque_shift-1', 'steeringTorque_shift1', 'steeringTorque_std', 'vEgo', 'vEgo_diff-1', 'vEgo_diff1', 'vEgo_max', 'vEgo_mean', 'vEgo_min', 'vEgo_shift-1', 'vEgo_shift1', 'vEgo_std', 'width_car']\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "\n",
    "# 使う特徴量を指定するより使わない特徴量を指定するほうが試行錯誤が楽\n",
    "del_columns = targets + [\"ID\", \"scene\", \"gearShifter\", \"fold\"]\n",
    "\n",
    "features = list(set(_all_df.columns) - set(del_columns))\n",
    "features.sort()\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAEを計算\n",
    "def evaluation(true_values, pred_values):\n",
    "    abs_diff = abs(true_values - pred_values)\n",
    "    mae = np.mean(\n",
    "        abs_diff.reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encdoding\n",
    "categorical_columns = [\"gearShifter\"]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    _all_df = _all_df.with_columns(pl.Series(le.fit_transform(_all_df[col])).alias(f\"{col}_le\"))\n",
    "cate_features = [f\"{col}_le\" for c in categorical_columns]\n",
    "features = list(set(features) | set(cate_features))\n",
    "\n",
    "# count encoding\n",
    "count_enc = [\"gearShifter\"]\n",
    "_all_df = _all_df.with_columns([pl.col(c).count().over(c).alias(f\"{c}_count\") for c in count_enc])\n",
    "count_features = [f\"{c}_count\" for c in count_enc]\n",
    "features = list(set(features) | set(count_features))\n",
    "\n",
    "\n",
    "train_df = train_df.join(_all_df, how=\"left\", on=\"ID\")\n",
    "test_df = test_df.join(_all_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(target):\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"mae\",  # 今回の評価指標がMAEを使用\n",
    "        \"objective\": \"regression\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": Config.RANDOM_SATE,\n",
    "        \"learning_rate\": 0.01,\n",
    "        # \"device\": \"gpu\"\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "\n",
    "    oof_pred = np.zeros(len(train_df))\n",
    "    y_pred = np.zeros(len(test_df))\n",
    "    models = []\n",
    "    cv_scores = {}\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"fold{fold}: \", end=\"\")\n",
    "\n",
    "        # TrainとTestに分割\n",
    "        x_train = train_df.filter(pl.col(\"fold\") != fold).select(features)\n",
    "        x_val = train_df.filter(pl.col(\"fold\") == fold).select(features)\n",
    "        y_train = train_df.filter(pl.col(\"fold\") != fold).select(target)\n",
    "        y_val = train_df.filter(pl.col(\"fold\") == fold).select(target)\n",
    "\n",
    "        test = test_df[features]\n",
    "\n",
    "        # create Dataset\n",
    "        train_set = lgb.Dataset(\n",
    "            x_train.to_pandas(),\n",
    "            y_train.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "        val_set = lgb.Dataset(\n",
    "            x_val.to_pandas(),\n",
    "            y_val.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "\n",
    "        # train\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            num_boost_round=10000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "                lgb.log_evaluation(500000),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        fold_pred = model.predict(x_val.to_pandas())\n",
    "\n",
    "        score = evaluation(y_val.to_numpy().reshape(-1), fold_pred)\n",
    "        cv_scores[f\"cv{fold}\"] = score\n",
    "\n",
    "        # oof_pred[test_index] = fold_pred\n",
    "        oof_pred[train_df[\"fold\"].to_numpy() == fold] = fold_pred\n",
    "\n",
    "        y_pred += model.predict(test.to_pandas()) / Config.N_FOLD\n",
    "\n",
    "        print(f\"{score}\")\n",
    "\n",
    "    oof_score = evaluation(train_df[target].to_numpy().reshape(-1), oof_pred)\n",
    "    print(f\"OOF score is {oof_score}\")\n",
    "\n",
    "    return oof_pred, y_pred, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "# x_0\n",
      "==================================================\n",
      "fold0: 0.06166038975812681\n",
      "fold1: 0.060445217035051714\n",
      "fold2: 0.06338158493649118\n",
      "fold3: 0.06168589245382569\n",
      "fold4: 0.06254899851669268\n",
      "OOF score is 0.06194440999126581\n",
      "==================================================\n",
      "# y_0\n",
      "==================================================\n",
      "fold0: 0.03244410596347763\n",
      "fold1: 0.031815958986059316\n",
      "fold2: 0.03272494156327116\n",
      "fold3: 0.03200615100117264\n",
      "fold4: 0.033429135668984554\n",
      "OOF score is 0.03248405771540902\n",
      "==================================================\n",
      "# z_0\n",
      "==================================================\n",
      "fold0: 0.025868668904609\n",
      "fold1: 0.02540140018105934\n",
      "fold2: 0.026390345937789824\n",
      "fold3: 0.026325904984568032\n",
      "fold4: 0.025641201657790044\n",
      "OOF score is 0.025925503022715513\n",
      "==================================================\n",
      "# x_1\n",
      "==================================================\n",
      "fold0: 0.13098200507877758\n",
      "fold1: 0.130871442361831\n",
      "fold2: 0.13386999172177277\n",
      "fold3: 0.13086961830029697\n",
      "fold4: 0.1345110817353934\n",
      "OOF score is 0.132220799276225\n",
      "==================================================\n",
      "# y_1\n",
      "==================================================\n",
      "fold0: 0.07410326174793094\n",
      "fold1: 0.07223453501659419\n",
      "fold2: 0.07485537852153941\n",
      "fold3: 0.07305184483876281\n",
      "fold4: 0.07480201405145306\n",
      "OOF score is 0.07380941361063394\n",
      "==================================================\n",
      "# z_1\n",
      "==================================================\n",
      "fold0: 0.05388564269763408\n",
      "fold1: 0.05237215214868925\n",
      "fold2: 0.05448901479876867\n",
      "fold3: 0.05474307615865372\n",
      "fold4: 0.053519203140808366\n",
      "OOF score is 0.053801819721651795\n",
      "==================================================\n",
      "# x_2\n",
      "==================================================\n",
      "fold0: 0.2226158974397218\n",
      "fold1: 0.22466189024845323\n",
      "fold2: 0.22459153842488022\n",
      "fold3: 0.22235382605296083\n",
      "fold4: 0.22815992681405617\n",
      "OOF score is 0.22447657289365214\n",
      "==================================================\n",
      "# y_2\n",
      "==================================================\n",
      "fold0: 0.13111115127148015\n",
      "fold1: 0.1299276229978038\n",
      "fold2: 0.13235471578621982\n",
      "fold3: 0.13006361638868183\n",
      "fold4: 0.13243363802114547\n",
      "OOF score is 0.13117814734831\n",
      "==================================================\n",
      "# z_2\n",
      "==================================================\n",
      "fold0: 0.08260009153003262\n",
      "fold1: 0.08025245938893778\n",
      "fold2: 0.08342615308400171\n",
      "fold3: 0.08446678787673564\n",
      "fold4: 0.08245763042209786\n",
      "OOF score is 0.08264062352579817\n",
      "==================================================\n",
      "# x_3\n",
      "==================================================\n",
      "fold0: 0.3434583843175449\n",
      "fold1: 0.3512450088971913\n",
      "fold2: 0.3501312798163062\n",
      "fold3: 0.345185120618572\n",
      "fold4: 0.35182000741568337\n",
      "OOF score is 0.3483678470135507\n",
      "==================================================\n",
      "# y_3\n",
      "==================================================\n",
      "fold0: 0.21236902941511024\n",
      "fold1: 0.2164032162088519\n",
      "fold2: 0.21832684205839106\n",
      "fold3: 0.2130045531047542\n",
      "fold4: 0.21786352135262987\n",
      "OOF score is 0.2155933580832698\n",
      "==================================================\n",
      "# z_3\n",
      "==================================================\n",
      "fold0: 0.11198879513755443\n",
      "fold1: 0.10913202921635684\n",
      "fold2: 0.11330338116106912\n",
      "fold3: 0.11496828166118019\n",
      "fold4: 0.11310106352128693\n",
      "OOF score is 0.11249869838243982\n",
      "==================================================\n",
      "# x_4\n",
      "==================================================\n",
      "fold0: 0.493585956323816\n",
      "fold1: 0.5055745634091201\n",
      "fold2: 0.5039056527326824\n",
      "fold3: 0.498608575288489\n",
      "fold4: 0.5047943161759976\n",
      "OOF score is 0.5012936350668893\n",
      "==================================================\n",
      "# y_4\n",
      "==================================================\n",
      "fold0: 0.3229983707036579\n",
      "fold1: 0.33425212113281894\n",
      "fold2: 0.3329983143419382\n",
      "fold3: 0.32436659355354436\n",
      "fold4: 0.3370895554165333\n",
      "OOF score is 0.33034082173177304\n",
      "==================================================\n",
      "# z_4\n",
      "==================================================\n",
      "fold0: 0.14238106716445206\n",
      "fold1: 0.1398233038976945\n",
      "fold2: 0.14403959425611748\n",
      "fold3: 0.1459795938604055\n",
      "fold4: 0.14409933133275815\n",
      "OOF score is 0.1432645577312787\n",
      "==================================================\n",
      "# x_5\n",
      "==================================================\n",
      "fold0: 0.6648019648797671\n",
      "fold1: 0.6829388305623487\n",
      "fold2: 0.6782969014540295\n",
      "fold3: 0.6761000857838879\n",
      "fold4: 0.6810678887513443\n",
      "OOF score is 0.6766408613119514\n",
      "==================================================\n",
      "# y_5\n",
      "==================================================\n",
      "fold0: 0.46621619331008546\n",
      "fold1: 0.4843407653290575\n",
      "fold2: 0.48138811713698854\n",
      "fold3: 0.4673613219888978\n",
      "fold4: 0.4853610300067589\n",
      "OOF score is 0.4769332384470222\n",
      "==================================================\n",
      "# z_5\n",
      "==================================================\n",
      "fold0: 0.17413739157045832\n",
      "fold1: 0.17167649680408215\n",
      "fold2: 0.17588093872776397\n",
      "fold3: 0.1784898017454175\n",
      "fold4: 0.17621027406815734\n",
      "OOF score is 0.1752789542616935\n"
     ]
    }
   ],
   "source": [
    "models_dict = {}\n",
    "test_pred = []\n",
    "oof_pred = []\n",
    "for target in targets:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"# {target}\")\n",
    "    print(\"=\" * 50)\n",
    "    oof_preds_partial, y_pred_partial, models_partial = train_lgbm(target)\n",
    "    models_dict[target] = models_partial\n",
    "    oof_pred.append(oof_preds_partial)\n",
    "    test_pred.append(y_pred_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21103851772975168"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(train_df[targets].to_numpy(), np.vstack(oof_pred).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit ファイル作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_727, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.455648</td><td>-0.050018</td><td>0.003142</td><td>3.028354</td><td>-0.112625</td><td>0.007276</td><td>4.526829</td><td>-0.207772</td><td>0.008392</td><td>5.862693</td><td>-0.186544</td><td>0.022955</td><td>7.265309</td><td>-0.148999</td><td>0.020651</td><td>8.616736</td><td>-0.061914</td><td>0.020857</td></tr><tr><td>0.931759</td><td>0.378611</td><td>-0.000151</td><td>1.727811</td><td>0.959351</td><td>0.001481</td><td>2.356016</td><td>1.618458</td><td>0.011347</td><td>2.919347</td><td>2.393055</td><td>0.015205</td><td>3.7591</td><td>3.232766</td><td>0.017041</td><td>4.400578</td><td>4.146869</td><td>0.023659</td></tr><tr><td>1.580343</td><td>0.012554</td><td>0.00411</td><td>3.263016</td><td>0.011007</td><td>0.006631</td><td>4.809744</td><td>0.037001</td><td>0.012242</td><td>6.295136</td><td>0.088492</td><td>0.010007</td><td>7.761515</td><td>0.122175</td><td>-0.000794</td><td>9.055633</td><td>0.184131</td><td>0.0046</td></tr><tr><td>0.832457</td><td>0.067855</td><td>-0.001345</td><td>1.645893</td><td>0.239849</td><td>-0.004596</td><td>2.379354</td><td>0.589268</td><td>-0.007941</td><td>2.951924</td><td>0.947877</td><td>-0.013307</td><td>3.557095</td><td>1.730979</td><td>-0.020588</td><td>4.205208</td><td>2.647696</td><td>-0.025641</td></tr><tr><td>0.819643</td><td>0.003443</td><td>-0.001796</td><td>1.421269</td><td>0.003373</td><td>-0.006486</td><td>1.890073</td><td>0.012693</td><td>-0.020091</td><td>2.241586</td><td>0.011022</td><td>-0.036228</td><td>2.193091</td><td>0.000391</td><td>-0.054343</td><td>1.72367</td><td>-0.009503</td><td>-0.070152</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6.537419</td><td>0.008363</td><td>0.018345</td><td>13.800382</td><td>0.047062</td><td>0.046983</td><td>21.009712</td><td>0.125885</td><td>0.079371</td><td>28.269606</td><td>0.203972</td><td>0.091345</td><td>35.549006</td><td>0.310601</td><td>0.100467</td><td>42.992752</td><td>0.444018</td><td>0.100446</td></tr><tr><td>6.997276</td><td>0.000465</td><td>0.005644</td><td>14.877982</td><td>-0.015178</td><td>0.012522</td><td>22.910983</td><td>-0.038721</td><td>0.020602</td><td>31.034883</td><td>-0.087646</td><td>0.035036</td><td>39.19934</td><td>-0.117717</td><td>0.040591</td><td>47.446969</td><td>-0.158336</td><td>0.047015</td></tr><tr><td>7.413496</td><td>-0.001997</td><td>0.007757</td><td>15.659215</td><td>-0.023365</td><td>0.017406</td><td>23.871527</td><td>-0.068416</td><td>0.033259</td><td>32.024329</td><td>-0.142547</td><td>0.067403</td><td>40.06737</td><td>-0.212788</td><td>0.089625</td><td>47.997185</td><td>-0.283517</td><td>0.137738</td></tr><tr><td>6.524535</td><td>-0.000574</td><td>-0.000146</td><td>13.67285</td><td>-0.00441</td><td>0.019255</td><td>20.766804</td><td>-0.001918</td><td>0.071913</td><td>27.824928</td><td>-0.0124</td><td>0.146933</td><td>34.832466</td><td>0.000116</td><td>0.25533</td><td>41.850009</td><td>0.000944</td><td>0.411791</td></tr><tr><td>5.814673</td><td>-0.243479</td><td>0.008524</td><td>12.324967</td><td>-1.060169</td><td>0.016339</td><td>18.891641</td><td>-2.335492</td><td>0.011324</td><td>25.464703</td><td>-4.148188</td><td>-0.007564</td><td>31.998026</td><td>-6.148273</td><td>-0.076423</td><td>38.406433</td><td>-8.619767</td><td>-0.144827</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_727, 18)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ x_0      ┆ y_0       ┆ z_0       ┆ x_1       ┆ … ┆ z_4       ┆ x_5       ┆ y_5       ┆ z_5       │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.455648 ┆ -0.050018 ┆ 0.003142  ┆ 3.028354  ┆ … ┆ 0.020651  ┆ 8.616736  ┆ -0.061914 ┆ 0.020857  │\n",
       "│ 0.931759 ┆ 0.378611  ┆ -0.000151 ┆ 1.727811  ┆ … ┆ 0.017041  ┆ 4.400578  ┆ 4.146869  ┆ 0.023659  │\n",
       "│ 1.580343 ┆ 0.012554  ┆ 0.00411   ┆ 3.263016  ┆ … ┆ -0.000794 ┆ 9.055633  ┆ 0.184131  ┆ 0.0046    │\n",
       "│ 0.832457 ┆ 0.067855  ┆ -0.001345 ┆ 1.645893  ┆ … ┆ -0.020588 ┆ 4.205208  ┆ 2.647696  ┆ -0.025641 │\n",
       "│ 0.819643 ┆ 0.003443  ┆ -0.001796 ┆ 1.421269  ┆ … ┆ -0.054343 ┆ 1.72367   ┆ -0.009503 ┆ -0.070152 │\n",
       "│ …        ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 6.537419 ┆ 0.008363  ┆ 0.018345  ┆ 13.800382 ┆ … ┆ 0.100467  ┆ 42.992752 ┆ 0.444018  ┆ 0.100446  │\n",
       "│ 6.997276 ┆ 0.000465  ┆ 0.005644  ┆ 14.877982 ┆ … ┆ 0.040591  ┆ 47.446969 ┆ -0.158336 ┆ 0.047015  │\n",
       "│ 7.413496 ┆ -0.001997 ┆ 0.007757  ┆ 15.659215 ┆ … ┆ 0.089625  ┆ 47.997185 ┆ -0.283517 ┆ 0.137738  │\n",
       "│ 6.524535 ┆ -0.000574 ┆ -0.000146 ┆ 13.67285  ┆ … ┆ 0.25533   ┆ 41.850009 ┆ 0.000944  ┆ 0.411791  │\n",
       "│ 5.814673 ┆ -0.243479 ┆ 0.008524  ┆ 12.324967 ┆ … ┆ -0.076423 ┆ 38.406433 ┆ -8.619767 ┆ -0.144827 │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_col_names = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "sub_df = pl.DataFrame(np.vstack(test_pred).T, schema=sub_col_names)\n",
    "display(sub_df)\n",
    "sub_df.write_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
