{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/*\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PACKAGE_DIR = \"/kaggle/src\"\n",
    "sys.path.append(PACKAGE_DIR)\n",
    "sys.path.append(os.path.join(PACKAGE_DIR, \"Penguin-ML-Library\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 11:19:12.898514: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 11:19:12.925726: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "set seed: 46\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from penguinml.utils.logger import get_logger, init_logger\n",
    "from penguinml.utils.set_seed import seed_base\n",
    "\n",
    "MODEL_NAME = \"lightgbm\"\n",
    "CFG = yaml.safe_load(open(os.path.join(PACKAGE_DIR, \"config.yaml\"), \"r\"))\n",
    "print(CFG[MODEL_NAME][\"execution\"][\"exp_id\"])\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG[MODEL_NAME]['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "init_logger(f\"{ CFG[MODEL_NAME]['execution']['exp_id']}.log\")\n",
    "logger = get_logger(\"main\")\n",
    "seed_base(CFG[MODEL_NAME][\"execution\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    N_FOLD = 5\n",
    "    RANDOM_SATE = 42\n",
    "\n",
    "\n",
    "NB = \"exp1015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/kaggle\")\n",
    "DATA_DIR = ROOT_DIR / Path(\"input/atmaCup#18_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(DATA_DIR / \"train_features.csv\")\n",
    "test_df = pl.read_csv(DATA_DIR / \"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df と test_dfを結合（特徴量エンジニアリングをしやすくするため）\n",
    "_all_df = pl.concat([train_df, test_df], how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    \"vEgo\",\n",
    "    \"aEgo\",\n",
    "    \"steeringAngleDeg\",\n",
    "    \"steeringTorque\",\n",
    "    \"gas\",\n",
    "]  # 同一シーンから集計する値のカラム名\n",
    "\n",
    "# 同一シーンから特徴量作成\n",
    "exprs = []\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(-1).over(\"scene\").alias(f\"{agg_col}_shift-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(1).over(\"scene\").alias(f\"{agg_col}_shift1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(-1).over(\"scene\").alias(f\"{agg_col}_diff-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値との差分\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(1).over(\"scene\").alias(f\"{agg_col}_diff1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値との差分\n",
    "exprs += [pl.col(agg_col).mean().over(\"scene\").alias(f\"{agg_col}_mean\") for agg_col in agg_cols]  # 同一シーンの平均値\n",
    "exprs += [pl.col(agg_col).std().over(\"scene\").alias(f\"{agg_col}_std\") for agg_col in agg_cols]  # 同一シーンの標準偏差\n",
    "exprs += [pl.col(agg_col).max().over(\"scene\").alias(f\"{agg_col}_max\") for agg_col in agg_cols]  # 同一シーンの最大値\n",
    "exprs += [pl.col(agg_col).min().over(\"scene\").alias(f\"{agg_col}_min\") for agg_col in agg_cols]  # 同一シーンの最小値\n",
    "\n",
    "_all_df = (\n",
    "    _all_df.with_columns(\n",
    "        # ID からシーンとデシ秒を作成\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(0).alias(\"scene\"),\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(1).cast(pl.Int32).alias(\"decisecond\"),\n",
    "    )\n",
    "    .sort(\n",
    "        # shiftと diffが時系列順に並んでいる必要があるためシーンごとに時間軸でソート\n",
    "        \"scene\",\n",
    "        \"decisecond\",\n",
    "    )\n",
    "    .with_columns(exprs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = pl.read_csv(CFG[\"dataset\"][\"train_fold_path\"]).rename({\"sceneID\": \"scene\"})\n",
    "_all_df = _all_df.join(train_folds, how=\"left\", on=\"scene\")\n",
    "# assert train_df[\"fold\"].null_count() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aEgo', 'aEgo_diff-1', 'aEgo_diff1', 'aEgo_max', 'aEgo_mean', 'aEgo_min', 'aEgo_shift-1', 'aEgo_shift1', 'aEgo_std', 'brake', 'brakePressed', 'decisecond', 'fold', 'gas', 'gasPressed', 'gas_diff-1', 'gas_diff1', 'gas_max', 'gas_mean', 'gas_min', 'gas_shift-1', 'gas_shift1', 'gas_std', 'leftBlinker', 'rightBlinker', 'steeringAngleDeg', 'steeringAngleDeg_diff-1', 'steeringAngleDeg_diff1', 'steeringAngleDeg_max', 'steeringAngleDeg_mean', 'steeringAngleDeg_min', 'steeringAngleDeg_shift-1', 'steeringAngleDeg_shift1', 'steeringAngleDeg_std', 'steeringTorque', 'steeringTorque_diff-1', 'steeringTorque_diff1', 'steeringTorque_max', 'steeringTorque_mean', 'steeringTorque_min', 'steeringTorque_shift-1', 'steeringTorque_shift1', 'steeringTorque_std', 'vEgo', 'vEgo_diff-1', 'vEgo_diff1', 'vEgo_max', 'vEgo_mean', 'vEgo_min', 'vEgo_shift-1', 'vEgo_shift1', 'vEgo_std']\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "\n",
    "# 使う特徴量を指定するより使わない特徴量を指定するほうが試行錯誤が楽\n",
    "del_columns = targets + [\"ID\", \"scene\", \"gearShifter\"]\n",
    "\n",
    "features = list(set(_all_df.columns) - set(del_columns))\n",
    "features.sort()\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAEを計算\n",
    "def evaluation(true_values, pred_values):\n",
    "    abs_diff = abs(true_values - pred_values)\n",
    "    mae = np.mean(\n",
    "        abs_diff.reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encdoding\n",
    "categorical_columns = [\"gearShifter\"]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    _all_df = _all_df.with_columns(pl.Series(le.fit_transform(_all_df[col])).alias(f\"{col}_le\"))\n",
    "cate_features = [f\"{col}_le\" for c in categorical_columns]\n",
    "features = list(set(features) | set(cate_features))\n",
    "\n",
    "# count encoding\n",
    "count_enc = [\"gearShifter\"]\n",
    "_all_df = _all_df.with_columns([pl.col(c).count().over(c).alias(f\"{c}_count\") for c in count_enc])\n",
    "count_features = [f\"{c}_count\" for c in count_enc]\n",
    "features = list(set(features) | set(count_features))\n",
    "\n",
    "\n",
    "train_df = train_df.join(_all_df, how=\"left\", on=\"ID\")\n",
    "test_df = test_df.join(_all_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(target):\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"mae\",  # 今回の評価指標がMAEを使用\n",
    "        \"objective\": \"regression\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": Config.RANDOM_SATE,\n",
    "        \"learning_rate\": 0.01,\n",
    "        # \"device\": \"gpu\"\n",
    "    }\n",
    "\n",
    "    oof_pred = np.zeros(len(train_df))\n",
    "    y_pred = np.zeros(len(test_df))\n",
    "    models = []\n",
    "    cv_scores = {}\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"====== fold {fold} ======\")\n",
    "\n",
    "        # TrainとTestに分割\n",
    "        x_train = train_df.filter(pl.col(\"fold\") != fold).select(features).drop([\"fold\"])\n",
    "        x_val = train_df.filter(pl.col(\"fold\") == fold).select(features).drop([\"fold\"])\n",
    "        y_train = train_df.filter(pl.col(\"fold\") != fold).select(target)\n",
    "        y_val = train_df.filter(pl.col(\"fold\") == fold).select(target)\n",
    "\n",
    "        test = test_df[features]\n",
    "\n",
    "        # create Dataset\n",
    "        train_set = lgb.Dataset(\n",
    "            x_train.to_pandas(),\n",
    "            y_train.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "        val_set = lgb.Dataset(\n",
    "            x_val.to_pandas(),\n",
    "            y_val.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "\n",
    "        # train\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            num_boost_round=10000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100, verbose=True),\n",
    "                lgb.log_evaluation(500),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        fold_pred = model.predict(x_val.to_pandas())\n",
    "\n",
    "        score = evaluation(y_val.to_numpy().reshape(-1), fold_pred)\n",
    "        cv_scores[f\"cv{fold}\"] = score\n",
    "\n",
    "        # oof_pred[test_index] = fold_pred\n",
    "        oof_pred[train_df[\"fold\"].to_numpy() == fold] = fold_pred\n",
    "\n",
    "        y_pred += model.predict(test.drop([\"fold\"]).to_pandas()) / Config.N_FOLD\n",
    "\n",
    "        print(f\"cv score is {score}\")\n",
    "\n",
    "    oof_score = evaluation(train_df[target].to_numpy().reshape(-1), oof_pred)\n",
    "    print(f\"OOF score is {oof_score}\")\n",
    "\n",
    "    return oof_pred, y_pred, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "# x_0\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 4.112955\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0645022\tvalid_1's l1: 0.0660327\n",
      "[1000]\ttraining's l1: 0.0573482\tvalid_1's l1: 0.0618247\n",
      "Early stopping, best iteration is:\n",
      "[980]\ttraining's l1: 0.0574501\tvalid_1's l1: 0.0618166\n",
      "cv score is 0.06181659804333758\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 4.136355\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0645734\tvalid_1's l1: 0.0648295\n",
      "Early stopping, best iteration is:\n",
      "[831]\ttraining's l1: 0.0583221\tvalid_1's l1: 0.0604486\n",
      "cv score is 0.060448609468825444\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 4.114706\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0639238\tvalid_1's l1: 0.0679094\n",
      "Early stopping, best iteration is:\n",
      "[879]\ttraining's l1: 0.0572994\tvalid_1's l1: 0.0633226\n",
      "cv score is 0.06332260045828345\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 4.107930\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0644849\tvalid_1's l1: 0.0666372\n",
      "[1000]\ttraining's l1: 0.0571916\tvalid_1's l1: 0.0617648\n",
      "Early stopping, best iteration is:\n",
      "[1252]\ttraining's l1: 0.055982\tvalid_1's l1: 0.0617289\n",
      "cv score is 0.06172893968837098\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 4.140272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0640697\tvalid_1's l1: 0.0668429\n",
      "[1000]\ttraining's l1: 0.0568937\tvalid_1's l1: 0.0624415\n",
      "Early stopping, best iteration is:\n",
      "[1251]\ttraining's l1: 0.0557397\tvalid_1's l1: 0.0623719\n",
      "cv score is 0.062371911084033074\n",
      "OOF score is 0.06193772895560465\n",
      "==================================================\n",
      "# y_0\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.001439\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0307116\tvalid_1's l1: 0.0324554\n",
      "Early stopping, best iteration is:\n",
      "[500]\ttraining's l1: 0.0307116\tvalid_1's l1: 0.0324554\n",
      "cv score is 0.03245544016507444\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.002174\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0308804\tvalid_1's l1: 0.0318579\n",
      "Early stopping, best iteration is:\n",
      "[489]\ttraining's l1: 0.0309275\tvalid_1's l1: 0.0318552\n",
      "cv score is 0.03185520490336907\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.001570\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0305151\tvalid_1's l1: 0.0327475\n",
      "[1000]\ttraining's l1: 0.0287644\tvalid_1's l1: 0.0326401\n",
      "Early stopping, best iteration is:\n",
      "[979]\ttraining's l1: 0.0288204\tvalid_1's l1: 0.0326363\n",
      "cv score is 0.03263633426217403\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.001818\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0307396\tvalid_1's l1: 0.032082\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's l1: 0.0303806\tvalid_1's l1: 0.032057\n",
      "cv score is 0.032056982935274904\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.002743\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0304131\tvalid_1's l1: 0.0333891\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttraining's l1: 0.0301686\tvalid_1's l1: 0.0333535\n",
      "cv score is 0.03335351742104342\n",
      "OOF score is 0.032471495567191144\n",
      "==================================================\n",
      "# z_0\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.001250\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's l1: 0.0256038\tvalid_1's l1: 0.0258892\n",
      "cv score is 0.02588920730274222\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.001410\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's l1: 0.0253277\tvalid_1's l1: 0.0254086\n",
      "cv score is 0.02540860631574023\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.001091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttraining's l1: 0.0250105\tvalid_1's l1: 0.026369\n",
      "cv score is 0.02636904293912517\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.001247\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\ttraining's l1: 0.024897\tvalid_1's l1: 0.0263989\n",
      "cv score is 0.026398934698818315\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.001238\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttraining's l1: 0.0255374\tvalid_1's l1: 0.0257205\n",
      "cv score is 0.02572049707763868\n",
      "OOF score is 0.02595725609778375\n",
      "==================================================\n",
      "# x_1\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 8.674834\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.139292\tvalid_1's l1: 0.142418\n",
      "[1000]\ttraining's l1: 0.121391\tvalid_1's l1: 0.131202\n",
      "Early stopping, best iteration is:\n",
      "[1025]\ttraining's l1: 0.121077\tvalid_1's l1: 0.13119\n",
      "cv score is 0.1311897119945277\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 8.722931\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.138707\tvalid_1's l1: 0.14244\n",
      "[1000]\ttraining's l1: 0.121309\tvalid_1's l1: 0.13109\n",
      "[1500]\ttraining's l1: 0.116013\tvalid_1's l1: 0.130892\n",
      "Early stopping, best iteration is:\n",
      "[1601]\ttraining's l1: 0.115065\tvalid_1's l1: 0.130861\n",
      "cv score is 0.1308615023170091\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 8.678675\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.138292\tvalid_1's l1: 0.14591\n",
      "[1000]\ttraining's l1: 0.120523\tvalid_1's l1: 0.133963\n",
      "Early stopping, best iteration is:\n",
      "[1340]\ttraining's l1: 0.116721\tvalid_1's l1: 0.13358\n",
      "cv score is 0.1335800987027015\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 8.663290\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.13918\tvalid_1's l1: 0.144055\n",
      "[1000]\ttraining's l1: 0.121382\tvalid_1's l1: 0.131003\n",
      "Early stopping, best iteration is:\n",
      "[1172]\ttraining's l1: 0.119368\tvalid_1's l1: 0.130917\n",
      "cv score is 0.1309170621318329\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 8.732202\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.13831\tvalid_1's l1: 0.146012\n",
      "[1000]\ttraining's l1: 0.120578\tvalid_1's l1: 0.134448\n",
      "[1500]\ttraining's l1: 0.115243\tvalid_1's l1: 0.133935\n",
      "Early stopping, best iteration is:\n",
      "[1561]\ttraining's l1: 0.114666\tvalid_1's l1: 0.133919\n",
      "cv score is 0.13391927138676596\n",
      "OOF score is 0.13209350846735893\n",
      "==================================================\n",
      "# y_1\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003005\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0701119\tvalid_1's l1: 0.074653\n",
      "[1000]\ttraining's l1: 0.0655073\tvalid_1's l1: 0.0740714\n",
      "[1500]\ttraining's l1: 0.0620515\tvalid_1's l1: 0.0739204\n",
      "Early stopping, best iteration is:\n",
      "[1431]\ttraining's l1: 0.0624875\tvalid_1's l1: 0.0739138\n",
      "cv score is 0.07391383688212196\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.005267\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0706989\tvalid_1's l1: 0.0728129\n",
      "[1000]\ttraining's l1: 0.0662331\tvalid_1's l1: 0.0724107\n",
      "Early stopping, best iteration is:\n",
      "[1141]\ttraining's l1: 0.0652132\tvalid_1's l1: 0.0723562\n",
      "cv score is 0.07235618729318122\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003145\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0699697\tvalid_1's l1: 0.0756635\n",
      "[1000]\ttraining's l1: 0.0654469\tvalid_1's l1: 0.075026\n",
      "Early stopping, best iteration is:\n",
      "[1054]\ttraining's l1: 0.0650089\tvalid_1's l1: 0.0749929\n",
      "cv score is 0.07499292310980984\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.004260\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0702011\tvalid_1's l1: 0.0742335\n",
      "[1000]\ttraining's l1: 0.0656343\tvalid_1's l1: 0.0734979\n",
      "[1500]\ttraining's l1: 0.0621245\tvalid_1's l1: 0.0731866\n",
      "Early stopping, best iteration is:\n",
      "[1777]\ttraining's l1: 0.0604832\tvalid_1's l1: 0.0731486\n",
      "cv score is 0.07314856130551695\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.006705\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0698056\tvalid_1's l1: 0.0764661\n",
      "[1000]\ttraining's l1: 0.0655229\tvalid_1's l1: 0.0754481\n",
      "[1500]\ttraining's l1: 0.0620961\tvalid_1's l1: 0.0749553\n",
      "[2000]\ttraining's l1: 0.0592532\tvalid_1's l1: 0.0748606\n",
      "Early stopping, best iteration is:\n",
      "[1901]\ttraining's l1: 0.0597706\tvalid_1's l1: 0.0748572\n",
      "cv score is 0.07485720511788291\n",
      "OOF score is 0.07385374412728604\n",
      "==================================================\n",
      "# z_1\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.002724\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's l1: 0.0535698\tvalid_1's l1: 0.054012\n",
      "cv score is 0.05401195094289263\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.002878\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.051228\tvalid_1's l1: 0.0526739\n",
      "Early stopping, best iteration is:\n",
      "[459]\ttraining's l1: 0.0514308\tvalid_1's l1: 0.052665\n",
      "cv score is 0.05266496170136376\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.002391\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttraining's l1: 0.0521656\tvalid_1's l1: 0.0546381\n",
      "cv score is 0.0546380745979585\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.002518\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[329]\ttraining's l1: 0.0515819\tvalid_1's l1: 0.0552798\n",
      "cv score is 0.05527978100640745\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.002578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\ttraining's l1: 0.0529665\tvalid_1's l1: 0.0538415\n",
      "cv score is 0.05384147877122223\n",
      "OOF score is 0.05408724766782123\n",
      "==================================================\n",
      "# x_2\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 13.225400\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.237262\tvalid_1's l1: 0.243878\n",
      "[1000]\ttraining's l1: 0.205387\tvalid_1's l1: 0.223166\n",
      "[1500]\ttraining's l1: 0.195644\tvalid_1's l1: 0.222727\n",
      "[2000]\ttraining's l1: 0.18753\tvalid_1's l1: 0.22245\n",
      "Early stopping, best iteration is:\n",
      "[2322]\ttraining's l1: 0.182905\tvalid_1's l1: 0.222276\n",
      "cv score is 0.22227594156590516\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 13.297193\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.235662\tvalid_1's l1: 0.246756\n",
      "[1000]\ttraining's l1: 0.204999\tvalid_1's l1: 0.225963\n",
      "[1500]\ttraining's l1: 0.195391\tvalid_1's l1: 0.224955\n",
      "Early stopping, best iteration is:\n",
      "[1797]\ttraining's l1: 0.190466\tvalid_1's l1: 0.224684\n",
      "cv score is 0.22468445035242102\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 13.232061\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.236127\tvalid_1's l1: 0.248093\n",
      "[1000]\ttraining's l1: 0.205134\tvalid_1's l1: 0.22637\n",
      "[1500]\ttraining's l1: 0.195256\tvalid_1's l1: 0.225314\n",
      "[2000]\ttraining's l1: 0.187152\tvalid_1's l1: 0.225026\n",
      "Early stopping, best iteration is:\n",
      "[1948]\ttraining's l1: 0.187965\tvalid_1's l1: 0.224988\n",
      "cv score is 0.22498771562071726\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 13.207209\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.236914\tvalid_1's l1: 0.24708\n",
      "[1000]\ttraining's l1: 0.205536\tvalid_1's l1: 0.223818\n",
      "[1500]\ttraining's l1: 0.195908\tvalid_1's l1: 0.223202\n",
      "[2000]\ttraining's l1: 0.188022\tvalid_1's l1: 0.223045\n",
      "Early stopping, best iteration is:\n",
      "[1969]\ttraining's l1: 0.188478\tvalid_1's l1: 0.223019\n",
      "cv score is 0.22301943447876496\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 13.313702\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.235396\tvalid_1's l1: 0.250056\n",
      "[1000]\ttraining's l1: 0.204365\tvalid_1's l1: 0.229026\n",
      "[1500]\ttraining's l1: 0.194766\tvalid_1's l1: 0.22791\n",
      "[2000]\ttraining's l1: 0.186679\tvalid_1's l1: 0.227544\n",
      "[2500]\ttraining's l1: 0.179525\tvalid_1's l1: 0.227423\n",
      "Early stopping, best iteration is:\n",
      "[2417]\ttraining's l1: 0.180639\tvalid_1's l1: 0.227374\n",
      "cv score is 0.22737382796555064\n",
      "OOF score is 0.22446822344832315\n",
      "==================================================\n",
      "# y_2\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003715\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.127021\tvalid_1's l1: 0.134388\n",
      "[1000]\ttraining's l1: 0.117897\tvalid_1's l1: 0.132392\n",
      "[1500]\ttraining's l1: 0.111413\tvalid_1's l1: 0.131767\n",
      "[2000]\ttraining's l1: 0.105961\tvalid_1's l1: 0.131389\n",
      "[2500]\ttraining's l1: 0.101064\tvalid_1's l1: 0.13122\n",
      "[3000]\ttraining's l1: 0.096557\tvalid_1's l1: 0.130963\n",
      "[3500]\ttraining's l1: 0.0924801\tvalid_1's l1: 0.130788\n",
      "Early stopping, best iteration is:\n",
      "[3702]\ttraining's l1: 0.0909132\tvalid_1's l1: 0.130737\n",
      "cv score is 0.13073718282946575\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.008631\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.127127\tvalid_1's l1: 0.132579\n",
      "[1000]\ttraining's l1: 0.118276\tvalid_1's l1: 0.131074\n",
      "[1500]\ttraining's l1: 0.111748\tvalid_1's l1: 0.130774\n",
      "Early stopping, best iteration is:\n",
      "[1517]\ttraining's l1: 0.111552\tvalid_1's l1: 0.130747\n",
      "cv score is 0.13074724718031516\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003770\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.126319\tvalid_1's l1: 0.137055\n",
      "[1000]\ttraining's l1: 0.117551\tvalid_1's l1: 0.13505\n",
      "[1500]\ttraining's l1: 0.110966\tvalid_1's l1: 0.134232\n",
      "[2000]\ttraining's l1: 0.105456\tvalid_1's l1: 0.133404\n",
      "Early stopping, best iteration is:\n",
      "[2219]\ttraining's l1: 0.10331\tvalid_1's l1: 0.133337\n",
      "cv score is 0.1333366002357597\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.006516\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.12663\tvalid_1's l1: 0.133963\n",
      "[1000]\ttraining's l1: 0.117972\tvalid_1's l1: 0.131755\n",
      "[1500]\ttraining's l1: 0.111187\tvalid_1's l1: 0.130545\n",
      "[2000]\ttraining's l1: 0.10553\tvalid_1's l1: 0.130104\n",
      "[2500]\ttraining's l1: 0.100411\tvalid_1's l1: 0.129837\n",
      "Early stopping, best iteration is:\n",
      "[2811]\ttraining's l1: 0.0976274\tvalid_1's l1: 0.129759\n",
      "cv score is 0.12975899315550657\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.011157\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.126325\tvalid_1's l1: 0.138093\n",
      "[1000]\ttraining's l1: 0.117591\tvalid_1's l1: 0.135548\n",
      "[1500]\ttraining's l1: 0.111104\tvalid_1's l1: 0.13433\n",
      "[2000]\ttraining's l1: 0.105616\tvalid_1's l1: 0.133715\n",
      "[2500]\ttraining's l1: 0.100706\tvalid_1's l1: 0.133434\n",
      "[3000]\ttraining's l1: 0.0963147\tvalid_1's l1: 0.133252\n",
      "Early stopping, best iteration is:\n",
      "[2977]\ttraining's l1: 0.0965041\tvalid_1's l1: 0.13324\n",
      "cv score is 0.1332401183039319\n",
      "OOF score is 0.13156400927651699\n",
      "==================================================\n",
      "# z_2\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.004213\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's l1: 0.0820126\tvalid_1's l1: 0.0833074\n",
      "cv score is 0.08330741775051619\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.004345\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[330]\ttraining's l1: 0.0805288\tvalid_1's l1: 0.0808572\n",
      "cv score is 0.08085723523307867\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003618\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\ttraining's l1: 0.0802646\tvalid_1's l1: 0.0839329\n",
      "cv score is 0.08393294620608036\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0780586\tvalid_1's l1: 0.0857135\n",
      "Early stopping, best iteration is:\n",
      "[546]\ttraining's l1: 0.0777096\tvalid_1's l1: 0.0857093\n",
      "cv score is 0.08570933795621613\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003851\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[365]\ttraining's l1: 0.0797184\tvalid_1's l1: 0.0831941\n",
      "cv score is 0.08319408412172996\n",
      "OOF score is 0.08340020211415687\n",
      "==================================================\n",
      "# x_3\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 17.761294\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.36929\tvalid_1's l1: 0.379111\n",
      "[1000]\ttraining's l1: 0.319301\tvalid_1's l1: 0.346323\n",
      "[1500]\ttraining's l1: 0.303346\tvalid_1's l1: 0.343973\n",
      "[2000]\ttraining's l1: 0.290464\tvalid_1's l1: 0.343266\n",
      "[2500]\ttraining's l1: 0.278831\tvalid_1's l1: 0.342919\n",
      "Early stopping, best iteration is:\n",
      "[2425]\ttraining's l1: 0.280513\tvalid_1's l1: 0.34288\n",
      "cv score is 0.3428796887922185\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 17.855881\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.365817\tvalid_1's l1: 0.388983\n",
      "[1000]\ttraining's l1: 0.317973\tvalid_1's l1: 0.355255\n",
      "[1500]\ttraining's l1: 0.302194\tvalid_1's l1: 0.35256\n",
      "[2000]\ttraining's l1: 0.289265\tvalid_1's l1: 0.351524\n",
      "[2500]\ttraining's l1: 0.277881\tvalid_1's l1: 0.351007\n",
      "[3000]\ttraining's l1: 0.267255\tvalid_1's l1: 0.350706\n",
      "Early stopping, best iteration is:\n",
      "[3137]\ttraining's l1: 0.26448\tvalid_1's l1: 0.350583\n",
      "cv score is 0.35058273175931537\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 17.771295\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.366898\tvalid_1's l1: 0.389144\n",
      "[1000]\ttraining's l1: 0.318347\tvalid_1's l1: 0.354407\n",
      "[1500]\ttraining's l1: 0.302606\tvalid_1's l1: 0.351776\n",
      "[2000]\ttraining's l1: 0.289696\tvalid_1's l1: 0.350792\n",
      "[2500]\ttraining's l1: 0.278071\tvalid_1's l1: 0.350126\n",
      "[3000]\ttraining's l1: 0.267618\tvalid_1's l1: 0.349892\n",
      "Early stopping, best iteration is:\n",
      "[3064]\ttraining's l1: 0.266301\tvalid_1's l1: 0.349816\n",
      "cv score is 0.3498163651744106\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 17.734461\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.368765\tvalid_1's l1: 0.384282\n",
      "[1000]\ttraining's l1: 0.319827\tvalid_1's l1: 0.349287\n",
      "[1500]\ttraining's l1: 0.303944\tvalid_1's l1: 0.347085\n",
      "[2000]\ttraining's l1: 0.291014\tvalid_1's l1: 0.346574\n",
      "[2500]\ttraining's l1: 0.279324\tvalid_1's l1: 0.345984\n",
      "Early stopping, best iteration is:\n",
      "[2724]\ttraining's l1: 0.274416\tvalid_1's l1: 0.345709\n",
      "cv score is 0.3457088851406353\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 17.879969\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.366395\tvalid_1's l1: 0.390627\n",
      "[1000]\ttraining's l1: 0.317494\tvalid_1's l1: 0.357153\n",
      "[1500]\ttraining's l1: 0.301533\tvalid_1's l1: 0.354536\n",
      "[2000]\ttraining's l1: 0.288627\tvalid_1's l1: 0.353292\n",
      "[2500]\ttraining's l1: 0.277056\tvalid_1's l1: 0.35287\n",
      "Early stopping, best iteration is:\n",
      "[2552]\ttraining's l1: 0.275923\tvalid_1's l1: 0.352824\n",
      "cv score is 0.352823590806631\n",
      "OOF score is 0.3483621259238252\n",
      "==================================================\n",
      "# y_3\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003849\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.210784\tvalid_1's l1: 0.221253\n",
      "[1000]\ttraining's l1: 0.195444\tvalid_1's l1: 0.216979\n",
      "[1500]\ttraining's l1: 0.183893\tvalid_1's l1: 0.214433\n",
      "[2000]\ttraining's l1: 0.174619\tvalid_1's l1: 0.213427\n",
      "[2500]\ttraining's l1: 0.166277\tvalid_1's l1: 0.213048\n",
      "Early stopping, best iteration is:\n",
      "[2671]\ttraining's l1: 0.163454\tvalid_1's l1: 0.212833\n",
      "cv score is 0.212833091508872\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.012601\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.209615\tvalid_1's l1: 0.222155\n",
      "[1000]\ttraining's l1: 0.193997\tvalid_1's l1: 0.218138\n",
      "[1500]\ttraining's l1: 0.183062\tvalid_1's l1: 0.217147\n",
      "[2000]\ttraining's l1: 0.173751\tvalid_1's l1: 0.216668\n",
      "Early stopping, best iteration is:\n",
      "[2097]\ttraining's l1: 0.172064\tvalid_1's l1: 0.216606\n",
      "cv score is 0.216606438599222\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003681\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.208746\tvalid_1's l1: 0.225905\n",
      "[1000]\ttraining's l1: 0.193796\tvalid_1's l1: 0.222361\n",
      "[1500]\ttraining's l1: 0.182629\tvalid_1's l1: 0.220553\n",
      "[2000]\ttraining's l1: 0.173277\tvalid_1's l1: 0.219238\n",
      "[2500]\ttraining's l1: 0.164863\tvalid_1's l1: 0.218276\n",
      "[3000]\ttraining's l1: 0.157314\tvalid_1's l1: 0.217925\n",
      "Early stopping, best iteration is:\n",
      "[3344]\ttraining's l1: 0.152828\tvalid_1's l1: 0.217748\n",
      "cv score is 0.21774753527585436\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.008695\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.209773\tvalid_1's l1: 0.22248\n",
      "[1000]\ttraining's l1: 0.19449\tvalid_1's l1: 0.218167\n",
      "[1500]\ttraining's l1: 0.183219\tvalid_1's l1: 0.215982\n",
      "[2000]\ttraining's l1: 0.174084\tvalid_1's l1: 0.215033\n",
      "[2500]\ttraining's l1: 0.165643\tvalid_1's l1: 0.214456\n",
      "[3000]\ttraining's l1: 0.158138\tvalid_1's l1: 0.214162\n",
      "[3500]\ttraining's l1: 0.151404\tvalid_1's l1: 0.21394\n",
      "Early stopping, best iteration is:\n",
      "[3472]\ttraining's l1: 0.15178\tvalid_1's l1: 0.213908\n",
      "cv score is 0.21390837876273963\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.016180\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.208624\tvalid_1's l1: 0.229614\n",
      "[1000]\ttraining's l1: 0.193039\tvalid_1's l1: 0.223778\n",
      "[1500]\ttraining's l1: 0.18234\tvalid_1's l1: 0.221608\n",
      "[2000]\ttraining's l1: 0.172963\tvalid_1's l1: 0.220145\n",
      "[2500]\ttraining's l1: 0.164724\tvalid_1's l1: 0.219365\n",
      "[3000]\ttraining's l1: 0.15742\tvalid_1's l1: 0.218995\n",
      "Early stopping, best iteration is:\n",
      "[3080]\ttraining's l1: 0.156299\tvalid_1's l1: 0.218949\n",
      "cv score is 0.21894908563586415\n",
      "OOF score is 0.21600883273213362\n",
      "==================================================\n",
      "# z_3\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.005641\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's l1: 0.110937\tvalid_1's l1: 0.113782\n",
      "cv score is 0.11378189655556183\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.005744\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.108225\tvalid_1's l1: 0.110664\n",
      "Early stopping, best iteration is:\n",
      "[498]\ttraining's l1: 0.108245\tvalid_1's l1: 0.110662\n",
      "cv score is 0.1106624449835699\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.004722\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[316]\ttraining's l1: 0.109332\tvalid_1's l1: 0.114411\n",
      "cv score is 0.11441081331497843\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.005164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[382]\ttraining's l1: 0.108037\tvalid_1's l1: 0.116822\n",
      "cv score is 0.11682230146589638\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.004843\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[360]\ttraining's l1: 0.108963\tvalid_1's l1: 0.114508\n",
      "cv score is 0.11450829551156035\n",
      "OOF score is 0.11403714448095656\n",
      "==================================================\n",
      "# x_4\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 22.281278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.532708\tvalid_1's l1: 0.547244\n",
      "[1000]\ttraining's l1: 0.460652\tvalid_1's l1: 0.498474\n",
      "[1500]\ttraining's l1: 0.437055\tvalid_1's l1: 0.495183\n",
      "[2000]\ttraining's l1: 0.417826\tvalid_1's l1: 0.493744\n",
      "[2500]\ttraining's l1: 0.400582\tvalid_1's l1: 0.492853\n",
      "Early stopping, best iteration is:\n",
      "[2521]\ttraining's l1: 0.399892\tvalid_1's l1: 0.49283\n",
      "cv score is 0.4928297952382882\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 22.397930\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.527455\tvalid_1's l1: 0.56509\n",
      "[1000]\ttraining's l1: 0.458029\tvalid_1's l1: 0.515162\n",
      "[1500]\ttraining's l1: 0.434422\tvalid_1's l1: 0.509611\n",
      "[2000]\ttraining's l1: 0.415152\tvalid_1's l1: 0.506662\n",
      "[2500]\ttraining's l1: 0.398289\tvalid_1's l1: 0.505227\n",
      "[3000]\ttraining's l1: 0.382962\tvalid_1's l1: 0.504553\n",
      "[3500]\ttraining's l1: 0.36901\tvalid_1's l1: 0.50419\n",
      "Early stopping, best iteration is:\n",
      "[3710]\ttraining's l1: 0.363349\tvalid_1's l1: 0.503894\n",
      "cv score is 0.5038935432579704\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 22.295103\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.529389\tvalid_1's l1: 0.564053\n",
      "[1000]\ttraining's l1: 0.459626\tvalid_1's l1: 0.51223\n",
      "[1500]\ttraining's l1: 0.435695\tvalid_1's l1: 0.508533\n",
      "[2000]\ttraining's l1: 0.416107\tvalid_1's l1: 0.506821\n",
      "[2500]\ttraining's l1: 0.399219\tvalid_1's l1: 0.505854\n",
      "Early stopping, best iteration is:\n",
      "[2880]\ttraining's l1: 0.387137\tvalid_1's l1: 0.505413\n",
      "cv score is 0.5054126806379361\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 22.245544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.531915\tvalid_1's l1: 0.557058\n",
      "[1000]\ttraining's l1: 0.460804\tvalid_1's l1: 0.507986\n",
      "[1500]\ttraining's l1: 0.436526\tvalid_1's l1: 0.502919\n",
      "[2000]\ttraining's l1: 0.417076\tvalid_1's l1: 0.500729\n",
      "Early stopping, best iteration is:\n",
      "[2236]\ttraining's l1: 0.408726\tvalid_1's l1: 0.499929\n",
      "cv score is 0.4999289711858057\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 22.431070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.529092\tvalid_1's l1: 0.563558\n",
      "[1000]\ttraining's l1: 0.45873\tvalid_1's l1: 0.515621\n",
      "[1500]\ttraining's l1: 0.434813\tvalid_1's l1: 0.510453\n",
      "[2000]\ttraining's l1: 0.414701\tvalid_1's l1: 0.507765\n",
      "[2500]\ttraining's l1: 0.397033\tvalid_1's l1: 0.506313\n",
      "[3000]\ttraining's l1: 0.381165\tvalid_1's l1: 0.505263\n",
      "[3500]\ttraining's l1: 0.367129\tvalid_1's l1: 0.504166\n",
      "Early stopping, best iteration is:\n",
      "[3636]\ttraining's l1: 0.363416\tvalid_1's l1: 0.503929\n",
      "cv score is 0.5039285222475316\n",
      "OOF score is 0.5011985095526046\n",
      "==================================================\n",
      "# y_4\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.003306\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.325321\tvalid_1's l1: 0.340603\n",
      "[1000]\ttraining's l1: 0.301048\tvalid_1's l1: 0.333129\n",
      "[1500]\ttraining's l1: 0.282661\tvalid_1's l1: 0.328988\n",
      "[2000]\ttraining's l1: 0.268236\tvalid_1's l1: 0.326997\n",
      "[2500]\ttraining's l1: 0.255744\tvalid_1's l1: 0.326154\n",
      "[3000]\ttraining's l1: 0.2448\tvalid_1's l1: 0.325739\n",
      "Early stopping, best iteration is:\n",
      "[3391]\ttraining's l1: 0.236989\tvalid_1's l1: 0.325506\n",
      "cv score is 0.3255059754542149\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.017119\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.321378\tvalid_1's l1: 0.345582\n",
      "[1000]\ttraining's l1: 0.296951\tvalid_1's l1: 0.338584\n",
      "[1500]\ttraining's l1: 0.280382\tvalid_1's l1: 0.336744\n",
      "[2000]\ttraining's l1: 0.266554\tvalid_1's l1: 0.336078\n",
      "[2500]\ttraining's l1: 0.253904\tvalid_1's l1: 0.335672\n",
      "Early stopping, best iteration is:\n",
      "[2427]\ttraining's l1: 0.255595\tvalid_1's l1: 0.3356\n",
      "cv score is 0.33560016236746687\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.002972\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.321215\tvalid_1's l1: 0.34684\n",
      "[1000]\ttraining's l1: 0.296774\tvalid_1's l1: 0.34041\n",
      "[1500]\ttraining's l1: 0.279623\tvalid_1's l1: 0.338354\n",
      "[2000]\ttraining's l1: 0.265698\tvalid_1's l1: 0.336943\n",
      "[2500]\ttraining's l1: 0.25336\tvalid_1's l1: 0.335701\n",
      "[3000]\ttraining's l1: 0.241903\tvalid_1's l1: 0.3346\n",
      "[3500]\ttraining's l1: 0.231904\tvalid_1's l1: 0.334292\n",
      "Early stopping, best iteration is:\n",
      "[3531]\ttraining's l1: 0.231344\tvalid_1's l1: 0.334261\n",
      "cv score is 0.3342613584380658\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.010795\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.323272\tvalid_1's l1: 0.342249\n",
      "[1000]\ttraining's l1: 0.299081\tvalid_1's l1: 0.334696\n",
      "[1500]\ttraining's l1: 0.280668\tvalid_1's l1: 0.330784\n",
      "[2000]\ttraining's l1: 0.265955\tvalid_1's l1: 0.329042\n",
      "[2500]\ttraining's l1: 0.253556\tvalid_1's l1: 0.328358\n",
      "[3000]\ttraining's l1: 0.242307\tvalid_1's l1: 0.327814\n",
      "Early stopping, best iteration is:\n",
      "[3372]\ttraining's l1: 0.234391\tvalid_1's l1: 0.327551\n",
      "cv score is 0.3275512045882901\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.021601\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.320749\tvalid_1's l1: 0.355314\n",
      "[1000]\ttraining's l1: 0.296475\tvalid_1's l1: 0.345693\n",
      "[1500]\ttraining's l1: 0.278991\tvalid_1's l1: 0.34173\n",
      "[2000]\ttraining's l1: 0.264976\tvalid_1's l1: 0.340233\n",
      "[2500]\ttraining's l1: 0.252615\tvalid_1's l1: 0.339204\n",
      "[3000]\ttraining's l1: 0.241397\tvalid_1's l1: 0.338513\n",
      "Early stopping, best iteration is:\n",
      "[3163]\ttraining's l1: 0.238064\tvalid_1's l1: 0.338455\n",
      "cv score is 0.3384549295478204\n",
      "OOF score is 0.3322745700128918\n",
      "==================================================\n",
      "# z_4\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.006538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[318]\ttraining's l1: 0.14043\tvalid_1's l1: 0.145592\n",
      "cv score is 0.14559239304065946\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.006756\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.138339\tvalid_1's l1: 0.142198\n",
      "Early stopping, best iteration is:\n",
      "[665]\ttraining's l1: 0.136138\tvalid_1's l1: 0.142151\n",
      "cv score is 0.14215066098022677\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.005414\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[387]\ttraining's l1: 0.138916\tvalid_1's l1: 0.146174\n",
      "cv score is 0.14617405726803318\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.005935\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.136559\tvalid_1's l1: 0.149245\n",
      "Early stopping, best iteration is:\n",
      "[669]\ttraining's l1: 0.134298\tvalid_1's l1: 0.149218\n",
      "cv score is 0.149217614616806\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.005418\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.137159\tvalid_1's l1: 0.146188\n",
      "Early stopping, best iteration is:\n",
      "[465]\ttraining's l1: 0.137695\tvalid_1's l1: 0.146148\n",
      "cv score is 0.1461477837392826\n",
      "OOF score is 0.1458564958394743\n",
      "==================================================\n",
      "# x_5\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 26.784090\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.721718\tvalid_1's l1: 0.742238\n",
      "[1000]\ttraining's l1: 0.623415\tvalid_1's l1: 0.675048\n",
      "[1500]\ttraining's l1: 0.589536\tvalid_1's l1: 0.667817\n",
      "[2000]\ttraining's l1: 0.562928\tvalid_1's l1: 0.665472\n",
      "[2500]\ttraining's l1: 0.538657\tvalid_1's l1: 0.664008\n",
      "Early stopping, best iteration is:\n",
      "[2577]\ttraining's l1: 0.535245\tvalid_1's l1: 0.663913\n",
      "cv score is 0.6639129804098716\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 26.922501\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.714657\tvalid_1's l1: 0.769647\n",
      "[1000]\ttraining's l1: 0.618679\tvalid_1's l1: 0.699285\n",
      "[1500]\ttraining's l1: 0.585524\tvalid_1's l1: 0.690325\n",
      "[2000]\ttraining's l1: 0.558952\tvalid_1's l1: 0.685732\n",
      "[2500]\ttraining's l1: 0.535755\tvalid_1's l1: 0.68316\n",
      "[3000]\ttraining's l1: 0.515051\tvalid_1's l1: 0.681469\n",
      "[3500]\ttraining's l1: 0.495768\tvalid_1's l1: 0.680805\n",
      "[4000]\ttraining's l1: 0.47834\tvalid_1's l1: 0.680479\n",
      "Early stopping, best iteration is:\n",
      "[3919]\ttraining's l1: 0.481057\tvalid_1's l1: 0.680433\n",
      "cv score is 0.6804328611043338\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 26.802501\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.717825\tvalid_1's l1: 0.764274\n",
      "[1000]\ttraining's l1: 0.621513\tvalid_1's l1: 0.692951\n",
      "[1500]\ttraining's l1: 0.586601\tvalid_1's l1: 0.684764\n",
      "[2000]\ttraining's l1: 0.559003\tvalid_1's l1: 0.681354\n",
      "[2500]\ttraining's l1: 0.535799\tvalid_1's l1: 0.679336\n",
      "Early stopping, best iteration is:\n",
      "[2615]\ttraining's l1: 0.530859\tvalid_1's l1: 0.679191\n",
      "cv score is 0.6791908672004081\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 26.738604\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.720539\tvalid_1's l1: 0.757565\n",
      "[1000]\ttraining's l1: 0.623057\tvalid_1's l1: 0.689942\n",
      "[1500]\ttraining's l1: 0.588628\tvalid_1's l1: 0.681839\n",
      "[2000]\ttraining's l1: 0.56174\tvalid_1's l1: 0.678941\n",
      "[2500]\ttraining's l1: 0.537963\tvalid_1's l1: 0.677089\n",
      "Early stopping, best iteration is:\n",
      "[2891]\ttraining's l1: 0.521193\tvalid_1's l1: 0.676037\n",
      "cv score is 0.6760371416256992\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 26.965337\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.71671\tvalid_1's l1: 0.763111\n",
      "[1000]\ttraining's l1: 0.619292\tvalid_1's l1: 0.69582\n",
      "[1500]\ttraining's l1: 0.584924\tvalid_1's l1: 0.688188\n",
      "[2000]\ttraining's l1: 0.556788\tvalid_1's l1: 0.684646\n",
      "[2500]\ttraining's l1: 0.533624\tvalid_1's l1: 0.682302\n",
      "[3000]\ttraining's l1: 0.512542\tvalid_1's l1: 0.681262\n",
      "[3500]\ttraining's l1: 0.493412\tvalid_1's l1: 0.680767\n",
      "[4000]\ttraining's l1: 0.475375\tvalid_1's l1: 0.679906\n",
      "Early stopping, best iteration is:\n",
      "[4129]\ttraining's l1: 0.470994\tvalid_1's l1: 0.679736\n",
      "cv score is 0.6797360730391231\n",
      "OOF score is 0.6758617091691138\n",
      "==================================================\n",
      "# y_5\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.002490\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.472504\tvalid_1's l1: 0.492222\n",
      "[1000]\ttraining's l1: 0.435754\tvalid_1's l1: 0.480546\n",
      "[1500]\ttraining's l1: 0.409145\tvalid_1's l1: 0.474593\n",
      "[2000]\ttraining's l1: 0.387642\tvalid_1's l1: 0.471672\n",
      "[2500]\ttraining's l1: 0.369855\tvalid_1's l1: 0.470233\n",
      "[3000]\ttraining's l1: 0.353655\tvalid_1's l1: 0.468892\n",
      "[3500]\ttraining's l1: 0.339287\tvalid_1's l1: 0.468186\n",
      "Early stopping, best iteration is:\n",
      "[3641]\ttraining's l1: 0.335465\tvalid_1's l1: 0.468062\n",
      "cv score is 0.46806169439314554\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.022428\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.46501\tvalid_1's l1: 0.501739\n",
      "[1000]\ttraining's l1: 0.428779\tvalid_1's l1: 0.491203\n",
      "[1500]\ttraining's l1: 0.403605\tvalid_1's l1: 0.488092\n",
      "[2000]\ttraining's l1: 0.383289\tvalid_1's l1: 0.486697\n",
      "Early stopping, best iteration is:\n",
      "[2214]\ttraining's l1: 0.375279\tvalid_1's l1: 0.486284\n",
      "cv score is 0.4862840754751346\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.001972\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.465965\tvalid_1's l1: 0.504003\n",
      "[1000]\ttraining's l1: 0.429657\tvalid_1's l1: 0.49345\n",
      "[1500]\ttraining's l1: 0.404376\tvalid_1's l1: 0.490211\n",
      "[2000]\ttraining's l1: 0.383452\tvalid_1's l1: 0.487926\n",
      "[2500]\ttraining's l1: 0.364806\tvalid_1's l1: 0.486602\n",
      "[3000]\ttraining's l1: 0.348688\tvalid_1's l1: 0.485677\n",
      "Early stopping, best iteration is:\n",
      "[3020]\ttraining's l1: 0.34807\tvalid_1's l1: 0.485669\n",
      "cv score is 0.48566936955740925\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.013295\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.468018\tvalid_1's l1: 0.496667\n",
      "[1000]\ttraining's l1: 0.431605\tvalid_1's l1: 0.485241\n",
      "[1500]\ttraining's l1: 0.403924\tvalid_1's l1: 0.478301\n",
      "[2000]\ttraining's l1: 0.382206\tvalid_1's l1: 0.475201\n",
      "[2500]\ttraining's l1: 0.364034\tvalid_1's l1: 0.474368\n",
      "Early stopping, best iteration is:\n",
      "[2441]\ttraining's l1: 0.36602\tvalid_1's l1: 0.47428\n",
      "cv score is 0.4742801963298678\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.027634\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.463571\tvalid_1's l1: 0.516315\n",
      "[1000]\ttraining's l1: 0.427137\tvalid_1's l1: 0.502439\n",
      "[1500]\ttraining's l1: 0.40153\tvalid_1's l1: 0.496985\n",
      "[2000]\ttraining's l1: 0.381574\tvalid_1's l1: 0.494422\n",
      "[2500]\ttraining's l1: 0.363713\tvalid_1's l1: 0.492739\n",
      "[3000]\ttraining's l1: 0.347849\tvalid_1's l1: 0.491617\n",
      "[3500]\ttraining's l1: 0.33321\tvalid_1's l1: 0.490911\n",
      "Early stopping, best iteration is:\n",
      "[3609]\ttraining's l1: 0.330124\tvalid_1's l1: 0.490833\n",
      "cv score is 0.4908325336067211\n",
      "OOF score is 0.48102527496582503\n",
      "==================================================\n",
      "# z_5\n",
      "==================================================\n",
      "====== fold 0 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10770\n",
      "[LightGBM] [Info] Number of data points in the train set: 34696, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.007355\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[274]\ttraining's l1: 0.173477\tvalid_1's l1: 0.179187\n",
      "cv score is 0.17918684510977315\n",
      "====== fold 1 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10758\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.007570\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.169796\tvalid_1's l1: 0.175431\n",
      "Early stopping, best iteration is:\n",
      "[546]\ttraining's l1: 0.16899\tvalid_1's l1: 0.175393\n",
      "cv score is 0.17539309642803322\n",
      "====== fold 2 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10765\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.005974\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[355]\ttraining's l1: 0.171363\tvalid_1's l1: 0.179699\n",
      "cv score is 0.17969922494504786\n",
      "====== fold 3 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10767\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.006465\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.167933\tvalid_1's l1: 0.182638\n",
      "Early stopping, best iteration is:\n",
      "[672]\ttraining's l1: 0.165011\tvalid_1's l1: 0.182524\n",
      "cv score is 0.18252378361832466\n",
      "====== fold 4 ======\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10768\n",
      "[LightGBM] [Info] Number of data points in the train set: 34697, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score 0.005875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.16863\tvalid_1's l1: 0.179246\n",
      "Early stopping, best iteration is:\n",
      "[409]\ttraining's l1: 0.170329\tvalid_1's l1: 0.179196\n",
      "cv score is 0.17919619538477766\n",
      "OOF score is 0.17919982879782104\n"
     ]
    }
   ],
   "source": [
    "models_dict = {}\n",
    "test_pred = []\n",
    "oof_pred = []\n",
    "for target in targets:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"# {target}\")\n",
    "    print(\"=\" * 50)\n",
    "    oof_preds_partial, y_pred_partial, models_partial = train_lgbm(target)\n",
    "    models_dict[target] = models_partial\n",
    "    oof_pred.append(oof_preds_partial)\n",
    "    test_pred.append(y_pred_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21186988373314944"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(train_df[targets].to_numpy(), np.vstack(oof_pred).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit ファイル作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_727, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.452</td><td>-0.051075</td><td>0.002421</td><td>3.027946</td><td>-0.116247</td><td>0.004716</td><td>4.542092</td><td>-0.196589</td><td>0.002783</td><td>5.820129</td><td>-0.206179</td><td>0.006065</td><td>7.303749</td><td>-0.120701</td><td>-0.00574</td><td>8.58239</td><td>-0.002586</td><td>-0.003567</td></tr><tr><td>0.943627</td><td>0.388967</td><td>-0.000332</td><td>1.743524</td><td>1.003402</td><td>-0.002867</td><td>2.383782</td><td>1.784852</td><td>-0.008241</td><td>2.763791</td><td>2.616801</td><td>-0.010621</td><td>3.510101</td><td>3.57755</td><td>-0.007471</td><td>4.336799</td><td>4.561304</td><td>0.00061</td></tr><tr><td>1.570422</td><td>0.015986</td><td>0.003822</td><td>3.261026</td><td>0.018118</td><td>0.007293</td><td>4.878632</td><td>0.045818</td><td>0.012156</td><td>6.334183</td><td>0.053155</td><td>0.012668</td><td>7.705174</td><td>0.133657</td><td>0.015786</td><td>8.983753</td><td>0.197793</td><td>0.021751</td></tr><tr><td>0.834648</td><td>0.064968</td><td>-0.001378</td><td>1.650741</td><td>0.222793</td><td>-0.007244</td><td>2.395832</td><td>0.551637</td><td>-0.012376</td><td>2.972891</td><td>0.862205</td><td>-0.019565</td><td>3.614984</td><td>1.525669</td><td>-0.020303</td><td>4.288629</td><td>2.244859</td><td>-0.016445</td></tr><tr><td>0.817229</td><td>0.004749</td><td>-0.001958</td><td>1.415719</td><td>0.003632</td><td>-0.004848</td><td>1.88172</td><td>-0.000778</td><td>-0.017307</td><td>2.279591</td><td>-0.000394</td><td>-0.037908</td><td>2.172891</td><td>-0.006109</td><td>-0.054472</td><td>1.701601</td><td>-0.021984</td><td>-0.069277</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6.536803</td><td>0.0093</td><td>0.017814</td><td>13.803687</td><td>0.048903</td><td>0.039918</td><td>21.004206</td><td>0.132271</td><td>0.065576</td><td>28.269154</td><td>0.221015</td><td>0.074146</td><td>35.556397</td><td>0.329059</td><td>0.080613</td><td>43.086334</td><td>0.45282</td><td>0.070313</td></tr><tr><td>7.000525</td><td>0.001282</td><td>0.004376</td><td>14.891301</td><td>-0.010288</td><td>0.008306</td><td>22.94336</td><td>-0.027871</td><td>0.013072</td><td>31.100466</td><td>-0.065433</td><td>0.023533</td><td>39.291845</td><td>-0.101419</td><td>0.03069</td><td>47.540539</td><td>-0.134003</td><td>0.037108</td></tr><tr><td>7.416801</td><td>-0.000922</td><td>0.007232</td><td>15.665297</td><td>-0.021446</td><td>0.011933</td><td>23.896645</td><td>-0.053737</td><td>0.023101</td><td>32.061631</td><td>-0.118897</td><td>0.047292</td><td>40.141177</td><td>-0.191456</td><td>0.077168</td><td>48.077369</td><td>-0.264317</td><td>0.090351</td></tr><tr><td>6.524221</td><td>-0.000094</td><td>-0.002052</td><td>13.669287</td><td>-0.009337</td><td>-0.004904</td><td>20.767913</td><td>-0.008719</td><td>-0.008711</td><td>27.829623</td><td>-0.008356</td><td>-0.012927</td><td>34.828611</td><td>-0.019157</td><td>-0.015463</td><td>41.833203</td><td>0.015961</td><td>-0.015824</td></tr><tr><td>5.814603</td><td>-0.249396</td><td>0.008767</td><td>12.32655</td><td>-1.047688</td><td>0.012369</td><td>18.931383</td><td>-2.350465</td><td>0.016102</td><td>25.548215</td><td>-4.134085</td><td>0.00558</td><td>32.053228</td><td>-6.220877</td><td>-0.047109</td><td>38.515141</td><td>-8.547035</td><td>-0.117428</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_727, 18)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ x_0      ┆ y_0       ┆ z_0       ┆ x_1       ┆ … ┆ z_4       ┆ x_5       ┆ y_5       ┆ z_5       │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.452    ┆ -0.051075 ┆ 0.002421  ┆ 3.027946  ┆ … ┆ -0.00574  ┆ 8.58239   ┆ -0.002586 ┆ -0.003567 │\n",
       "│ 0.943627 ┆ 0.388967  ┆ -0.000332 ┆ 1.743524  ┆ … ┆ -0.007471 ┆ 4.336799  ┆ 4.561304  ┆ 0.00061   │\n",
       "│ 1.570422 ┆ 0.015986  ┆ 0.003822  ┆ 3.261026  ┆ … ┆ 0.015786  ┆ 8.983753  ┆ 0.197793  ┆ 0.021751  │\n",
       "│ 0.834648 ┆ 0.064968  ┆ -0.001378 ┆ 1.650741  ┆ … ┆ -0.020303 ┆ 4.288629  ┆ 2.244859  ┆ -0.016445 │\n",
       "│ 0.817229 ┆ 0.004749  ┆ -0.001958 ┆ 1.415719  ┆ … ┆ -0.054472 ┆ 1.701601  ┆ -0.021984 ┆ -0.069277 │\n",
       "│ …        ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 6.536803 ┆ 0.0093    ┆ 0.017814  ┆ 13.803687 ┆ … ┆ 0.080613  ┆ 43.086334 ┆ 0.45282   ┆ 0.070313  │\n",
       "│ 7.000525 ┆ 0.001282  ┆ 0.004376  ┆ 14.891301 ┆ … ┆ 0.03069   ┆ 47.540539 ┆ -0.134003 ┆ 0.037108  │\n",
       "│ 7.416801 ┆ -0.000922 ┆ 0.007232  ┆ 15.665297 ┆ … ┆ 0.077168  ┆ 48.077369 ┆ -0.264317 ┆ 0.090351  │\n",
       "│ 6.524221 ┆ -0.000094 ┆ -0.002052 ┆ 13.669287 ┆ … ┆ -0.015463 ┆ 41.833203 ┆ 0.015961  ┆ -0.015824 │\n",
       "│ 5.814603 ┆ -0.249396 ┆ 0.008767  ┆ 12.32655  ┆ … ┆ -0.047109 ┆ 38.515141 ┆ -8.547035 ┆ -0.117428 │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_col_names = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "sub_df = pl.DataFrame(np.vstack(test_pred).T, schema=sub_col_names)\n",
    "display(sub_df)\n",
    "sub_df.write_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
