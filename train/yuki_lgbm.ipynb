{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/*\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PACKAGE_DIR = \"/kaggle/src\"\n",
    "sys.path.append(PACKAGE_DIR)\n",
    "sys.path.append(os.path.join(PACKAGE_DIR, \"Penguin-ML-Library\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 11:41:29.579204: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 11:41:29.607161: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "set seed: 46\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from penguinml.utils.logger import get_logger, init_logger\n",
    "from penguinml.utils.set_seed import seed_base\n",
    "\n",
    "MODEL_NAME = \"lightgbm\"\n",
    "CFG = yaml.safe_load(open(os.path.join(PACKAGE_DIR, \"config.yaml\"), \"r\"))\n",
    "print(CFG[MODEL_NAME][\"execution\"][\"exp_id\"])\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG[MODEL_NAME]['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "init_logger(f\"{ CFG[MODEL_NAME]['execution']['exp_id']}.log\")\n",
    "logger = get_logger(\"main\")\n",
    "seed_base(CFG[MODEL_NAME][\"execution\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    N_FOLD = 5\n",
    "    RANDOM_SATE = 42\n",
    "\n",
    "\n",
    "NB = \"exp1015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/kaggle\")\n",
    "DATA_DIR = ROOT_DIR / Path(\"input/atmaCup#18_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(DATA_DIR / \"train_features.csv\")\n",
    "test_df = pl.read_csv(DATA_DIR / \"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df と test_dfを結合（特徴量エンジニアリングをしやすくするため）\n",
    "_all_df = pl.concat([train_df, test_df], how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    \"vEgo\",\n",
    "    \"aEgo\",\n",
    "    \"steeringAngleDeg\",\n",
    "    \"steeringTorque\",\n",
    "    \"gas\",\n",
    "]  # 同一シーンから集計する値のカラム名\n",
    "\n",
    "# 同一シーンから特徴量作成\n",
    "exprs = []\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(-1).over(\"scene\").alias(f\"{agg_col}_shift-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(1).over(\"scene\").alias(f\"{agg_col}_shift1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(-1).over(\"scene\").alias(f\"{agg_col}_diff-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値との差分\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(1).over(\"scene\").alias(f\"{agg_col}_diff1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値との差分\n",
    "exprs += [pl.col(agg_col).mean().over(\"scene\").alias(f\"{agg_col}_mean\") for agg_col in agg_cols]  # 同一シーンの平均値\n",
    "exprs += [pl.col(agg_col).std().over(\"scene\").alias(f\"{agg_col}_std\") for agg_col in agg_cols]  # 同一シーンの標準偏差\n",
    "exprs += [pl.col(agg_col).max().over(\"scene\").alias(f\"{agg_col}_max\") for agg_col in agg_cols]  # 同一シーンの最大値\n",
    "exprs += [pl.col(agg_col).min().over(\"scene\").alias(f\"{agg_col}_min\") for agg_col in agg_cols]  # 同一シーンの最小値\n",
    "\n",
    "_all_df = (\n",
    "    _all_df.with_columns(\n",
    "        # ID からシーンとデシ秒を作成\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(0).alias(\"scene\"),\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(1).cast(pl.Int32).alias(\"decisecond\"),\n",
    "    )\n",
    "    .sort(\n",
    "        # shiftと diffが時系列順に並んでいる必要があるためシーンごとに時間軸でソート\n",
    "        \"scene\",\n",
    "        \"decisecond\",\n",
    "    )\n",
    "    .with_columns(exprs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = pl.read_csv(CFG[\"dataset\"][\"train_fold_path\"]).rename({\"sceneID\": \"scene\"})\n",
    "_all_df = _all_df.join(train_folds, how=\"left\", on=\"scene\")\n",
    "# assert train_df[\"fold\"].null_count() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aEgo', 'aEgo_diff-1', 'aEgo_diff1', 'aEgo_max', 'aEgo_mean', 'aEgo_min', 'aEgo_shift-1', 'aEgo_shift1', 'aEgo_std', 'brake', 'brakePressed', 'decisecond', 'fold', 'gas', 'gasPressed', 'gas_diff-1', 'gas_diff1', 'gas_max', 'gas_mean', 'gas_min', 'gas_shift-1', 'gas_shift1', 'gas_std', 'leftBlinker', 'rightBlinker', 'steeringAngleDeg', 'steeringAngleDeg_diff-1', 'steeringAngleDeg_diff1', 'steeringAngleDeg_max', 'steeringAngleDeg_mean', 'steeringAngleDeg_min', 'steeringAngleDeg_shift-1', 'steeringAngleDeg_shift1', 'steeringAngleDeg_std', 'steeringTorque', 'steeringTorque_diff-1', 'steeringTorque_diff1', 'steeringTorque_max', 'steeringTorque_mean', 'steeringTorque_min', 'steeringTorque_shift-1', 'steeringTorque_shift1', 'steeringTorque_std', 'vEgo', 'vEgo_diff-1', 'vEgo_diff1', 'vEgo_max', 'vEgo_mean', 'vEgo_min', 'vEgo_shift-1', 'vEgo_shift1', 'vEgo_std']\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "\n",
    "# 使う特徴量を指定するより使わない特徴量を指定するほうが試行錯誤が楽\n",
    "del_columns = targets + [\"ID\", \"scene\", \"gearShifter\"]\n",
    "\n",
    "features = list(set(_all_df.columns) - set(del_columns))\n",
    "features.sort()\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAEを計算\n",
    "def evaluation(true_values, pred_values):\n",
    "    abs_diff = abs(true_values - pred_values)\n",
    "    mae = np.mean(\n",
    "        abs_diff.reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encdoding\n",
    "categorical_columns = [\"gearShifter\"]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    _all_df = _all_df.with_columns(pl.Series(le.fit_transform(_all_df[col])).alias(f\"{col}_le\"))\n",
    "cate_features = [f\"{col}_le\" for c in categorical_columns]\n",
    "features = list(set(features) | set(cate_features))\n",
    "\n",
    "# count encoding\n",
    "count_enc = [\"gearShifter\"]\n",
    "_all_df = _all_df.with_columns([pl.col(c).count().over(c).alias(f\"{c}_count\") for c in count_enc])\n",
    "count_features = [f\"{c}_count\" for c in count_enc]\n",
    "features = list(set(features) | set(count_features))\n",
    "\n",
    "\n",
    "train_df = train_df.join(_all_df, how=\"left\", on=\"ID\")\n",
    "test_df = test_df.join(_all_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(target):\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"mae\",  # 今回の評価指標がMAEを使用\n",
    "        \"objective\": \"regression\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": Config.RANDOM_SATE,\n",
    "        \"learning_rate\": 0.01,\n",
    "        # \"device\": \"gpu\"\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "\n",
    "    oof_pred = np.zeros(len(train_df))\n",
    "    y_pred = np.zeros(len(test_df))\n",
    "    models = []\n",
    "    cv_scores = {}\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"fold{fold}: \", end=\"\")\n",
    "\n",
    "        # TrainとTestに分割\n",
    "        x_train = train_df.filter(pl.col(\"fold\") != fold).select(features).drop([\"fold\"])\n",
    "        x_val = train_df.filter(pl.col(\"fold\") == fold).select(features).drop([\"fold\"])\n",
    "        y_train = train_df.filter(pl.col(\"fold\") != fold).select(target)\n",
    "        y_val = train_df.filter(pl.col(\"fold\") == fold).select(target)\n",
    "\n",
    "        test = test_df[features]\n",
    "\n",
    "        # create Dataset\n",
    "        train_set = lgb.Dataset(\n",
    "            x_train.to_pandas(),\n",
    "            y_train.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "        val_set = lgb.Dataset(\n",
    "            x_val.to_pandas(),\n",
    "            y_val.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "\n",
    "        # train\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            num_boost_round=10000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "                lgb.log_evaluation(500000),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        fold_pred = model.predict(x_val.to_pandas())\n",
    "\n",
    "        score = evaluation(y_val.to_numpy().reshape(-1), fold_pred)\n",
    "        cv_scores[f\"cv{fold}\"] = score\n",
    "\n",
    "        # oof_pred[test_index] = fold_pred\n",
    "        oof_pred[train_df[\"fold\"].to_numpy() == fold] = fold_pred\n",
    "\n",
    "        y_pred += model.predict(test.drop([\"fold\"]).to_pandas()) / Config.N_FOLD\n",
    "\n",
    "        print(f\"{score}\")\n",
    "\n",
    "    oof_score = evaluation(train_df[target].to_numpy().reshape(-1), oof_pred)\n",
    "    print(f\"OOF score is {oof_score}\")\n",
    "\n",
    "    return oof_pred, y_pred, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "# x_0\n",
      "==================================================\n",
      "fold0: 0.061814169501656906\n",
      "fold1: 0.06044789503792708\n",
      "fold2: 0.06332190411798463\n",
      "fold3: 0.06172711954156965\n",
      "fold4: 0.062372365740872474\n",
      "OOF score is 0.06193668796304339\n",
      "==================================================\n",
      "# y_0\n",
      "==================================================\n",
      "fold0: 0.03245544016507444\n",
      "fold1: 0.03185520490336907\n",
      "fold2: 0.03263411762208743\n",
      "fold3: 0.03205547841499206\n",
      "fold4: 0.03335351742104342\n",
      "OOF score is 0.03247075135227692\n",
      "==================================================\n",
      "# z_0\n",
      "==================================================\n",
      "fold0: 0.025887936299316603\n",
      "fold1: 0.02540527160511098\n",
      "fold2: 0.026368891925292744\n",
      "fold3: 0.02639706753113625\n",
      "fold4: 0.025721373015107796\n",
      "OOF score is 0.025956106503364326\n",
      "==================================================\n",
      "# x_1\n",
      "==================================================\n",
      "fold0: 0.13117405566603507\n",
      "fold1: 0.13086497168094022\n",
      "fold2: 0.13358152683247207\n",
      "fold3: 0.13092803577582302\n",
      "fold4: 0.13391680054839308\n",
      "OOF score is 0.13209305691094148\n",
      "==================================================\n",
      "# y_1\n",
      "==================================================\n",
      "fold0: 0.07391652032527428\n",
      "fold1: 0.07235495449610779\n",
      "fold2: 0.07499963463707451\n",
      "fold3: 0.07314786954132887\n",
      "fold4: 0.07485061458743036\n",
      "OOF score is 0.07385392016084101\n",
      "==================================================\n",
      "# z_1\n",
      "==================================================\n",
      "fold0: 0.05400884903387175\n",
      "fold1: 0.05267174383663384\n",
      "fold2: 0.05463740210261288\n",
      "fold3: 0.0552795651023596\n",
      "fold4: 0.05384142965053619\n",
      "OOF score is 0.05408779612488717\n",
      "==================================================\n",
      "# x_2\n",
      "==================================================\n",
      "fold0: 0.2223233903323274\n",
      "fold1: 0.22469220891916547\n",
      "fold2: 0.22498880357994838\n",
      "fold3: 0.22301568746075795\n",
      "fold4: 0.22737958150731066\n",
      "OOF score is 0.22447988463672228\n",
      "==================================================\n",
      "# y_2\n",
      "==================================================\n",
      "fold0: 0.13074118333772092\n",
      "fold1: 0.13073514109156353\n",
      "fold2: 0.13333347676634733\n",
      "fold3: 0.12976884816669487\n",
      "fold4: 0.13323456757895336\n",
      "OOF score is 0.1315626244479491\n",
      "==================================================\n",
      "# z_2\n",
      "==================================================\n",
      "fold0: 0.08329682034559457\n",
      "fold1: 0.08086083976072778\n",
      "fold2: 0.08393801067853737\n",
      "fold3: 0.08571591928817664\n",
      "fold4: 0.08319467947403957\n",
      "OOF score is 0.08340125150150289\n",
      "==================================================\n",
      "# x_3\n",
      "==================================================\n",
      "fold0: 0.3429085345238358\n",
      "fold1: 0.3505730280054324\n",
      "fold2: 0.34980081930742196\n",
      "fold3: 0.3456940153578039\n",
      "fold4: 0.3528153382161783\n",
      "OOF score is 0.348358221426453\n",
      "==================================================\n",
      "# y_3\n",
      "==================================================\n",
      "fold0: 0.21283333804769033\n",
      "fold1: 0.21659766464748598\n",
      "fold2: 0.21779278781138459\n",
      "fold3: 0.21386636650520838\n",
      "fold4: 0.2189398284866612\n",
      "OOF score is 0.21600592394806287\n",
      "==================================================\n",
      "# z_3\n",
      "==================================================\n",
      "fold0: 0.11376084948942992\n",
      "fold1: 0.11067709304511145\n",
      "fold2: 0.1144107872364372\n",
      "fold3: 0.11682524158421242\n",
      "fold4: 0.11450992196970654\n",
      "OOF score is 0.11403677230291326\n",
      "==================================================\n",
      "# x_4\n",
      "==================================================\n",
      "fold0: 0.49281428774661273\n",
      "fold1: 0.5038637702460509\n",
      "fold2: 0.5053735655382806\n",
      "fold3: 0.4999242639388552\n",
      "fold4: 0.5039223524694059\n",
      "OOF score is 0.5011794551087226\n",
      "==================================================\n",
      "# y_4\n",
      "==================================================\n",
      "fold0: 0.3255099036573157\n",
      "fold1: 0.33559522029604666\n",
      "fold2: 0.33426375315825235\n",
      "fold3: 0.3275457826260913\n",
      "fold4: 0.3384657042715195\n",
      "OOF score is 0.3322759167950861\n",
      "==================================================\n",
      "# z_4\n",
      "==================================================\n",
      "fold0: 0.14558856693473082\n",
      "fold1: 0.1421706141440911\n",
      "fold2: 0.14618013349920816\n",
      "fold3: 0.14921531953526293\n",
      "fold4: 0.1461610383902804\n",
      "OOF score is 0.14586312817004285\n",
      "==================================================\n",
      "# x_5\n",
      "==================================================\n",
      "fold0: 0.6639547003500426\n",
      "fold1: 0.6804070533197889\n",
      "fold2: 0.6791968850245048\n",
      "fold3: 0.6760223721245111\n",
      "fold4: 0.6797428066705609\n",
      "OOF score is 0.6758644888889691\n",
      "==================================================\n",
      "# y_5\n",
      "==================================================\n",
      "fold0: 0.46806165500356567\n",
      "fold1: 0.48624656865617455\n",
      "fold2: 0.48567521447755146\n",
      "fold3: 0.4743040229972198\n",
      "fold4: 0.49079814450851156\n",
      "OOF score is 0.4810168224159596\n",
      "==================================================\n",
      "# z_5\n",
      "==================================================\n",
      "fold0: 0.1791757115537376\n",
      "fold1: 0.17542185773226857\n",
      "fold2: 0.1796999321879072\n",
      "fold3: 0.18253631344253501\n",
      "fold4: 0.17920334793795162\n",
      "OOF score is 0.17920743183949228\n"
     ]
    }
   ],
   "source": [
    "models_dict = {}\n",
    "test_pred = []\n",
    "oof_pred = []\n",
    "for target in targets:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"# {target}\")\n",
    "    print(\"=\" * 50)\n",
    "    oof_preds_partial, y_pred_partial, models_partial = train_lgbm(target)\n",
    "    models_dict[target] = models_partial\n",
    "    oof_pred.append(oof_preds_partial)\n",
    "    test_pred.append(y_pred_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21186945780540176"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(train_df[targets].to_numpy(), np.vstack(oof_pred).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit ファイル作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_727, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.452</td><td>-0.051075</td><td>0.002424</td><td>3.027946</td><td>-0.116615</td><td>0.004675</td><td>4.54256</td><td>-0.196589</td><td>0.002783</td><td>5.820129</td><td>-0.206179</td><td>0.006065</td><td>7.303749</td><td>-0.120701</td><td>-0.004875</td><td>8.58239</td><td>-0.002588</td><td>-0.003567</td></tr><tr><td>0.943627</td><td>0.388967</td><td>-0.000333</td><td>1.743524</td><td>1.00377</td><td>-0.002847</td><td>2.384993</td><td>1.784852</td><td>-0.008241</td><td>2.763791</td><td>2.616801</td><td>-0.010621</td><td>3.510101</td><td>3.57755</td><td>-0.007681</td><td>4.336799</td><td>4.561301</td><td>0.00061</td></tr><tr><td>1.570422</td><td>0.015986</td><td>0.003826</td><td>3.261026</td><td>0.016607</td><td>0.007196</td><td>4.878119</td><td>0.045818</td><td>0.012156</td><td>6.334183</td><td>0.053155</td><td>0.012668</td><td>7.705174</td><td>0.133657</td><td>0.0156</td><td>8.983753</td><td>0.197791</td><td>0.021751</td></tr><tr><td>0.834648</td><td>0.064968</td><td>-0.00139</td><td>1.650741</td><td>0.221638</td><td>-0.00699</td><td>2.396598</td><td>0.551637</td><td>-0.012376</td><td>2.972891</td><td>0.862205</td><td>-0.019565</td><td>3.614984</td><td>1.525669</td><td>-0.020291</td><td>4.288629</td><td>2.244856</td><td>-0.016445</td></tr><tr><td>0.817229</td><td>0.004749</td><td>-0.001976</td><td>1.415719</td><td>0.003891</td><td>-0.004815</td><td>1.881919</td><td>-0.000778</td><td>-0.017307</td><td>2.279591</td><td>-0.000394</td><td>-0.037908</td><td>2.172891</td><td>-0.006109</td><td>-0.054205</td><td>1.701601</td><td>-0.021986</td><td>-0.069277</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6.536803</td><td>0.0093</td><td>0.017823</td><td>13.803687</td><td>0.049009</td><td>0.039545</td><td>21.004637</td><td>0.132271</td><td>0.065576</td><td>28.269154</td><td>0.221015</td><td>0.074146</td><td>35.556963</td><td>0.329059</td><td>0.080569</td><td>43.086334</td><td>0.452818</td><td>0.070313</td></tr><tr><td>7.000525</td><td>0.001282</td><td>0.004378</td><td>14.891301</td><td>-0.009974</td><td>0.008282</td><td>22.943261</td><td>-0.027871</td><td>0.013072</td><td>31.100466</td><td>-0.065433</td><td>0.023533</td><td>39.291845</td><td>-0.101419</td><td>0.03098</td><td>47.540539</td><td>-0.134006</td><td>0.037108</td></tr><tr><td>7.416801</td><td>-0.000922</td><td>0.007246</td><td>15.665297</td><td>-0.021421</td><td>0.011577</td><td>23.896622</td><td>-0.053737</td><td>0.023101</td><td>32.061631</td><td>-0.118897</td><td>0.047292</td><td>40.141177</td><td>-0.191456</td><td>0.077176</td><td>48.077369</td><td>-0.26432</td><td>0.090351</td></tr><tr><td>6.524221</td><td>-0.000094</td><td>-0.002061</td><td>13.669287</td><td>-0.009227</td><td>-0.004767</td><td>20.767928</td><td>-0.008719</td><td>-0.008711</td><td>27.829623</td><td>-0.008356</td><td>-0.012927</td><td>34.828611</td><td>-0.019157</td><td>-0.015435</td><td>41.833203</td><td>0.015958</td><td>-0.015824</td></tr><tr><td>5.814603</td><td>-0.249396</td><td>0.00876</td><td>12.32655</td><td>-1.047948</td><td>0.012275</td><td>18.931334</td><td>-2.350465</td><td>0.016102</td><td>25.548215</td><td>-4.134085</td><td>0.00558</td><td>32.053228</td><td>-6.220877</td><td>-0.046663</td><td>38.515141</td><td>-8.547037</td><td>-0.117428</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_727, 18)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ x_0      ┆ y_0       ┆ z_0       ┆ x_1       ┆ … ┆ z_4       ┆ x_5       ┆ y_5       ┆ z_5       │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.452    ┆ -0.051075 ┆ 0.002424  ┆ 3.027946  ┆ … ┆ -0.004875 ┆ 8.58239   ┆ -0.002588 ┆ -0.003567 │\n",
       "│ 0.943627 ┆ 0.388967  ┆ -0.000333 ┆ 1.743524  ┆ … ┆ -0.007681 ┆ 4.336799  ┆ 4.561301  ┆ 0.00061   │\n",
       "│ 1.570422 ┆ 0.015986  ┆ 0.003826  ┆ 3.261026  ┆ … ┆ 0.0156    ┆ 8.983753  ┆ 0.197791  ┆ 0.021751  │\n",
       "│ 0.834648 ┆ 0.064968  ┆ -0.00139  ┆ 1.650741  ┆ … ┆ -0.020291 ┆ 4.288629  ┆ 2.244856  ┆ -0.016445 │\n",
       "│ 0.817229 ┆ 0.004749  ┆ -0.001976 ┆ 1.415719  ┆ … ┆ -0.054205 ┆ 1.701601  ┆ -0.021986 ┆ -0.069277 │\n",
       "│ …        ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 6.536803 ┆ 0.0093    ┆ 0.017823  ┆ 13.803687 ┆ … ┆ 0.080569  ┆ 43.086334 ┆ 0.452818  ┆ 0.070313  │\n",
       "│ 7.000525 ┆ 0.001282  ┆ 0.004378  ┆ 14.891301 ┆ … ┆ 0.03098   ┆ 47.540539 ┆ -0.134006 ┆ 0.037108  │\n",
       "│ 7.416801 ┆ -0.000922 ┆ 0.007246  ┆ 15.665297 ┆ … ┆ 0.077176  ┆ 48.077369 ┆ -0.26432  ┆ 0.090351  │\n",
       "│ 6.524221 ┆ -0.000094 ┆ -0.002061 ┆ 13.669287 ┆ … ┆ -0.015435 ┆ 41.833203 ┆ 0.015958  ┆ -0.015824 │\n",
       "│ 5.814603 ┆ -0.249396 ┆ 0.00876   ┆ 12.32655  ┆ … ┆ -0.046663 ┆ 38.515141 ┆ -8.547037 ┆ -0.117428 │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_col_names = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "sub_df = pl.DataFrame(np.vstack(test_pred).T, schema=sub_col_names)\n",
    "display(sub_df)\n",
    "sub_df.write_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
