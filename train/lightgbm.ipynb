{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original: https://www.guruguru.science/competitions/25/discussions/8b97734b-1f76-4075-b1af-5d227d6b70e8/ (@yururoi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/*\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PACKAGE_DIR = \"/kaggle/src\"\n",
    "sys.path.append(PACKAGE_DIR)\n",
    "sys.path.append(os.path.join(PACKAGE_DIR, \"Penguin-ML-Library\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 00:42:32.812150: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-21 00:42:32.837579: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "set seed: 46\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from penguinml.utils.logger import get_logger, init_logger\n",
    "from penguinml.utils.set_seed import seed_base\n",
    "\n",
    "MODEL_NAME = \"lightgbm\"\n",
    "CFG = yaml.safe_load(open(os.path.join(PACKAGE_DIR, \"config.yaml\"), \"r\"))\n",
    "print(CFG[MODEL_NAME][\"execution\"][\"exp_id\"])\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG[MODEL_NAME]['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "init_logger(f\"{ CFG[MODEL_NAME]['execution']['exp_id']}.log\")\n",
    "logger = get_logger(\"main\")\n",
    "seed_base(CFG[MODEL_NAME][\"execution\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    N_FOLD = 5\n",
    "    RANDOM_SATE = 42\n",
    "\n",
    "\n",
    "NB = \"exp1015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/kaggle\")\n",
    "DATA_DIR = ROOT_DIR / Path(\"input/atmaCup#18_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(DATA_DIR / \"train_features.csv\")\n",
    "test_df = pl.read_csv(DATA_DIR / \"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df と test_dfを結合（特徴量エンジニアリングをしやすくするため）\n",
    "_all_df = pl.concat([train_df, test_df], how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    \"vEgo\",\n",
    "    \"aEgo\",\n",
    "    \"steeringAngleDeg\",\n",
    "    \"steeringTorque\",\n",
    "    \"gas\",\n",
    "]  # 同一シーンから集計する値のカラム名\n",
    "\n",
    "# 同一シーンから特徴量作成\n",
    "exprs = []\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(-1).over(\"scene\").alias(f\"{agg_col}_shift-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(1).over(\"scene\").alias(f\"{agg_col}_shift1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(-1).over(\"scene\").alias(f\"{agg_col}_diff-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値との差分\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(1).over(\"scene\").alias(f\"{agg_col}_diff1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値との差分\n",
    "exprs += [pl.col(agg_col).mean().over(\"scene\").alias(f\"{agg_col}_mean\") for agg_col in agg_cols]  # 同一シーンの平均値\n",
    "exprs += [pl.col(agg_col).std().over(\"scene\").alias(f\"{agg_col}_std\") for agg_col in agg_cols]  # 同一シーンの標準偏差\n",
    "exprs += [pl.col(agg_col).max().over(\"scene\").alias(f\"{agg_col}_max\") for agg_col in agg_cols]  # 同一シーンの最大値\n",
    "exprs += [pl.col(agg_col).min().over(\"scene\").alias(f\"{agg_col}_min\") for agg_col in agg_cols]  # 同一シーンの最小値\n",
    "\n",
    "_all_df = (\n",
    "    _all_df.with_columns(\n",
    "        # ID からシーンとデシ秒を作成\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(0).alias(\"scene\"),\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(1).cast(pl.Int32).alias(\"decisecond\"),\n",
    "    )\n",
    "    .sort(\n",
    "        # shiftと diffが時系列順に並んでいる必要があるためシーンごとに時間軸でソート\n",
    "        \"scene\",\n",
    "        \"decisecond\",\n",
    "    )\n",
    "    .with_columns(exprs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = pl.read_csv(CFG[\"dataset\"][\"train_fold_path\"]).rename({\"sceneID\": \"scene\"})\n",
    "_all_df = _all_df.join(train_folds, how=\"left\", on=\"scene\")\n",
    "# assert train_df[\"fold\"].null_count() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45098/45098 [00:00<00:00, 77790.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# YOLOの検出結果\n",
    "import json\n",
    "\n",
    "yolo_paths = glob.glob(\"/kaggle/input/yolo-det/det/*.json\")\n",
    "yolo_dfs = []\n",
    "for path in tqdm(yolo_paths):\n",
    "    ID = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    yolo_feature = {\n",
    "        \"ID\": ID,\n",
    "        \"num_objects\": len(data),\n",
    "    }\n",
    "    for bbox in data:\n",
    "        if bbox[\"x1\"] == bbox[\"x2\"] or bbox[\"y1\"] == bbox[\"y2\"]:\n",
    "            continue\n",
    "\n",
    "        if bbox[\"cls\"] != \"car\":\n",
    "            continue\n",
    "\n",
    "        # count\n",
    "        if bbox[\"cls\"] not in yolo_feature:\n",
    "            yolo_feature[bbox[\"cls\"]] = 0\n",
    "        yolo_feature[bbox[\"cls\"]] += 1\n",
    "\n",
    "        # 最も横方向が中央にあるものの情報\n",
    "        if f\"center_x_{bbox['cls']}\" not in yolo_feature:\n",
    "            yolo_feature[f\"center_x_{bbox['cls']}\"] = -1\n",
    "        current_dist = abs(yolo_feature[f\"center_x_{bbox['cls']}\"] - 64)\n",
    "        now_center_x = (bbox[\"x1\"] + bbox[\"x2\"]) / 2\n",
    "        now_dist = abs(now_center_x - 64)\n",
    "        if now_dist < current_dist:\n",
    "            yolo_feature[f\"center_x_{bbox['cls']}\"] = now_center_x\n",
    "            yolo_feature[f\"center_y_{bbox['cls']}\"] = (bbox[\"y1\"] + bbox[\"y2\"]) / 2\n",
    "            yolo_feature[f\"width_{bbox['cls']}\"] = bbox[\"x2\"] - bbox[\"x1\"]\n",
    "            yolo_feature[f\"height_{bbox['cls']}\"] = bbox[\"y2\"] - bbox[\"y1\"]\n",
    "            yolo_feature[f\"bottom_{bbox['cls']}\"] = bbox[\"y2\"]\n",
    "            yolo_feature[f\"area_{bbox['cls']}\"] = (bbox[\"x2\"] - bbox[\"x1\"]) * (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "            yolo_feature[f\"aspect_ratio_{bbox['cls']}\"] = (bbox[\"x2\"] - bbox[\"x1\"]) / (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "            yolo_feature[f\"conf_{bbox['cls']}\"] = bbox[\"conf\"]\n",
    "    yolo_dfs.append(yolo_feature)\n",
    "yolo_df = pl.DataFrame(yolo_dfs)\n",
    "\n",
    "_all_df = _all_df.join(yolo_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45098 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 45098/45098 [00:18<00:00, 2446.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# depth\n",
    "import cv2\n",
    "\n",
    "depth_features = []\n",
    "for ID in tqdm(_all_df[\"ID\"]):\n",
    "    path = f\"/kaggle/input/depth_image/depth/{ID}/0.png\"\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    patch_size = 16\n",
    "    this_features = {\"ID\": ID}\n",
    "    for i in range(0, 128, patch_size):\n",
    "        for j in range(0, 64, patch_size):\n",
    "            patch = image[i : i + patch_size, j : j + patch_size]\n",
    "            this_features[f\"patch_{i}_{j}_mean\"] = np.mean(patch)\n",
    "            this_features[f\"patch_{i}_{j}_median\"] = np.median(patch)\n",
    "    depth_features.append(this_features)\n",
    "depth_df = pl.DataFrame(depth_features)\n",
    "_all_df = _all_df.join(depth_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aEgo', 'aEgo_diff-1', 'aEgo_diff1', 'aEgo_max', 'aEgo_mean', 'aEgo_min', 'aEgo_shift-1', 'aEgo_shift1', 'aEgo_std', 'area_car', 'aspect_ratio_car', 'bottom_car', 'brake', 'brakePressed', 'car', 'center_x_car', 'center_y_car', 'conf_car', 'decisecond', 'gas', 'gasPressed', 'gas_diff-1', 'gas_diff1', 'gas_max', 'gas_mean', 'gas_min', 'gas_shift-1', 'gas_shift1', 'gas_std', 'height_car', 'leftBlinker', 'num_objects', 'patch_0_0_mean', 'patch_0_0_median', 'patch_0_16_mean', 'patch_0_16_median', 'patch_0_32_mean', 'patch_0_32_median', 'patch_0_48_mean', 'patch_0_48_median', 'patch_112_0_mean', 'patch_112_0_median', 'patch_112_16_mean', 'patch_112_16_median', 'patch_112_32_mean', 'patch_112_32_median', 'patch_112_48_mean', 'patch_112_48_median', 'patch_16_0_mean', 'patch_16_0_median', 'patch_16_16_mean', 'patch_16_16_median', 'patch_16_32_mean', 'patch_16_32_median', 'patch_16_48_mean', 'patch_16_48_median', 'patch_32_0_mean', 'patch_32_0_median', 'patch_32_16_mean', 'patch_32_16_median', 'patch_32_32_mean', 'patch_32_32_median', 'patch_32_48_mean', 'patch_32_48_median', 'patch_48_0_mean', 'patch_48_0_median', 'patch_48_16_mean', 'patch_48_16_median', 'patch_48_32_mean', 'patch_48_32_median', 'patch_48_48_mean', 'patch_48_48_median', 'patch_64_0_mean', 'patch_64_0_median', 'patch_64_16_mean', 'patch_64_16_median', 'patch_64_32_mean', 'patch_64_32_median', 'patch_64_48_mean', 'patch_64_48_median', 'patch_80_0_mean', 'patch_80_0_median', 'patch_80_16_mean', 'patch_80_16_median', 'patch_80_32_mean', 'patch_80_32_median', 'patch_80_48_mean', 'patch_80_48_median', 'patch_96_0_mean', 'patch_96_0_median', 'patch_96_16_mean', 'patch_96_16_median', 'patch_96_32_mean', 'patch_96_32_median', 'patch_96_48_mean', 'patch_96_48_median', 'rightBlinker', 'steeringAngleDeg', 'steeringAngleDeg_diff-1', 'steeringAngleDeg_diff1', 'steeringAngleDeg_max', 'steeringAngleDeg_mean', 'steeringAngleDeg_min', 'steeringAngleDeg_shift-1', 'steeringAngleDeg_shift1', 'steeringAngleDeg_std', 'steeringTorque', 'steeringTorque_diff-1', 'steeringTorque_diff1', 'steeringTorque_max', 'steeringTorque_mean', 'steeringTorque_min', 'steeringTorque_shift-1', 'steeringTorque_shift1', 'steeringTorque_std', 'vEgo', 'vEgo_diff-1', 'vEgo_diff1', 'vEgo_max', 'vEgo_mean', 'vEgo_min', 'vEgo_shift-1', 'vEgo_shift1', 'vEgo_std', 'width_car']\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "\n",
    "# 使う特徴量を指定するより使わない特徴量を指定するほうが試行錯誤が楽\n",
    "del_columns = targets + [\"ID\", \"scene\", \"gearShifter\", \"fold\"]\n",
    "\n",
    "features = list(set(_all_df.columns) - set(del_columns))\n",
    "features.sort()\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAEを計算\n",
    "def evaluation(true_values, pred_values):\n",
    "    abs_diff = abs(true_values - pred_values)\n",
    "    mae = np.mean(\n",
    "        abs_diff.reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encdoding\n",
    "categorical_columns = [\"gearShifter\"]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    _all_df = _all_df.with_columns(pl.Series(le.fit_transform(_all_df[col])).alias(f\"{col}_le\"))\n",
    "cate_features = [f\"{col}_le\" for c in categorical_columns]\n",
    "features = list(set(features) | set(cate_features))\n",
    "\n",
    "# count encoding\n",
    "count_enc = [\"gearShifter\"]\n",
    "_all_df = _all_df.with_columns([pl.col(c).count().over(c).alias(f\"{c}_count\") for c in count_enc])\n",
    "count_features = [f\"{c}_count\" for c in count_enc]\n",
    "features = list(set(features) | set(count_features))\n",
    "\n",
    "\n",
    "train_df = train_df.join(_all_df, how=\"left\", on=\"ID\")\n",
    "test_df = test_df.join(_all_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(target, params):\n",
    "    oof_pred = np.zeros(len(train_df))\n",
    "    y_pred = np.zeros(len(test_df))\n",
    "    models = []\n",
    "    cv_scores = {}\n",
    "\n",
    "    for fold in range(5):\n",
    "        # print(f\"fold{fold}: \", end=\"\")\n",
    "\n",
    "        # TrainとTestに分割\n",
    "        x_train = train_df.filter(pl.col(\"fold\") != fold).select(features)\n",
    "        x_val = train_df.filter(pl.col(\"fold\") == fold).select(features)\n",
    "        y_train = train_df.filter(pl.col(\"fold\") != fold).select(target)\n",
    "        y_val = train_df.filter(pl.col(\"fold\") == fold).select(target)\n",
    "\n",
    "        test = test_df[features]\n",
    "\n",
    "        # create Dataset\n",
    "        train_set = lgb.Dataset(\n",
    "            x_train.to_pandas(),\n",
    "            y_train.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "        val_set = lgb.Dataset(\n",
    "            x_val.to_pandas(),\n",
    "            y_val.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "\n",
    "        # train\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            num_boost_round=10000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "                lgb.log_evaluation(500000),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        fold_pred = model.predict(x_val.to_pandas())\n",
    "\n",
    "        score = evaluation(y_val.to_numpy().reshape(-1), fold_pred)\n",
    "        cv_scores[f\"cv{fold}\"] = score\n",
    "\n",
    "        # oof_pred[test_index] = fold_pred\n",
    "        oof_pred[train_df[\"fold\"].to_numpy() == fold] = fold_pred\n",
    "\n",
    "        y_pred += model.predict(test.to_pandas()) / Config.N_FOLD\n",
    "\n",
    "        # print(f\"{score}\")\n",
    "\n",
    "    oof_score = evaluation(train_df[target].to_numpy().reshape(-1), oof_pred)\n",
    "    # print(f\"OOF score is {oof_score}\")\n",
    "\n",
    "    return oof_pred, y_pred, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-21 00:42:55,809] A new study created in memory with name: no-name-23ae72dd-288e-4717-ba00-63d277cb3280\n",
      "[I 2024-11-21 00:49:01,224] Trial 0 finished with value: 0.20889926848570828 and parameters: {'max_depth': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001, 'reg_lambda': 0.001, 'subsample': 1.0, 'min_child_samples': 20, 'subsample_freq': 0}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 00:58:00,605] Trial 1 finished with value: 0.2257071692103231 and parameters: {'max_depth': 5, 'colsample_bytree': 0.6654388599971016, 'reg_alpha': 0.023540330983112142, 'reg_lambda': 162.32735309201252, 'subsample': 0.5636625122102001, 'min_child_samples': 202, 'subsample_freq': 5}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 01:05:58,588] Trial 2 finished with value: 0.22426596506962568 and parameters: {'max_depth': 3, 'colsample_bytree': 0.6578180982869597, 'reg_alpha': 0.07221556640229311, 'reg_lambda': 14.745916171907252, 'subsample': 0.6691378860254912, 'min_child_samples': 50, 'subsample_freq': 3}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 01:14:34,337] Trial 3 finished with value: 0.22567101376362642 and parameters: {'max_depth': 3, 'colsample_bytree': 0.7173391362107358, 'reg_alpha': 0.24512830329739058, 'reg_lambda': 0.0033555553887625335, 'subsample': 0.7410706865547624, 'min_child_samples': 302, 'subsample_freq': 3}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 01:21:00,257] Trial 4 finished with value: 0.2558478714458658 and parameters: {'max_depth': 5, 'colsample_bytree': 0.3765784053900655, 'reg_alpha': 90.02820076784845, 'reg_lambda': 112.64066188048524, 'subsample': 0.8108106391647049, 'min_child_samples': 153, 'subsample_freq': 4}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 01:22:34,812] Trial 5 finished with value: 0.3505400630501327 and parameters: {'max_depth': 5, 'colsample_bytree': 0.541364977980107, 'reg_alpha': 522.0739242280397, 'reg_lambda': 0.5022952816015486, 'subsample': 0.5176752173664979, 'min_child_samples': 34, 'subsample_freq': 5}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 01:32:30,647] Trial 6 finished with value: 0.2455287053953062 and parameters: {'max_depth': 6, 'colsample_bytree': 0.20232800069420778, 'reg_alpha': 3.5671562141296347, 'reg_lambda': 0.5067918811915013, 'subsample': 0.6890483856177311, 'min_child_samples': 85, 'subsample_freq': 5}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 01:35:40,225] Trial 7 finished with value: 0.25316084698360264 and parameters: {'max_depth': 3, 'colsample_bytree': 0.9317537734596304, 'reg_alpha': 227.359308509261, 'reg_lambda': 0.036257377945917914, 'subsample': 0.9412332152280312, 'min_child_samples': 191, 'subsample_freq': 6}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 01:47:58,679] Trial 8 finished with value: 0.23145806063315125 and parameters: {'max_depth': 8, 'colsample_bytree': 0.2830493358253424, 'reg_alpha': 0.02939647642483797, 'reg_lambda': 3.0403899068524143, 'subsample': 0.8901694908941825, 'min_child_samples': 71, 'subsample_freq': 1}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 01:58:12,589] Trial 9 finished with value: 0.22033316134807157 and parameters: {'max_depth': 6, 'colsample_bytree': 0.8432879780937657, 'reg_alpha': 0.8159907048406956, 'reg_lambda': 0.19402115270020895, 'subsample': 0.8665113473364503, 'min_child_samples': 368, 'subsample_freq': 2}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 02:04:20,830] Trial 10 finished with value: 0.2171342542322039 and parameters: {'max_depth': 8, 'colsample_bytree': 0.9058147405637382, 'reg_alpha': 0.001234051168540521, 'reg_lambda': 0.0019433251309044315, 'subsample': 0.9859957650142831, 'min_child_samples': 277, 'subsample_freq': 0}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 02:10:30,302] Trial 11 finished with value: 0.21560617857865685 and parameters: {'max_depth': 8, 'colsample_bytree': 0.993786967807288, 'reg_alpha': 0.0010538485527582214, 'reg_lambda': 0.001496359840672808, 'subsample': 0.9906321996265861, 'min_child_samples': 292, 'subsample_freq': 0}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 02:16:28,270] Trial 12 finished with value: 0.21593104059253992 and parameters: {'max_depth': 7, 'colsample_bytree': 0.991569484119888, 'reg_alpha': 0.001243532306930879, 'reg_lambda': 0.015360784058980495, 'subsample': 0.999069630663283, 'min_child_samples': 305, 'subsample_freq': 0}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 02:26:59,878] Trial 13 finished with value: 0.22256928898249004 and parameters: {'max_depth': 7, 'colsample_bytree': 0.8038740365918343, 'reg_alpha': 0.006395840925271624, 'reg_lambda': 0.0010178627903351836, 'subsample': 0.7922507860413535, 'min_child_samples': 398, 'subsample_freq': 1}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 02:36:58,965] Trial 14 finished with value: 0.22145596101112744 and parameters: {'max_depth': 7, 'colsample_bytree': 0.4811617907705046, 'reg_alpha': 0.005279828648950096, 'reg_lambda': 0.024716944193566244, 'subsample': 0.8859030304842589, 'min_child_samples': 129, 'subsample_freq': 1}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 02:44:10,475] Trial 15 finished with value: 0.21386581184547154 and parameters: {'max_depth': 8, 'colsample_bytree': 0.9937062636996457, 'reg_alpha': 9.3918536926309, 'reg_lambda': 0.005842345866514642, 'subsample': 0.5822292479090798, 'min_child_samples': 255, 'subsample_freq': 0}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 02:53:33,550] Trial 16 finished with value: 0.22152899664604758 and parameters: {'max_depth': 7, 'colsample_bytree': 0.7960664479020128, 'reg_alpha': 18.638165350405032, 'reg_lambda': 0.010578333786962161, 'subsample': 0.6128569884995055, 'min_child_samples': 238, 'subsample_freq': 2}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 03:00:49,405] Trial 17 finished with value: 0.21341596517166006 and parameters: {'max_depth': 8, 'colsample_bytree': 0.88640846198905, 'reg_alpha': 6.828801614894853, 'reg_lambda': 0.0805942231684836, 'subsample': 0.6032900561363039, 'min_child_samples': 130, 'subsample_freq': 2}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 03:07:38,821] Trial 18 finished with value: 0.2100191227601491 and parameters: {'max_depth': 6, 'colsample_bytree': 0.8985412049431115, 'reg_alpha': 0.596710517783015, 'reg_lambda': 0.09314420475986704, 'subsample': 0.5020683808551726, 'min_child_samples': 8, 'subsample_freq': 2}. Best is trial 0 with value: 0.20889926848570828.\n",
      "[I 2024-11-21 03:24:03,053] Trial 19 finished with value: 0.2270103452449138 and parameters: {'max_depth': 4, 'colsample_bytree': 0.7411949239294875, 'reg_alpha': 0.5776656253034882, 'reg_lambda': 977.2448566061988, 'subsample': 0.5256469384245736, 'min_child_samples': 7, 'subsample_freq': 1}. Best is trial 0 with value: 0.20889926848570828.\n"
     ]
    }
   ],
   "source": [
    "# def add_dt_features(train: pl.DataFrame):\n",
    "#     \"\"\"dt秒後の特徴\"\"\"\n",
    "#     train = train.with_columns(\n",
    "#         # vt\n",
    "#         (pl.col(\"vEgo\") * pl.col(\"dt\").cast(pl.Float32)).alias(\"linear_movement@dt\"),\n",
    "#         # vt + 0.5at^2\n",
    "#         ((pl.col(\"vEgo\") + 0.5 * pl.col(\"aEgo\") * pl.col(\"dt\").cast(pl.Float32) ** 2).alias(\"movement@dt\")),\n",
    "#         # v + at\n",
    "#         (pl.col(\"vEgo\") + pl.col(\"aEgo\") * pl.col(\"dt\").cast(pl.Float32)).alias(\"velocity@dt\"),\n",
    "#     )\n",
    "#     return train\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 8)\n",
    "    num_leaves = int(0.7 * max_depth**2)\n",
    "    colsample_bytree = trial.suggest_uniform(\"colsample_bytree\", 0.2, 1.0)\n",
    "    reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1e3)\n",
    "    reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1e3)\n",
    "    subsample = trial.suggest_loguniform(\"subsample\", 0.5, 1.0)\n",
    "    min_child_samples = trial.suggest_int(\"min_child_samples\", 5, 400)\n",
    "    subsample_freq = trial.suggest_int(\"subsample_freq\", 0, 6)\n",
    "\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"mae\",  # 今回の評価指標がMAEを使用\n",
    "        \"objective\": \"regression\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": Config.RANDOM_SATE,\n",
    "        \"learning_rate\": 0.01,\n",
    "        # \"device\": \"gpu\"\n",
    "        \"verbosity\": -1,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"num_leaves\": num_leaves,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"reg_alpha\": reg_alpha,\n",
    "        \"reg_lambda\": reg_lambda,\n",
    "        \"subsample\": subsample,\n",
    "        \"min_child_samples\": min_child_samples,\n",
    "        \"subsample_freq\": subsample_freq,\n",
    "        # \"n_estimators\": 10,\n",
    "    }\n",
    "\n",
    "    models_dict = {}\n",
    "    test_pred = []\n",
    "    oof_pred = []\n",
    "    for target in targets:\n",
    "        # print(\"=\" * 50)\n",
    "        # print(f\"# {target}\")\n",
    "        # print(\"=\" * 50)\n",
    "\n",
    "        # # dt features\n",
    "        # dt = float(target.split(\"_\")[-1]) * 0.5 + 0.5\n",
    "        # train_df = train_df.with_columns(pl.lit(dt).alias(\"dt\"))\n",
    "        # test_df = test_df.with_columns(pl.lit(dt).alias(\"dt\"))\n",
    "        # train_df = add_dt_features(train_df)\n",
    "        # test_df = add_dt_features(test_df)\n",
    "        # features = list(set(features) | set([\"linear_movement@dt\", \"movement@dt\", \"velocity@dt\"]))\n",
    "\n",
    "        oof_preds_partial, y_pred_partial, models_partial = train_lgbm(target, params)\n",
    "        models_dict[target] = models_partial\n",
    "        oof_pred.append(oof_preds_partial)\n",
    "        test_pred.append(y_pred_partial)\n",
    "    mae = evaluation(train_df[targets].to_numpy(), np.vstack(oof_pred).T)\n",
    "    return mae\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.enqueue_trial(\n",
    "    {\n",
    "        \"max_depth\": 7,\n",
    "        \"colsample_bytree\": 1.0,\n",
    "        \"reg_alpha\": 1e-3,\n",
    "        \"reg_lambda\": 1e-3,\n",
    "        \"subsample\": 1.0,\n",
    "        \"min_child_samples\": 20,\n",
    "        \"subsample_freq\": 0,\n",
    "    }\n",
    ")\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study.trials_dataframe()\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit ファイル作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_727, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th><th>ID</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>1.451966</td><td>-0.05001</td><td>0.000828</td><td>3.02292</td><td>-0.118906</td><td>0.003799</td><td>4.581418</td><td>-0.226131</td><td>0.005058</td><td>5.960247</td><td>-0.197664</td><td>0.001139</td><td>7.293397</td><td>-0.129997</td><td>0.012701</td><td>8.633616</td><td>0.008382</td><td>0.020247</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>0.949345</td><td>0.37931</td><td>0.002446</td><td>1.78144</td><td>0.997347</td><td>0.009869</td><td>2.416597</td><td>1.656721</td><td>0.016779</td><td>3.018493</td><td>2.455365</td><td>0.022162</td><td>3.717404</td><td>3.277484</td><td>0.041375</td><td>4.531961</td><td>4.347581</td><td>0.051499</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>1.574644</td><td>0.012977</td><td>-0.000396</td><td>3.284368</td><td>0.013113</td><td>0.001907</td><td>4.818523</td><td>0.027939</td><td>0.00021</td><td>6.35423</td><td>0.058121</td><td>-0.007488</td><td>7.929633</td><td>0.062045</td><td>-0.002237</td><td>9.17903</td><td>0.122829</td><td>-0.008452</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>0.834858</td><td>0.071709</td><td>-0.004797</td><td>1.669115</td><td>0.265695</td><td>-0.014526</td><td>2.469084</td><td>0.648576</td><td>-0.019613</td><td>2.996955</td><td>1.083865</td><td>-0.037253</td><td>3.617305</td><td>1.894096</td><td>-0.054112</td><td>4.219986</td><td>2.808786</td><td>-0.082212</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>0.819024</td><td>0.003951</td><td>-0.004481</td><td>1.425394</td><td>0.007575</td><td>-0.009175</td><td>1.895713</td><td>0.001957</td><td>-0.018596</td><td>2.230749</td><td>-0.009298</td><td>-0.03604</td><td>2.186012</td><td>-0.010073</td><td>-0.043591</td><td>1.669718</td><td>-0.026504</td><td>-0.049678</td><td>&quot;01d738e799d260a10f6324f78023b3…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6.537135</td><td>0.008542</td><td>0.014563</td><td>13.798478</td><td>0.041535</td><td>0.036641</td><td>21.022014</td><td>0.096245</td><td>0.052083</td><td>28.292109</td><td>0.186007</td><td>0.07237</td><td>35.626491</td><td>0.305797</td><td>0.084002</td><td>43.041352</td><td>0.443229</td><td>0.090601</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>6.988506</td><td>0.000371</td><td>-0.005645</td><td>14.857086</td><td>-0.016367</td><td>-0.041432</td><td>22.885263</td><td>-0.067638</td><td>-0.103802</td><td>31.022227</td><td>-0.134661</td><td>-0.222285</td><td>39.254969</td><td>-0.227326</td><td>-0.368399</td><td>47.522269</td><td>-0.336563</td><td>-0.55295</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>7.413827</td><td>-0.000097</td><td>0.016546</td><td>15.655867</td><td>-0.016144</td><td>0.04354</td><td>23.843606</td><td>-0.041808</td><td>0.073727</td><td>31.945971</td><td>-0.068803</td><td>0.117456</td><td>39.950944</td><td>-0.119747</td><td>0.172923</td><td>47.864668</td><td>-0.202397</td><td>0.236791</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>6.5249</td><td>-0.000282</td><td>0.018482</td><td>13.660526</td><td>-0.002987</td><td>0.0846</td><td>20.698266</td><td>0.007619</td><td>0.185175</td><td>27.682034</td><td>0.020512</td><td>0.36199</td><td>34.684556</td><td>0.095081</td><td>0.553349</td><td>41.590194</td><td>0.179893</td><td>0.79642</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>5.821521</td><td>-0.232853</td><td>0.008813</td><td>12.343806</td><td>-1.042234</td><td>0.015574</td><td>18.928862</td><td>-2.352702</td><td>0.015097</td><td>25.509667</td><td>-4.271434</td><td>-0.003059</td><td>32.014075</td><td>-6.406349</td><td>-0.046597</td><td>38.348723</td><td>-9.18127</td><td>-0.100566</td><td>&quot;ffc9272ee663f281a5f0ac533e97a1…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_727, 19)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ x_0      ┆ y_0       ┆ z_0       ┆ x_1       ┆ … ┆ x_5       ┆ y_5       ┆ z_5       ┆ ID        │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ str       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.451966 ┆ -0.05001  ┆ 0.000828  ┆ 3.02292   ┆ … ┆ 8.633616  ┆ 0.008382  ┆ 0.020247  ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 0.949345 ┆ 0.37931   ┆ 0.002446  ┆ 1.78144   ┆ … ┆ 4.531961  ┆ 4.347581  ┆ 0.051499  ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 1.574644 ┆ 0.012977  ┆ -0.000396 ┆ 3.284368  ┆ … ┆ 9.17903   ┆ 0.122829  ┆ -0.008452 ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 0.834858 ┆ 0.071709  ┆ -0.004797 ┆ 1.669115  ┆ … ┆ 4.219986  ┆ 2.808786  ┆ -0.082212 ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 0.819024 ┆ 0.003951  ┆ -0.004481 ┆ 1.425394  ┆ … ┆ 1.669718  ┆ -0.026504 ┆ -0.049678 ┆ 01d738e79 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9d260a10f │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6324f7802 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 3b3…      │\n",
       "│ …        ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 6.537135 ┆ 0.008542  ┆ 0.014563  ┆ 13.798478 ┆ … ┆ 43.041352 ┆ 0.443229  ┆ 0.090601  ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 6.988506 ┆ 0.000371  ┆ -0.005645 ┆ 14.857086 ┆ … ┆ 47.522269 ┆ -0.336563 ┆ -0.55295  ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 7.413827 ┆ -0.000097 ┆ 0.016546  ┆ 15.655867 ┆ … ┆ 47.864668 ┆ -0.202397 ┆ 0.236791  ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 6.5249   ┆ -0.000282 ┆ 0.018482  ┆ 13.660526 ┆ … ┆ 41.590194 ┆ 0.179893  ┆ 0.79642   ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 5.821521 ┆ -0.232853 ┆ 0.008813  ┆ 12.343806 ┆ … ┆ 38.348723 ┆ -9.18127  ┆ -0.100566 ┆ ffc9272ee │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 663f281a5 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f0ac533e9 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7a1…      │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sub_col_names = [\n",
    "#     \"x_0\",\n",
    "#     \"y_0\",\n",
    "#     \"z_0\",\n",
    "#     \"x_1\",\n",
    "#     \"y_1\",\n",
    "#     \"z_1\",\n",
    "#     \"x_2\",\n",
    "#     \"y_2\",\n",
    "#     \"z_2\",\n",
    "#     \"x_3\",\n",
    "#     \"y_3\",\n",
    "#     \"z_3\",\n",
    "#     \"x_4\",\n",
    "#     \"y_4\",\n",
    "#     \"z_4\",\n",
    "#     \"x_5\",\n",
    "#     \"y_5\",\n",
    "#     \"z_5\",\n",
    "# ]\n",
    "# sub_df = pl.DataFrame(np.vstack(test_pred).T, schema=sub_col_names)\n",
    "# sub_df = sub_df.with_columns(pl.Series(\"ID\", test_df[\"ID\"]))\n",
    "# sub_df.write_csv(os.path.join(CFG[\"output_dir\"], \"submission.csv\"))\n",
    "\n",
    "# oof_df = pl.DataFrame(np.vstack(oof_pred).T, schema=sub_col_names)\n",
    "# oof_df = oof_df.with_columns(pl.Series(\"ID\", train_df[\"ID\"]))\n",
    "# oof_df.write_csv(os.path.join(CFG[\"output_dir\"], \"oof.csv\"))\n",
    "\n",
    "# display(sub_df)\n",
    "# sub_df.drop(\"ID\").write_csv(os.path.join(CFG[\"output_dir\"], \"submission_wo_ID.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
