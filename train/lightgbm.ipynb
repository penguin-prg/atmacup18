{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original: https://www.guruguru.science/competitions/25/discussions/8b97734b-1f76-4075-b1af-5d227d6b70e8/ (@yururoi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/kaggle/working/*': No such file or directory\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/*\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PACKAGE_DIR = \"/kaggle/src\"\n",
    "sys.path.append(PACKAGE_DIR)\n",
    "sys.path.append(os.path.join(PACKAGE_DIR, \"Penguin-ML-Library\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 13:05:08.667124: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 13:05:08.695238: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "set seed: 46\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from penguinml.utils.logger import get_logger, init_logger\n",
    "from penguinml.utils.set_seed import seed_base\n",
    "\n",
    "MODEL_NAME = \"lightgbm\"\n",
    "CFG = yaml.safe_load(open(os.path.join(PACKAGE_DIR, \"config.yaml\"), \"r\"))\n",
    "print(CFG[MODEL_NAME][\"execution\"][\"exp_id\"])\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG[MODEL_NAME]['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "init_logger(f\"{ CFG[MODEL_NAME]['execution']['exp_id']}.log\")\n",
    "logger = get_logger(\"main\")\n",
    "seed_base(CFG[MODEL_NAME][\"execution\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    N_FOLD = 5\n",
    "    RANDOM_SATE = 42\n",
    "\n",
    "\n",
    "NB = \"exp1015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/kaggle\")\n",
    "DATA_DIR = ROOT_DIR / Path(\"input/atmaCup#18_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(DATA_DIR / \"train_features.csv\")\n",
    "test_df = pl.read_csv(DATA_DIR / \"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df と test_dfを結合（特徴量エンジニアリングをしやすくするため）\n",
    "_all_df = pl.concat([train_df, test_df], how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    \"vEgo\",\n",
    "    \"aEgo\",\n",
    "    \"steeringAngleDeg\",\n",
    "    \"steeringTorque\",\n",
    "    \"gas\",\n",
    "]  # 同一シーンから集計する値のカラム名\n",
    "\n",
    "# 同一シーンから特徴量作成\n",
    "exprs = []\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(-1).over(\"scene\").alias(f\"{agg_col}_shift-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(1).over(\"scene\").alias(f\"{agg_col}_shift1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(-1).over(\"scene\").alias(f\"{agg_col}_diff-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値との差分\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(1).over(\"scene\").alias(f\"{agg_col}_diff1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値との差分\n",
    "exprs += [pl.col(agg_col).mean().over(\"scene\").alias(f\"{agg_col}_mean\") for agg_col in agg_cols]  # 同一シーンの平均値\n",
    "exprs += [pl.col(agg_col).std().over(\"scene\").alias(f\"{agg_col}_std\") for agg_col in agg_cols]  # 同一シーンの標準偏差\n",
    "exprs += [pl.col(agg_col).max().over(\"scene\").alias(f\"{agg_col}_max\") for agg_col in agg_cols]  # 同一シーンの最大値\n",
    "exprs += [pl.col(agg_col).min().over(\"scene\").alias(f\"{agg_col}_min\") for agg_col in agg_cols]  # 同一シーンの最小値\n",
    "\n",
    "_all_df = (\n",
    "    _all_df.with_columns(\n",
    "        # ID からシーンとデシ秒を作成\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(0).alias(\"scene\"),\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(1).cast(pl.Int32).alias(\"decisecond\"),\n",
    "    )\n",
    "    .sort(\n",
    "        # shiftと diffが時系列順に並んでいる必要があるためシーンごとに時間軸でソート\n",
    "        \"scene\",\n",
    "        \"decisecond\",\n",
    "    )\n",
    "    .with_columns(exprs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = pl.read_csv(CFG[\"dataset\"][\"train_fold_path\"]).rename({\"sceneID\": \"scene\"})\n",
    "_all_df = _all_df.join(train_folds, how=\"left\", on=\"scene\")\n",
    "# assert train_df[\"fold\"].null_count() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45098/45098 [00:00<00:00, 78270.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# YOLOの検出結果\n",
    "import json\n",
    "\n",
    "yolo_paths = glob.glob(\"/kaggle/input/yolo-det/det/*.json\")\n",
    "yolo_dfs = []\n",
    "for path in tqdm(yolo_paths):\n",
    "    ID = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    yolo_feature = {\n",
    "        \"ID\": ID,\n",
    "        \"num_objects\": len(data),\n",
    "    }\n",
    "    for bbox in data:\n",
    "        if bbox[\"x1\"] == bbox[\"x2\"] or bbox[\"y1\"] == bbox[\"y2\"]:\n",
    "            continue\n",
    "\n",
    "        if bbox[\"cls\"] != \"car\":\n",
    "            continue\n",
    "\n",
    "        # count\n",
    "        if bbox[\"cls\"] not in yolo_feature:\n",
    "            yolo_feature[bbox[\"cls\"]] = 0\n",
    "        yolo_feature[bbox[\"cls\"]] += 1\n",
    "\n",
    "        # 最も横方向が中央にあるものの情報\n",
    "        if f\"center_x_{bbox['cls']}\" not in yolo_feature:\n",
    "            yolo_feature[f\"center_x_{bbox['cls']}\"] = -1\n",
    "        current_dist = abs(yolo_feature[f\"center_x_{bbox['cls']}\"] - 64)\n",
    "        now_center_x = (bbox[\"x1\"] + bbox[\"x2\"]) / 2\n",
    "        now_dist = abs(now_center_x - 64)\n",
    "        if now_dist < current_dist:\n",
    "            yolo_feature[f\"center_x_{bbox['cls']}\"] = now_center_x\n",
    "            yolo_feature[f\"center_y_{bbox['cls']}\"] = (bbox[\"y1\"] + bbox[\"y2\"]) / 2\n",
    "            yolo_feature[f\"width_{bbox['cls']}\"] = bbox[\"x2\"] - bbox[\"x1\"]\n",
    "            yolo_feature[f\"height_{bbox['cls']}\"] = bbox[\"y2\"] - bbox[\"y1\"]\n",
    "            yolo_feature[f\"bottom_{bbox['cls']}\"] = bbox[\"y2\"]\n",
    "            yolo_feature[f\"area_{bbox['cls']}\"] = (bbox[\"x2\"] - bbox[\"x1\"]) * (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "            yolo_feature[f\"aspect_ratio_{bbox['cls']}\"] = (bbox[\"x2\"] - bbox[\"x1\"]) / (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "            yolo_feature[f\"conf_{bbox['cls']}\"] = bbox[\"conf\"]\n",
    "    yolo_dfs.append(yolo_feature)\n",
    "yolo_df = pl.DataFrame(yolo_dfs)\n",
    "\n",
    "_all_df = _all_df.join(yolo_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45098 [00:00<?, ?it/s]/tmp/ipykernel_6955/657324386.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  this_features[f\"patch_{i}_{j}_mean\"] = patch.mean()\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "100%|██████████| 45098/45098 [00:23<00:00, 1923.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# depth\n",
    "import cv2\n",
    "\n",
    "depth_features = []\n",
    "for ID in tqdm(_all_df[\"ID\"]):\n",
    "    path = f\"/kaggle/input/depth_image/depth/{ID}/0.png\"\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    patch_size = 16\n",
    "    this_features = {\"ID\": ID}\n",
    "    for i in range(0, 128, patch_size):\n",
    "        for j in range(0, 64, patch_size):\n",
    "            patch = image[i : i + patch_size, j : j + patch_size]\n",
    "            this_features[f\"patch_{i}_{j}_mean\"] = np.mean(patch)\n",
    "            this_features[f\"patch_{i}_{j}_median\"] = np.median(patch)\n",
    "    depth_features.append(this_features)\n",
    "depth_df = pl.DataFrame(depth_features)\n",
    "_all_df = _all_df.join(depth_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aEgo', 'aEgo_diff-1', 'aEgo_diff1', 'aEgo_max', 'aEgo_mean', 'aEgo_min', 'aEgo_shift-1', 'aEgo_shift1', 'aEgo_std', 'area_car', 'aspect_ratio_car', 'bottom_car', 'brake', 'brakePressed', 'car', 'center_x_car', 'center_y_car', 'conf_car', 'decisecond', 'gas', 'gasPressed', 'gas_diff-1', 'gas_diff1', 'gas_max', 'gas_mean', 'gas_min', 'gas_shift-1', 'gas_shift1', 'gas_std', 'height_car', 'leftBlinker', 'num_objects', 'patch_0_0_mean', 'patch_0_0_median', 'patch_0_16_mean', 'patch_0_16_median', 'patch_0_32_mean', 'patch_0_32_median', 'patch_0_48_mean', 'patch_0_48_median', 'patch_112_0_mean', 'patch_112_0_median', 'patch_112_16_mean', 'patch_112_16_median', 'patch_112_32_mean', 'patch_112_32_median', 'patch_112_48_mean', 'patch_112_48_median', 'patch_16_0_mean', 'patch_16_0_median', 'patch_16_16_mean', 'patch_16_16_median', 'patch_16_32_mean', 'patch_16_32_median', 'patch_16_48_mean', 'patch_16_48_median', 'patch_32_0_mean', 'patch_32_0_median', 'patch_32_16_mean', 'patch_32_16_median', 'patch_32_32_mean', 'patch_32_32_median', 'patch_32_48_mean', 'patch_32_48_median', 'patch_48_0_mean', 'patch_48_0_median', 'patch_48_16_mean', 'patch_48_16_median', 'patch_48_32_mean', 'patch_48_32_median', 'patch_48_48_mean', 'patch_48_48_median', 'patch_64_0_mean', 'patch_64_0_median', 'patch_64_16_mean', 'patch_64_16_median', 'patch_64_32_mean', 'patch_64_32_median', 'patch_64_48_mean', 'patch_64_48_median', 'patch_80_0_mean', 'patch_80_0_median', 'patch_80_16_mean', 'patch_80_16_median', 'patch_80_32_mean', 'patch_80_32_median', 'patch_80_48_mean', 'patch_80_48_median', 'patch_96_0_mean', 'patch_96_0_median', 'patch_96_16_mean', 'patch_96_16_median', 'patch_96_32_mean', 'patch_96_32_median', 'patch_96_48_mean', 'patch_96_48_median', 'rightBlinker', 'steeringAngleDeg', 'steeringAngleDeg_diff-1', 'steeringAngleDeg_diff1', 'steeringAngleDeg_max', 'steeringAngleDeg_mean', 'steeringAngleDeg_min', 'steeringAngleDeg_shift-1', 'steeringAngleDeg_shift1', 'steeringAngleDeg_std', 'steeringTorque', 'steeringTorque_diff-1', 'steeringTorque_diff1', 'steeringTorque_max', 'steeringTorque_mean', 'steeringTorque_min', 'steeringTorque_shift-1', 'steeringTorque_shift1', 'steeringTorque_std', 'vEgo', 'vEgo_diff-1', 'vEgo_diff1', 'vEgo_max', 'vEgo_mean', 'vEgo_min', 'vEgo_shift-1', 'vEgo_shift1', 'vEgo_std', 'width_car']\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "\n",
    "# 使う特徴量を指定するより使わない特徴量を指定するほうが試行錯誤が楽\n",
    "del_columns = targets + [\"ID\", \"scene\", \"gearShifter\", \"fold\"]\n",
    "\n",
    "features = list(set(_all_df.columns) - set(del_columns))\n",
    "features.sort()\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAEを計算\n",
    "def evaluation(true_values, pred_values):\n",
    "    abs_diff = abs(true_values - pred_values)\n",
    "    mae = np.mean(\n",
    "        abs_diff.reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encdoding\n",
    "categorical_columns = [\"gearShifter\"]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    _all_df = _all_df.with_columns(pl.Series(le.fit_transform(_all_df[col])).alias(f\"{col}_le\"))\n",
    "cate_features = [f\"{col}_le\" for c in categorical_columns]\n",
    "features = list(set(features) | set(cate_features))\n",
    "\n",
    "# count encoding\n",
    "count_enc = [\"gearShifter\"]\n",
    "_all_df = _all_df.with_columns([pl.col(c).count().over(c).alias(f\"{c}_count\") for c in count_enc])\n",
    "count_features = [f\"{c}_count\" for c in count_enc]\n",
    "features = list(set(features) | set(count_features))\n",
    "\n",
    "\n",
    "train_df = train_df.join(_all_df, how=\"left\", on=\"ID\")\n",
    "test_df = test_df.join(_all_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(target):\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"mae\",  # 今回の評価指標がMAEを使用\n",
    "        \"objective\": \"regression\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": Config.RANDOM_SATE,\n",
    "        \"learning_rate\": 0.01,\n",
    "        # \"device\": \"gpu\"\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "\n",
    "    oof_pred = np.zeros(len(train_df))\n",
    "    y_pred = np.zeros(len(test_df))\n",
    "    models = []\n",
    "    cv_scores = {}\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"fold{fold}: \", end=\"\")\n",
    "\n",
    "        # TrainとTestに分割\n",
    "        x_train = train_df.filter(pl.col(\"fold\") != fold).select(features)\n",
    "        x_val = train_df.filter(pl.col(\"fold\") == fold).select(features)\n",
    "        y_train = train_df.filter(pl.col(\"fold\") != fold).select(target)\n",
    "        y_val = train_df.filter(pl.col(\"fold\") == fold).select(target)\n",
    "\n",
    "        test = test_df[features]\n",
    "\n",
    "        # create Dataset\n",
    "        train_set = lgb.Dataset(\n",
    "            x_train.to_pandas(),\n",
    "            y_train.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "        val_set = lgb.Dataset(\n",
    "            x_val.to_pandas(),\n",
    "            y_val.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "\n",
    "        # train\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            num_boost_round=10000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "                lgb.log_evaluation(500000),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        fold_pred = model.predict(x_val.to_pandas())\n",
    "\n",
    "        score = evaluation(y_val.to_numpy().reshape(-1), fold_pred)\n",
    "        cv_scores[f\"cv{fold}\"] = score\n",
    "\n",
    "        # oof_pred[test_index] = fold_pred\n",
    "        oof_pred[train_df[\"fold\"].to_numpy() == fold] = fold_pred\n",
    "\n",
    "        y_pred += model.predict(test.to_pandas()) / Config.N_FOLD\n",
    "\n",
    "        print(f\"{score}\")\n",
    "\n",
    "    oof_score = evaluation(train_df[target].to_numpy().reshape(-1), oof_pred)\n",
    "    print(f\"OOF score is {oof_score}\")\n",
    "\n",
    "    return oof_pred, y_pred, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "# x_0\n",
      "==================================================\n",
      "fold0: 0.06174700103134624\n",
      "fold1: 0.0605609631914479\n",
      "fold2: 0.06351436655516013\n",
      "fold3: 0.06179586262802187\n",
      "fold4: 0.06265109872743597\n",
      "OOF score is 0.062053851351507865\n",
      "==================================================\n",
      "# y_0\n",
      "==================================================\n",
      "fold0: 0.03247910177590133\n",
      "fold1: 0.031880280058723905\n",
      "fold2: 0.032762417994991376\n",
      "fold3: 0.032133496387509196\n",
      "fold4: 0.033425131783826535\n",
      "OOF score is 0.03253608428632119\n",
      "==================================================\n",
      "# z_0\n",
      "==================================================\n",
      "fold0: 0.0257099779966058\n",
      "fold1: 0.0252207338544065\n",
      "fold2: 0.02631099853127826\n",
      "fold3: 0.026204107564326985\n",
      "fold4: 0.025486122076005487\n",
      "OOF score is 0.025786386242748125\n",
      "==================================================\n",
      "# x_1\n",
      "==================================================\n",
      "fold0: 0.13043021269970825\n",
      "fold1: 0.13101471204249607\n",
      "fold2: 0.13378873283816065\n",
      "fold3: 0.13050276567205252\n",
      "fold4: 0.1345828718821\n",
      "OOF score is 0.132063821360114\n",
      "==================================================\n",
      "# y_1\n",
      "==================================================\n",
      "fold0: 0.07388794513016497\n",
      "fold1: 0.07202221955105405\n",
      "fold2: 0.07444471055988178\n",
      "fold3: 0.07301776740381566\n",
      "fold4: 0.07485430244863393\n",
      "OOF score is 0.07364539461129756\n",
      "==================================================\n",
      "# z_1\n",
      "==================================================\n",
      "fold0: 0.05308792805950924\n",
      "fold1: 0.051733360141119906\n",
      "fold2: 0.053848772061505935\n",
      "fold3: 0.054152633999121375\n",
      "fold4: 0.05254474803514842\n",
      "OOF score is 0.05307348879221313\n",
      "==================================================\n",
      "# x_2\n",
      "==================================================\n",
      "fold0: 0.2223483529997832\n",
      "fold1: 0.22555214938030713\n",
      "fold2: 0.2251052112176891\n",
      "fold3: 0.22242667389632473\n",
      "fold4: 0.22824354035124036\n",
      "OOF score is 0.2247351305361536\n",
      "==================================================\n",
      "# y_2\n",
      "==================================================\n",
      "fold0: 0.12988379311018824\n",
      "fold1: 0.12783277880668603\n",
      "fold2: 0.13030309507549911\n",
      "fold3: 0.1296424869986028\n",
      "fold4: 0.13180480804478598\n",
      "OOF score is 0.1298933921858226\n",
      "==================================================\n",
      "# z_2\n",
      "==================================================\n",
      "fold0: 0.08070133862312448\n",
      "fold1: 0.07859886185273603\n",
      "fold2: 0.08194770724850431\n",
      "fold3: 0.08263712479186547\n",
      "fold4: 0.08044098055828891\n",
      "OOF score is 0.08086519883671123\n",
      "==================================================\n",
      "# x_3\n",
      "==================================================\n",
      "fold0: 0.3431789103179131\n",
      "fold1: 0.3516195566970327\n",
      "fold2: 0.3506641063679312\n",
      "fold3: 0.34538856849482275\n",
      "fold4: 0.3527589394182159\n",
      "OOF score is 0.3487218884524472\n",
      "==================================================\n",
      "# y_3\n",
      "==================================================\n",
      "fold0: 0.20837008313988223\n",
      "fold1: 0.21043826605392188\n",
      "fold2: 0.21349857500029013\n",
      "fold3: 0.2105157002352578\n",
      "fold4: 0.21470803702618593\n",
      "OOF score is 0.2115060599835945\n",
      "==================================================\n",
      "# z_3\n",
      "==================================================\n",
      "fold0: 0.1085174961070828\n",
      "fold1: 0.1059285958782025\n",
      "fold2: 0.11043728828566737\n",
      "fold3: 0.11120153916812991\n",
      "fold4: 0.10854758515099655\n",
      "OOF score is 0.10892649148764043\n",
      "==================================================\n",
      "# x_4\n",
      "==================================================\n",
      "fold0: 0.4925934212570427\n",
      "fold1: 0.5056651769093421\n",
      "fold2: 0.5040874629208216\n",
      "fold3: 0.499137442228078\n",
      "fold4: 0.5075667605090871\n",
      "OOF score is 0.5018098402580954\n",
      "==================================================\n",
      "# y_4\n",
      "==================================================\n",
      "fold0: 0.3149007391795326\n",
      "fold1: 0.3241160176376956\n",
      "fold2: 0.3238220379033934\n",
      "fold3: 0.3191924167042393\n",
      "fold4: 0.328380132432297\n",
      "OOF score is 0.32208210318775604\n",
      "==================================================\n",
      "# z_4\n",
      "==================================================\n",
      "fold0: 0.13689357137968483\n",
      "fold1: 0.13381029091097457\n",
      "fold2: 0.13918205354840718\n",
      "fold3: 0.1403799248085538\n",
      "fold4: 0.1371081151111948\n",
      "OOF score is 0.13747477775064773\n",
      "==================================================\n",
      "# x_5\n",
      "==================================================\n",
      "fold0: 0.6639191686515504\n",
      "fold1: 0.6873333846806172\n",
      "fold2: 0.6776374379972906\n",
      "fold3: 0.6742472460854435\n",
      "fold4: 0.6842403884895857\n",
      "OOF score is 0.6774752126135938\n",
      "==================================================\n",
      "# y_5\n",
      "==================================================\n",
      "fold0: 0.45324011941075826\n",
      "fold1: 0.47009933345583627\n",
      "fold2: 0.467606323086165\n",
      "fold3: 0.45629008076012223\n",
      "fold4: 0.4735598956339207\n",
      "OOF score is 0.4641588987105572\n",
      "==================================================\n",
      "# z_5\n",
      "==================================================\n",
      "fold0: 0.16593451820660413\n",
      "fold1: 0.1629496349471789\n",
      "fold2: 0.16871637230517975\n",
      "fold3: 0.16933423953168933\n",
      "fold4: 0.16604075644963906\n",
      "OOF score is 0.16659508905700338\n"
     ]
    }
   ],
   "source": [
    "# def add_dt_features(train: pl.DataFrame):\n",
    "#     \"\"\"dt秒後の特徴\"\"\"\n",
    "#     train = train.with_columns(\n",
    "#         # vt\n",
    "#         (pl.col(\"vEgo\") * pl.col(\"dt\").cast(pl.Float32)).alias(\"linear_movement@dt\"),\n",
    "#         # vt + 0.5at^2\n",
    "#         ((pl.col(\"vEgo\") + 0.5 * pl.col(\"aEgo\") * pl.col(\"dt\").cast(pl.Float32) ** 2).alias(\"movement@dt\")),\n",
    "#         # v + at\n",
    "#         (pl.col(\"vEgo\") + pl.col(\"aEgo\") * pl.col(\"dt\").cast(pl.Float32)).alias(\"velocity@dt\"),\n",
    "#     )\n",
    "#     return train\n",
    "\n",
    "\n",
    "models_dict = {}\n",
    "test_pred = []\n",
    "oof_pred = []\n",
    "for target in targets:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"# {target}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # # dt features\n",
    "    # dt = float(target.split(\"_\")[-1]) * 0.5 + 0.5\n",
    "    # train_df = train_df.with_columns(pl.lit(dt).alias(\"dt\"))\n",
    "    # test_df = test_df.with_columns(pl.lit(dt).alias(\"dt\"))\n",
    "    # train_df = add_dt_features(train_df)\n",
    "    # test_df = add_dt_features(test_df)\n",
    "    # features = list(set(features) | set([\"linear_movement@dt\", \"movement@dt\", \"velocity@dt\"]))\n",
    "\n",
    "    oof_preds_partial, y_pred_partial, models_partial = train_lgbm(target)\n",
    "    models_dict[target] = models_partial\n",
    "    oof_pred.append(oof_preds_partial)\n",
    "    test_pred.append(y_pred_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20852239498356806"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(train_df[targets].to_numpy(), np.vstack(oof_pred).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit ファイル作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_727, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th><th>ID</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>1.451966</td><td>-0.05001</td><td>0.000828</td><td>3.02292</td><td>-0.118906</td><td>0.003799</td><td>4.581418</td><td>-0.226131</td><td>0.005058</td><td>5.960247</td><td>-0.197664</td><td>0.001139</td><td>7.293397</td><td>-0.129997</td><td>0.012701</td><td>8.633616</td><td>0.008382</td><td>0.020247</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>0.949345</td><td>0.37931</td><td>0.002446</td><td>1.78144</td><td>0.997347</td><td>0.009869</td><td>2.416597</td><td>1.656721</td><td>0.016779</td><td>3.018493</td><td>2.455365</td><td>0.022162</td><td>3.717404</td><td>3.277484</td><td>0.041375</td><td>4.531961</td><td>4.347581</td><td>0.051499</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>1.574644</td><td>0.012977</td><td>-0.000396</td><td>3.284368</td><td>0.013113</td><td>0.001907</td><td>4.818523</td><td>0.027939</td><td>0.00021</td><td>6.35423</td><td>0.058121</td><td>-0.007488</td><td>7.929633</td><td>0.062045</td><td>-0.002237</td><td>9.17903</td><td>0.122829</td><td>-0.008452</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>0.834858</td><td>0.071709</td><td>-0.004797</td><td>1.669115</td><td>0.265695</td><td>-0.014526</td><td>2.469084</td><td>0.648576</td><td>-0.019613</td><td>2.996955</td><td>1.083865</td><td>-0.037253</td><td>3.617305</td><td>1.894096</td><td>-0.054112</td><td>4.219986</td><td>2.808786</td><td>-0.082212</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>0.819024</td><td>0.003951</td><td>-0.004481</td><td>1.425394</td><td>0.007575</td><td>-0.009175</td><td>1.895713</td><td>0.001957</td><td>-0.018596</td><td>2.230749</td><td>-0.009298</td><td>-0.03604</td><td>2.186012</td><td>-0.010073</td><td>-0.043591</td><td>1.669718</td><td>-0.026504</td><td>-0.049678</td><td>&quot;01d738e799d260a10f6324f78023b3…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6.537135</td><td>0.008542</td><td>0.014563</td><td>13.798478</td><td>0.041535</td><td>0.036641</td><td>21.022014</td><td>0.096245</td><td>0.052083</td><td>28.292109</td><td>0.186007</td><td>0.07237</td><td>35.626491</td><td>0.305797</td><td>0.084002</td><td>43.041352</td><td>0.443229</td><td>0.090601</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>6.988506</td><td>0.000371</td><td>-0.005645</td><td>14.857086</td><td>-0.016367</td><td>-0.041432</td><td>22.885263</td><td>-0.067638</td><td>-0.103802</td><td>31.022227</td><td>-0.134661</td><td>-0.222285</td><td>39.254969</td><td>-0.227326</td><td>-0.368399</td><td>47.522269</td><td>-0.336563</td><td>-0.55295</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>7.413827</td><td>-0.000097</td><td>0.016546</td><td>15.655867</td><td>-0.016144</td><td>0.04354</td><td>23.843606</td><td>-0.041808</td><td>0.073727</td><td>31.945971</td><td>-0.068803</td><td>0.117456</td><td>39.950944</td><td>-0.119747</td><td>0.172923</td><td>47.864668</td><td>-0.202397</td><td>0.236791</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>6.5249</td><td>-0.000282</td><td>0.018482</td><td>13.660526</td><td>-0.002987</td><td>0.0846</td><td>20.698266</td><td>0.007619</td><td>0.185175</td><td>27.682034</td><td>0.020512</td><td>0.36199</td><td>34.684556</td><td>0.095081</td><td>0.553349</td><td>41.590194</td><td>0.179893</td><td>0.79642</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>5.821521</td><td>-0.232853</td><td>0.008813</td><td>12.343806</td><td>-1.042234</td><td>0.015574</td><td>18.928862</td><td>-2.352702</td><td>0.015097</td><td>25.509667</td><td>-4.271434</td><td>-0.003059</td><td>32.014075</td><td>-6.406349</td><td>-0.046597</td><td>38.348723</td><td>-9.18127</td><td>-0.100566</td><td>&quot;ffc9272ee663f281a5f0ac533e97a1…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_727, 19)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ x_0      ┆ y_0       ┆ z_0       ┆ x_1       ┆ … ┆ x_5       ┆ y_5       ┆ z_5       ┆ ID        │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ str       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.451966 ┆ -0.05001  ┆ 0.000828  ┆ 3.02292   ┆ … ┆ 8.633616  ┆ 0.008382  ┆ 0.020247  ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 0.949345 ┆ 0.37931   ┆ 0.002446  ┆ 1.78144   ┆ … ┆ 4.531961  ┆ 4.347581  ┆ 0.051499  ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 1.574644 ┆ 0.012977  ┆ -0.000396 ┆ 3.284368  ┆ … ┆ 9.17903   ┆ 0.122829  ┆ -0.008452 ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 0.834858 ┆ 0.071709  ┆ -0.004797 ┆ 1.669115  ┆ … ┆ 4.219986  ┆ 2.808786  ┆ -0.082212 ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 0.819024 ┆ 0.003951  ┆ -0.004481 ┆ 1.425394  ┆ … ┆ 1.669718  ┆ -0.026504 ┆ -0.049678 ┆ 01d738e79 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9d260a10f │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6324f7802 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 3b3…      │\n",
       "│ …        ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 6.537135 ┆ 0.008542  ┆ 0.014563  ┆ 13.798478 ┆ … ┆ 43.041352 ┆ 0.443229  ┆ 0.090601  ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 6.988506 ┆ 0.000371  ┆ -0.005645 ┆ 14.857086 ┆ … ┆ 47.522269 ┆ -0.336563 ┆ -0.55295  ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 7.413827 ┆ -0.000097 ┆ 0.016546  ┆ 15.655867 ┆ … ┆ 47.864668 ┆ -0.202397 ┆ 0.236791  ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 6.5249   ┆ -0.000282 ┆ 0.018482  ┆ 13.660526 ┆ … ┆ 41.590194 ┆ 0.179893  ┆ 0.79642   ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 5.821521 ┆ -0.232853 ┆ 0.008813  ┆ 12.343806 ┆ … ┆ 38.348723 ┆ -9.18127  ┆ -0.100566 ┆ ffc9272ee │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 663f281a5 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f0ac533e9 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7a1…      │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_col_names = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "sub_df = pl.DataFrame(np.vstack(test_pred).T, schema=sub_col_names)\n",
    "sub_df = sub_df.with_columns(pl.Series(\"ID\", test_df[\"ID\"]))\n",
    "sub_df.write_csv(os.path.join(CFG[\"output_dir\"], \"submission.csv\"))\n",
    "\n",
    "oof_df = pl.DataFrame(np.vstack(oof_pred).T, schema=sub_col_names)\n",
    "oof_df = oof_df.with_columns(pl.Series(\"ID\", train_df[\"ID\"]))\n",
    "oof_df.write_csv(os.path.join(CFG[\"output_dir\"], \"oof.csv\"))\n",
    "\n",
    "display(sub_df)\n",
    "sub_df.drop(\"ID\").write_csv(os.path.join(CFG[\"output_dir\"], \"submission_wo_ID.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
