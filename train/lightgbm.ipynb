{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original: https://www.guruguru.science/competitions/25/discussions/8b97734b-1f76-4075-b1af-5d227d6b70e8/ (@yururoi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/*\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PACKAGE_DIR = \"/kaggle/src\"\n",
    "sys.path.append(PACKAGE_DIR)\n",
    "sys.path.append(os.path.join(PACKAGE_DIR, \"Penguin-ML-Library\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 14:36:49.960723: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-21 14:36:49.994592: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "set seed: 46\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from penguinml.utils.logger import get_logger, init_logger\n",
    "from penguinml.utils.set_seed import seed_base\n",
    "\n",
    "MODEL_NAME = \"lightgbm\"\n",
    "CFG = yaml.safe_load(open(os.path.join(PACKAGE_DIR, \"config.yaml\"), \"r\"))\n",
    "print(CFG[MODEL_NAME][\"execution\"][\"exp_id\"])\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG[MODEL_NAME]['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "init_logger(f\"{ CFG[MODEL_NAME]['execution']['exp_id']}.log\")\n",
    "logger = get_logger(\"main\")\n",
    "seed_base(CFG[MODEL_NAME][\"execution\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    N_FOLD = 5\n",
    "    RANDOM_SATE = 42\n",
    "\n",
    "\n",
    "NB = \"exp1015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"/kaggle\")\n",
    "DATA_DIR = ROOT_DIR / Path(\"input/atmaCup#18_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(DATA_DIR / \"train_features.csv\")\n",
    "test_df = pl.read_csv(DATA_DIR / \"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df と test_dfを結合（特徴量エンジニアリングをしやすくするため）\n",
    "_all_df = pl.concat([train_df, test_df], how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = [\n",
    "    \"vEgo\",\n",
    "    \"aEgo\",\n",
    "    \"steeringAngleDeg\",\n",
    "    \"steeringTorque\",\n",
    "    \"gas\",\n",
    "]  # 同一シーンから集計する値のカラム名\n",
    "\n",
    "# 同一シーンから特徴量作成\n",
    "exprs = []\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(-1).over(\"scene\").alias(f\"{agg_col}_shift-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(1).over(\"scene\").alias(f\"{agg_col}_shift1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(-1).over(\"scene\").alias(f\"{agg_col}_diff-1\") for agg_col in agg_cols\n",
    "]  # 1ステップ前の時間の値との差分\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(1).over(\"scene\").alias(f\"{agg_col}_diff1\") for agg_col in agg_cols\n",
    "]  # 1ステップ後の時間の値との差分\n",
    "exprs += [pl.col(agg_col).mean().over(\"scene\").alias(f\"{agg_col}_mean\") for agg_col in agg_cols]  # 同一シーンの平均値\n",
    "exprs += [pl.col(agg_col).std().over(\"scene\").alias(f\"{agg_col}_std\") for agg_col in agg_cols]  # 同一シーンの標準偏差\n",
    "exprs += [pl.col(agg_col).max().over(\"scene\").alias(f\"{agg_col}_max\") for agg_col in agg_cols]  # 同一シーンの最大値\n",
    "exprs += [pl.col(agg_col).min().over(\"scene\").alias(f\"{agg_col}_min\") for agg_col in agg_cols]  # 同一シーンの最小値\n",
    "\n",
    "_all_df = (\n",
    "    _all_df.with_columns(\n",
    "        # ID からシーンとデシ秒を作成\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(0).alias(\"scene\"),\n",
    "        pl.col(\"ID\").str.split(\"_\").list.get(1).cast(pl.Int32).alias(\"decisecond\"),\n",
    "    )\n",
    "    .sort(\n",
    "        # shiftと diffが時系列順に並んでいる必要があるためシーンごとに時間軸でソート\n",
    "        \"scene\",\n",
    "        \"decisecond\",\n",
    "    )\n",
    "    .with_columns(exprs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = pl.read_csv(CFG[\"dataset\"][\"train_fold_path\"]).rename({\"sceneID\": \"scene\"})\n",
    "_all_df = _all_df.join(train_folds, how=\"left\", on=\"scene\")\n",
    "# assert train_df[\"fold\"].null_count() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45098/45098 [00:00<00:00, 75242.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# YOLOの検出結果\n",
    "import json\n",
    "\n",
    "yolo_paths = glob.glob(\"/kaggle/input/yolo-det/det/*.json\")\n",
    "yolo_dfs = []\n",
    "for path in tqdm(yolo_paths):\n",
    "    ID = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    yolo_feature = {\n",
    "        \"ID\": ID,\n",
    "        \"num_objects\": len(data),\n",
    "    }\n",
    "    for bbox in data:\n",
    "        if bbox[\"x1\"] == bbox[\"x2\"] or bbox[\"y1\"] == bbox[\"y2\"]:\n",
    "            continue\n",
    "\n",
    "        if bbox[\"cls\"] != \"car\":\n",
    "            continue\n",
    "\n",
    "        # count\n",
    "        if bbox[\"cls\"] not in yolo_feature:\n",
    "            yolo_feature[bbox[\"cls\"]] = 0\n",
    "        yolo_feature[bbox[\"cls\"]] += 1\n",
    "\n",
    "        # 最も横方向が中央にあるものの情報\n",
    "        if f\"center_x_{bbox['cls']}\" not in yolo_feature:\n",
    "            yolo_feature[f\"center_x_{bbox['cls']}\"] = -1\n",
    "        current_dist = abs(yolo_feature[f\"center_x_{bbox['cls']}\"] - 64)\n",
    "        now_center_x = (bbox[\"x1\"] + bbox[\"x2\"]) / 2\n",
    "        now_dist = abs(now_center_x - 64)\n",
    "        if now_dist < current_dist:\n",
    "            yolo_feature[f\"center_x_{bbox['cls']}\"] = now_center_x\n",
    "            yolo_feature[f\"center_y_{bbox['cls']}\"] = (bbox[\"y1\"] + bbox[\"y2\"]) / 2\n",
    "            yolo_feature[f\"width_{bbox['cls']}\"] = bbox[\"x2\"] - bbox[\"x1\"]\n",
    "            yolo_feature[f\"height_{bbox['cls']}\"] = bbox[\"y2\"] - bbox[\"y1\"]\n",
    "            yolo_feature[f\"bottom_{bbox['cls']}\"] = bbox[\"y2\"]\n",
    "            yolo_feature[f\"area_{bbox['cls']}\"] = (bbox[\"x2\"] - bbox[\"x1\"]) * (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "            yolo_feature[f\"aspect_ratio_{bbox['cls']}\"] = (bbox[\"x2\"] - bbox[\"x1\"]) / (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "            yolo_feature[f\"conf_{bbox['cls']}\"] = bbox[\"conf\"]\n",
    "    yolo_dfs.append(yolo_feature)\n",
    "yolo_df = pl.DataFrame(yolo_dfs)\n",
    "\n",
    "_all_df = _all_df.join(yolo_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45098 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 45098/45098 [00:18<00:00, 2387.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# depth\n",
    "import cv2\n",
    "\n",
    "depth_features = []\n",
    "for ID in tqdm(_all_df[\"ID\"]):\n",
    "    path = f\"/kaggle/input/depth_image/depth/{ID}/0.png\"\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    patch_size = 16\n",
    "    this_features = {\"ID\": ID}\n",
    "    for i in range(0, 128, patch_size):\n",
    "        for j in range(0, 64, patch_size):\n",
    "            patch = image[i : i + patch_size, j : j + patch_size]\n",
    "            this_features[f\"patch_{i}_{j}_mean\"] = np.mean(patch)\n",
    "            this_features[f\"patch_{i}_{j}_median\"] = np.median(patch)\n",
    "    depth_features.append(this_features)\n",
    "depth_df = pl.DataFrame(depth_features)\n",
    "_all_df = _all_df.join(depth_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aEgo', 'aEgo_diff-1', 'aEgo_diff1', 'aEgo_max', 'aEgo_mean', 'aEgo_min', 'aEgo_shift-1', 'aEgo_shift1', 'aEgo_std', 'area_car', 'aspect_ratio_car', 'bottom_car', 'brake', 'brakePressed', 'car', 'center_x_car', 'center_y_car', 'conf_car', 'decisecond', 'gas', 'gasPressed', 'gas_diff-1', 'gas_diff1', 'gas_max', 'gas_mean', 'gas_min', 'gas_shift-1', 'gas_shift1', 'gas_std', 'height_car', 'leftBlinker', 'num_objects', 'patch_0_0_mean', 'patch_0_0_median', 'patch_0_16_mean', 'patch_0_16_median', 'patch_0_32_mean', 'patch_0_32_median', 'patch_0_48_mean', 'patch_0_48_median', 'patch_112_0_mean', 'patch_112_0_median', 'patch_112_16_mean', 'patch_112_16_median', 'patch_112_32_mean', 'patch_112_32_median', 'patch_112_48_mean', 'patch_112_48_median', 'patch_16_0_mean', 'patch_16_0_median', 'patch_16_16_mean', 'patch_16_16_median', 'patch_16_32_mean', 'patch_16_32_median', 'patch_16_48_mean', 'patch_16_48_median', 'patch_32_0_mean', 'patch_32_0_median', 'patch_32_16_mean', 'patch_32_16_median', 'patch_32_32_mean', 'patch_32_32_median', 'patch_32_48_mean', 'patch_32_48_median', 'patch_48_0_mean', 'patch_48_0_median', 'patch_48_16_mean', 'patch_48_16_median', 'patch_48_32_mean', 'patch_48_32_median', 'patch_48_48_mean', 'patch_48_48_median', 'patch_64_0_mean', 'patch_64_0_median', 'patch_64_16_mean', 'patch_64_16_median', 'patch_64_32_mean', 'patch_64_32_median', 'patch_64_48_mean', 'patch_64_48_median', 'patch_80_0_mean', 'patch_80_0_median', 'patch_80_16_mean', 'patch_80_16_median', 'patch_80_32_mean', 'patch_80_32_median', 'patch_80_48_mean', 'patch_80_48_median', 'patch_96_0_mean', 'patch_96_0_median', 'patch_96_16_mean', 'patch_96_16_median', 'patch_96_32_mean', 'patch_96_32_median', 'patch_96_48_mean', 'patch_96_48_median', 'rightBlinker', 'steeringAngleDeg', 'steeringAngleDeg_diff-1', 'steeringAngleDeg_diff1', 'steeringAngleDeg_max', 'steeringAngleDeg_mean', 'steeringAngleDeg_min', 'steeringAngleDeg_shift-1', 'steeringAngleDeg_shift1', 'steeringAngleDeg_std', 'steeringTorque', 'steeringTorque_diff-1', 'steeringTorque_diff1', 'steeringTorque_max', 'steeringTorque_mean', 'steeringTorque_min', 'steeringTorque_shift-1', 'steeringTorque_shift1', 'steeringTorque_std', 'vEgo', 'vEgo_diff-1', 'vEgo_diff1', 'vEgo_max', 'vEgo_mean', 'vEgo_min', 'vEgo_shift-1', 'vEgo_shift1', 'vEgo_std', 'width_car']\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "\n",
    "# 使う特徴量を指定するより使わない特徴量を指定するほうが試行錯誤が楽\n",
    "del_columns = targets + [\"ID\", \"scene\", \"gearShifter\", \"fold\"]\n",
    "\n",
    "features = list(set(_all_df.columns) - set(del_columns))\n",
    "features.sort()\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAEを計算\n",
    "def evaluation(true_values, pred_values):\n",
    "    abs_diff = abs(true_values - pred_values)\n",
    "    mae = np.mean(\n",
    "        abs_diff.reshape(\n",
    "            -1,\n",
    "        )\n",
    "    )\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encdoding\n",
    "categorical_columns = [\"gearShifter\"]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    _all_df = _all_df.with_columns(pl.Series(le.fit_transform(_all_df[col])).alias(f\"{col}_le\"))\n",
    "cate_features = [f\"{col}_le\" for c in categorical_columns]\n",
    "features = list(set(features) | set(cate_features))\n",
    "\n",
    "# count encoding\n",
    "count_enc = [\"gearShifter\"]\n",
    "_all_df = _all_df.with_columns([pl.col(c).count().over(c).alias(f\"{c}_count\") for c in count_enc])\n",
    "count_features = [f\"{c}_count\" for c in count_enc]\n",
    "features = list(set(features) | set(count_features))\n",
    "\n",
    "\n",
    "train_df = train_df.join(_all_df, how=\"left\", on=\"ID\")\n",
    "test_df = test_df.join(_all_df, how=\"left\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt\n",
    "train_dfs = []\n",
    "test_dfs = []\n",
    "for i, target in enumerate(targets):\n",
    "    this_train_df = train_df.clone()\n",
    "    this_train_df = (\n",
    "        this_train_df.with_columns(\n",
    "            pl.lit(1.0).alias(f\"target_is_{target}\"),\n",
    "            pl.lit(target).alias(\"target_name\"),\n",
    "        )\n",
    "        .rename({target: \"target\"})\n",
    "        .drop(set(targets) - {target})\n",
    "    )\n",
    "\n",
    "    this_test_df = test_df.clone()\n",
    "    this_test_df = (\n",
    "        this_test_df.with_columns(\n",
    "            pl.lit(1.0).alias(f\"target_is_{target}\"),\n",
    "            pl.lit(target).alias(\"target_name\"),\n",
    "        )\n",
    "        .rename({target: \"target\"})\n",
    "        .drop(set(targets) - {target})\n",
    "    )\n",
    "\n",
    "    train_dfs.append(this_train_df)\n",
    "    test_dfs.append(this_test_df)\n",
    "    features = list(set(features) | {f\"target_is_{target}\"})\n",
    "\n",
    "train_lgbm_df = pl.concat(train_dfs, how=\"diagonal\")\n",
    "test_lgbm_df = pl.concat(test_dfs, how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(target):\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"mae\",  # 今回の評価指標がMAEを使用\n",
    "        \"objective\": \"regression\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": Config.RANDOM_SATE,\n",
    "        \"learning_rate\": 0.01,\n",
    "        # \"device\": \"gpu\"\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "\n",
    "    oof_pred = np.zeros(len(train_lgbm_df))\n",
    "    y_pred = np.zeros(len(test_lgbm_df))\n",
    "    models = []\n",
    "    cv_scores = {}\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"fold{fold}: \", end=\"\")\n",
    "\n",
    "        # TrainとTestに分割\n",
    "        x_train = train_lgbm_df.filter(pl.col(\"fold\") != fold).select(features)\n",
    "        x_val = train_lgbm_df.filter(pl.col(\"fold\") == fold).select(features)\n",
    "        y_train = train_lgbm_df.filter(pl.col(\"fold\") != fold).select(target)\n",
    "        y_val = train_lgbm_df.filter(pl.col(\"fold\") == fold).select(target)\n",
    "\n",
    "        test = test_lgbm_df[features]\n",
    "\n",
    "        # create Dataset\n",
    "        train_set = lgb.Dataset(\n",
    "            x_train.to_pandas(),\n",
    "            y_train.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "        val_set = lgb.Dataset(\n",
    "            x_val.to_pandas(),\n",
    "            y_val.to_pandas(),\n",
    "            categorical_feature=cate_features,\n",
    "            free_raw_data=False,\n",
    "        )\n",
    "\n",
    "        # train\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set,\n",
    "            valid_sets=[train_set, val_set],\n",
    "            num_boost_round=100000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=500, verbose=False),\n",
    "                lgb.log_evaluation(500),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        fold_pred = model.predict(x_val.to_pandas())\n",
    "\n",
    "        score = evaluation(y_val.to_numpy().reshape(-1), fold_pred)\n",
    "        cv_scores[f\"cv{fold}\"] = score\n",
    "\n",
    "        # oof_pred[test_index] = fold_pred\n",
    "        oof_pred[train_lgbm_df[\"fold\"].to_numpy() == fold] = fold_pred\n",
    "\n",
    "        y_pred += model.predict(test.to_pandas()) / Config.N_FOLD\n",
    "\n",
    "        print(f\"{score}\")\n",
    "\n",
    "    oof_score = evaluation(train_lgbm_df[target].to_numpy().reshape(-1), oof_pred)\n",
    "    print(f\"OOF score is {oof_score}\")\n",
    "\n",
    "    return oof_pred, y_pred, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0: [500]\ttraining's l1: 0.335331\tvalid_1's l1: 0.331167\n",
      "[1000]\ttraining's l1: 0.280476\tvalid_1's l1: 0.279279\n",
      "[1500]\ttraining's l1: 0.261118\tvalid_1's l1: 0.261549\n",
      "[2000]\ttraining's l1: 0.247815\tvalid_1's l1: 0.249986\n",
      "[2500]\ttraining's l1: 0.239008\tvalid_1's l1: 0.242891\n",
      "[3000]\ttraining's l1: 0.23277\tvalid_1's l1: 0.238476\n",
      "[3500]\ttraining's l1: 0.228558\tvalid_1's l1: 0.235832\n",
      "[4000]\ttraining's l1: 0.224797\tvalid_1's l1: 0.233572\n",
      "[4500]\ttraining's l1: 0.221498\tvalid_1's l1: 0.231741\n",
      "[5000]\ttraining's l1: 0.218041\tvalid_1's l1: 0.229539\n",
      "[5500]\ttraining's l1: 0.215213\tvalid_1's l1: 0.227899\n",
      "[6000]\ttraining's l1: 0.212918\tvalid_1's l1: 0.226867\n",
      "[6500]\ttraining's l1: 0.210982\tvalid_1's l1: 0.226148\n",
      "[7000]\ttraining's l1: 0.209116\tvalid_1's l1: 0.225492\n",
      "[7500]\ttraining's l1: 0.207316\tvalid_1's l1: 0.224891\n",
      "[8000]\ttraining's l1: 0.205584\tvalid_1's l1: 0.224275\n",
      "[8500]\ttraining's l1: 0.20391\tvalid_1's l1: 0.223701\n",
      "[9000]\ttraining's l1: 0.202339\tvalid_1's l1: 0.223215\n",
      "[9500]\ttraining's l1: 0.200741\tvalid_1's l1: 0.222648\n",
      "[10000]\ttraining's l1: 0.199355\tvalid_1's l1: 0.222279\n",
      "[10500]\ttraining's l1: 0.197963\tvalid_1's l1: 0.221914\n",
      "[11000]\ttraining's l1: 0.196737\tvalid_1's l1: 0.221652\n",
      "[11500]\ttraining's l1: 0.195429\tvalid_1's l1: 0.221276\n",
      "[12000]\ttraining's l1: 0.194247\tvalid_1's l1: 0.221033\n",
      "[12500]\ttraining's l1: 0.193099\tvalid_1's l1: 0.220781\n",
      "[13000]\ttraining's l1: 0.19195\tvalid_1's l1: 0.220507\n",
      "[13500]\ttraining's l1: 0.190882\tvalid_1's l1: 0.220318\n",
      "[14000]\ttraining's l1: 0.189822\tvalid_1's l1: 0.22014\n",
      "[14500]\ttraining's l1: 0.188742\tvalid_1's l1: 0.219881\n",
      "[15000]\ttraining's l1: 0.187635\tvalid_1's l1: 0.219597\n",
      "[15500]\ttraining's l1: 0.186511\tvalid_1's l1: 0.219299\n",
      "[16000]\ttraining's l1: 0.185544\tvalid_1's l1: 0.2191\n",
      "[16500]\ttraining's l1: 0.184646\tvalid_1's l1: 0.218972\n",
      "[17000]\ttraining's l1: 0.18372\tvalid_1's l1: 0.218829\n",
      "[17500]\ttraining's l1: 0.182747\tvalid_1's l1: 0.218608\n",
      "[18000]\ttraining's l1: 0.181834\tvalid_1's l1: 0.218438\n",
      "[18500]\ttraining's l1: 0.180823\tvalid_1's l1: 0.21816\n",
      "[19000]\ttraining's l1: 0.17984\tvalid_1's l1: 0.217914\n",
      "[19500]\ttraining's l1: 0.178975\tvalid_1's l1: 0.217744\n",
      "[20000]\ttraining's l1: 0.178045\tvalid_1's l1: 0.217493\n",
      "[20500]\ttraining's l1: 0.177145\tvalid_1's l1: 0.217281\n",
      "[21000]\ttraining's l1: 0.176155\tvalid_1's l1: 0.216937\n",
      "[21500]\ttraining's l1: 0.175398\tvalid_1's l1: 0.216844\n",
      "[22000]\ttraining's l1: 0.174642\tvalid_1's l1: 0.216731\n",
      "[22500]\ttraining's l1: 0.173921\tvalid_1's l1: 0.21665\n",
      "[23000]\ttraining's l1: 0.17317\tvalid_1's l1: 0.216563\n",
      "[23500]\ttraining's l1: 0.172434\tvalid_1's l1: 0.21647\n",
      "[24000]\ttraining's l1: 0.171725\tvalid_1's l1: 0.216376\n",
      "[24500]\ttraining's l1: 0.171009\tvalid_1's l1: 0.2163\n",
      "[25000]\ttraining's l1: 0.170264\tvalid_1's l1: 0.216179\n",
      "[25500]\ttraining's l1: 0.169543\tvalid_1's l1: 0.216057\n",
      "[26000]\ttraining's l1: 0.168798\tvalid_1's l1: 0.215915\n",
      "[26500]\ttraining's l1: 0.168083\tvalid_1's l1: 0.215786\n",
      "[27000]\ttraining's l1: 0.167421\tvalid_1's l1: 0.215703\n",
      "[27500]\ttraining's l1: 0.166748\tvalid_1's l1: 0.215622\n",
      "[28000]\ttraining's l1: 0.166101\tvalid_1's l1: 0.215549\n",
      "[28500]\ttraining's l1: 0.165438\tvalid_1's l1: 0.215464\n",
      "[29000]\ttraining's l1: 0.164732\tvalid_1's l1: 0.215351\n",
      "[29500]\ttraining's l1: 0.164101\tvalid_1's l1: 0.215292\n",
      "[30000]\ttraining's l1: 0.163457\tvalid_1's l1: 0.215214\n",
      "[30500]\ttraining's l1: 0.162788\tvalid_1's l1: 0.215107\n",
      "[31000]\ttraining's l1: 0.162153\tvalid_1's l1: 0.215021\n",
      "[31500]\ttraining's l1: 0.16153\tvalid_1's l1: 0.214956\n",
      "[32000]\ttraining's l1: 0.160936\tvalid_1's l1: 0.214907\n",
      "[32500]\ttraining's l1: 0.160319\tvalid_1's l1: 0.214825\n",
      "[33000]\ttraining's l1: 0.159705\tvalid_1's l1: 0.21475\n",
      "[33500]\ttraining's l1: 0.159106\tvalid_1's l1: 0.214675\n",
      "[34000]\ttraining's l1: 0.158512\tvalid_1's l1: 0.214604\n",
      "[34500]\ttraining's l1: 0.157947\tvalid_1's l1: 0.214548\n",
      "[35000]\ttraining's l1: 0.157362\tvalid_1's l1: 0.214479\n",
      "[35500]\ttraining's l1: 0.156802\tvalid_1's l1: 0.214424\n",
      "[36000]\ttraining's l1: 0.156242\tvalid_1's l1: 0.214391\n",
      "[36500]\ttraining's l1: 0.155685\tvalid_1's l1: 0.214324\n",
      "[37000]\ttraining's l1: 0.155153\tvalid_1's l1: 0.214281\n",
      "[37500]\ttraining's l1: 0.154613\tvalid_1's l1: 0.214231\n",
      "[38000]\ttraining's l1: 0.154081\tvalid_1's l1: 0.214194\n",
      "[38500]\ttraining's l1: 0.153542\tvalid_1's l1: 0.214127\n",
      "[39000]\ttraining's l1: 0.153025\tvalid_1's l1: 0.214082\n",
      "[39500]\ttraining's l1: 0.152496\tvalid_1's l1: 0.214037\n",
      "[40000]\ttraining's l1: 0.151983\tvalid_1's l1: 0.213986\n",
      "[40500]\ttraining's l1: 0.15149\tvalid_1's l1: 0.213954\n",
      "[41000]\ttraining's l1: 0.151002\tvalid_1's l1: 0.21392\n",
      "[41500]\ttraining's l1: 0.150518\tvalid_1's l1: 0.213902\n",
      "[42000]\ttraining's l1: 0.150016\tvalid_1's l1: 0.213831\n",
      "[42500]\ttraining's l1: 0.149526\tvalid_1's l1: 0.213799\n",
      "[43000]\ttraining's l1: 0.14903\tvalid_1's l1: 0.213761\n",
      "[43500]\ttraining's l1: 0.148552\tvalid_1's l1: 0.213733\n",
      "[44000]\ttraining's l1: 0.148085\tvalid_1's l1: 0.213703\n",
      "[44500]\ttraining's l1: 0.147624\tvalid_1's l1: 0.213682\n",
      "[45000]\ttraining's l1: 0.147166\tvalid_1's l1: 0.213681\n",
      "0.21367539296642338\n",
      "fold1: [500]\ttraining's l1: 0.332746\tvalid_1's l1: 0.336607\n",
      "[1000]\ttraining's l1: 0.280809\tvalid_1's l1: 0.28523\n",
      "[1500]\ttraining's l1: 0.259444\tvalid_1's l1: 0.26511\n",
      "[2000]\ttraining's l1: 0.24712\tvalid_1's l1: 0.254104\n",
      "[2500]\ttraining's l1: 0.238056\tvalid_1's l1: 0.246034\n",
      "[3000]\ttraining's l1: 0.231684\tvalid_1's l1: 0.240877\n",
      "[3500]\ttraining's l1: 0.227164\tvalid_1's l1: 0.237712\n",
      "[4000]\ttraining's l1: 0.223258\tvalid_1's l1: 0.235095\n",
      "[4500]\ttraining's l1: 0.21992\tvalid_1's l1: 0.232977\n",
      "[5000]\ttraining's l1: 0.217142\tvalid_1's l1: 0.231477\n",
      "[5500]\ttraining's l1: 0.214554\tvalid_1's l1: 0.230127\n",
      "[6000]\ttraining's l1: 0.21236\tvalid_1's l1: 0.229141\n",
      "[6500]\ttraining's l1: 0.21028\tvalid_1's l1: 0.2282\n",
      "[7000]\ttraining's l1: 0.208299\tvalid_1's l1: 0.227288\n",
      "[7500]\ttraining's l1: 0.206423\tvalid_1's l1: 0.226507\n",
      "[8000]\ttraining's l1: 0.204777\tvalid_1's l1: 0.225932\n",
      "[8500]\ttraining's l1: 0.20314\tvalid_1's l1: 0.225331\n",
      "[9000]\ttraining's l1: 0.201567\tvalid_1's l1: 0.224805\n",
      "[9500]\ttraining's l1: 0.200064\tvalid_1's l1: 0.224313\n",
      "[10000]\ttraining's l1: 0.19854\tvalid_1's l1: 0.223745\n",
      "[10500]\ttraining's l1: 0.197183\tvalid_1's l1: 0.223346\n",
      "[11000]\ttraining's l1: 0.195918\tvalid_1's l1: 0.223003\n",
      "[11500]\ttraining's l1: 0.194644\tvalid_1's l1: 0.222693\n",
      "[12000]\ttraining's l1: 0.193503\tvalid_1's l1: 0.222446\n",
      "[12500]\ttraining's l1: 0.19239\tvalid_1's l1: 0.222218\n",
      "[13000]\ttraining's l1: 0.191302\tvalid_1's l1: 0.222003\n",
      "[13500]\ttraining's l1: 0.190263\tvalid_1's l1: 0.221783\n",
      "[14000]\ttraining's l1: 0.189236\tvalid_1's l1: 0.221611\n",
      "[14500]\ttraining's l1: 0.18819\tvalid_1's l1: 0.221414\n",
      "[15000]\ttraining's l1: 0.187135\tvalid_1's l1: 0.221219\n",
      "[15500]\ttraining's l1: 0.186146\tvalid_1's l1: 0.221086\n",
      "[16000]\ttraining's l1: 0.185171\tvalid_1's l1: 0.220941\n",
      "[16500]\ttraining's l1: 0.184233\tvalid_1's l1: 0.22077\n",
      "[17000]\ttraining's l1: 0.183273\tvalid_1's l1: 0.220584\n",
      "[17500]\ttraining's l1: 0.182294\tvalid_1's l1: 0.220365\n",
      "[18000]\ttraining's l1: 0.181389\tvalid_1's l1: 0.220198\n",
      "[18500]\ttraining's l1: 0.18022\tvalid_1's l1: 0.219737\n",
      "[19000]\ttraining's l1: 0.179277\tvalid_1's l1: 0.21953\n",
      "[19500]\ttraining's l1: 0.178397\tvalid_1's l1: 0.219355\n",
      "[20000]\ttraining's l1: 0.177546\tvalid_1's l1: 0.219244\n",
      "[20500]\ttraining's l1: 0.176716\tvalid_1's l1: 0.219147\n",
      "[21000]\ttraining's l1: 0.175834\tvalid_1's l1: 0.218938\n",
      "[21500]\ttraining's l1: 0.174931\tvalid_1's l1: 0.218704\n",
      "[22000]\ttraining's l1: 0.174107\tvalid_1's l1: 0.218588\n",
      "[22500]\ttraining's l1: 0.173292\tvalid_1's l1: 0.218453\n",
      "[23000]\ttraining's l1: 0.172507\tvalid_1's l1: 0.218321\n",
      "[23500]\ttraining's l1: 0.171642\tvalid_1's l1: 0.218067\n",
      "[24000]\ttraining's l1: 0.170883\tvalid_1's l1: 0.217937\n",
      "[24500]\ttraining's l1: 0.170123\tvalid_1's l1: 0.217779\n",
      "[25000]\ttraining's l1: 0.169363\tvalid_1's l1: 0.217663\n",
      "[25500]\ttraining's l1: 0.168662\tvalid_1's l1: 0.217596\n",
      "[26000]\ttraining's l1: 0.167981\tvalid_1's l1: 0.217539\n",
      "[26500]\ttraining's l1: 0.167303\tvalid_1's l1: 0.217461\n",
      "[27000]\ttraining's l1: 0.166625\tvalid_1's l1: 0.217354\n",
      "[27500]\ttraining's l1: 0.165962\tvalid_1's l1: 0.217266\n",
      "[28000]\ttraining's l1: 0.165326\tvalid_1's l1: 0.217215\n",
      "[28500]\ttraining's l1: 0.164695\tvalid_1's l1: 0.217164\n",
      "[29000]\ttraining's l1: 0.164071\tvalid_1's l1: 0.217115\n",
      "[29500]\ttraining's l1: 0.163448\tvalid_1's l1: 0.21705\n",
      "[30000]\ttraining's l1: 0.162835\tvalid_1's l1: 0.216986\n",
      "[30500]\ttraining's l1: 0.16219\tvalid_1's l1: 0.216886\n",
      "[31000]\ttraining's l1: 0.161581\tvalid_1's l1: 0.216822\n",
      "[31500]\ttraining's l1: 0.160978\tvalid_1's l1: 0.216751\n",
      "[32000]\ttraining's l1: 0.160368\tvalid_1's l1: 0.216674\n",
      "[32500]\ttraining's l1: 0.159751\tvalid_1's l1: 0.216599\n",
      "[33000]\ttraining's l1: 0.15915\tvalid_1's l1: 0.216516\n",
      "[33500]\ttraining's l1: 0.158482\tvalid_1's l1: 0.216394\n",
      "[34000]\ttraining's l1: 0.157831\tvalid_1's l1: 0.216293\n",
      "[34500]\ttraining's l1: 0.157171\tvalid_1's l1: 0.21617\n",
      "[35000]\ttraining's l1: 0.156592\tvalid_1's l1: 0.216111\n",
      "[35500]\ttraining's l1: 0.15599\tvalid_1's l1: 0.216023\n",
      "[36000]\ttraining's l1: 0.155447\tvalid_1's l1: 0.215995\n",
      "[36500]\ttraining's l1: 0.154891\tvalid_1's l1: 0.215963\n",
      "[37000]\ttraining's l1: 0.154348\tvalid_1's l1: 0.215925\n",
      "[37500]\ttraining's l1: 0.153802\tvalid_1's l1: 0.215888\n",
      "[38000]\ttraining's l1: 0.153278\tvalid_1's l1: 0.21584\n",
      "[38500]\ttraining's l1: 0.152763\tvalid_1's l1: 0.215816\n",
      "[39000]\ttraining's l1: 0.152241\tvalid_1's l1: 0.215804\n",
      "[39500]\ttraining's l1: 0.151751\tvalid_1's l1: 0.215798\n",
      "[40000]\ttraining's l1: 0.15125\tvalid_1's l1: 0.215782\n",
      "[40500]\ttraining's l1: 0.150761\tvalid_1's l1: 0.215756\n",
      "[41000]\ttraining's l1: 0.150263\tvalid_1's l1: 0.21572\n",
      "[41500]\ttraining's l1: 0.149791\tvalid_1's l1: 0.215693\n",
      "[42000]\ttraining's l1: 0.14932\tvalid_1's l1: 0.215658\n",
      "[42500]\ttraining's l1: 0.148836\tvalid_1's l1: 0.215638\n",
      "[43000]\ttraining's l1: 0.148321\tvalid_1's l1: 0.215559\n",
      "[43500]\ttraining's l1: 0.147821\tvalid_1's l1: 0.215513\n",
      "[44000]\ttraining's l1: 0.147377\tvalid_1's l1: 0.2155\n",
      "[44500]\ttraining's l1: 0.146932\tvalid_1's l1: 0.215493\n",
      "[45000]\ttraining's l1: 0.146478\tvalid_1's l1: 0.215475\n",
      "[45500]\ttraining's l1: 0.146014\tvalid_1's l1: 0.215463\n",
      "[46000]\ttraining's l1: 0.14556\tvalid_1's l1: 0.215452\n",
      "[46500]\ttraining's l1: 0.145114\tvalid_1's l1: 0.215425\n",
      "[47000]\ttraining's l1: 0.144668\tvalid_1's l1: 0.215393\n",
      "[47500]\ttraining's l1: 0.144235\tvalid_1's l1: 0.215384\n",
      "[48000]\ttraining's l1: 0.143806\tvalid_1's l1: 0.215373\n",
      "0.21536989190746614\n",
      "fold2: [500]\ttraining's l1: 0.332591\tvalid_1's l1: 0.339768\n",
      "[1000]\ttraining's l1: 0.279459\tvalid_1's l1: 0.287777\n",
      "[1500]\ttraining's l1: 0.258325\tvalid_1's l1: 0.267366\n",
      "[2000]\ttraining's l1: 0.245695\tvalid_1's l1: 0.255713\n",
      "[2500]\ttraining's l1: 0.237134\tvalid_1's l1: 0.248368\n",
      "[3000]\ttraining's l1: 0.231312\tvalid_1's l1: 0.243864\n",
      "[3500]\ttraining's l1: 0.226581\tvalid_1's l1: 0.240493\n",
      "[4000]\ttraining's l1: 0.222811\tvalid_1's l1: 0.238094\n",
      "[4500]\ttraining's l1: 0.219733\tvalid_1's l1: 0.236355\n",
      "[5000]\ttraining's l1: 0.217086\tvalid_1's l1: 0.23498\n",
      "[5500]\ttraining's l1: 0.214417\tvalid_1's l1: 0.233519\n",
      "[6000]\ttraining's l1: 0.211942\tvalid_1's l1: 0.232164\n",
      "[6500]\ttraining's l1: 0.209761\tvalid_1's l1: 0.231092\n",
      "[7000]\ttraining's l1: 0.207794\tvalid_1's l1: 0.230211\n",
      "[7500]\ttraining's l1: 0.205942\tvalid_1's l1: 0.229417\n",
      "[8000]\ttraining's l1: 0.204203\tvalid_1's l1: 0.228742\n",
      "[8500]\ttraining's l1: 0.202546\tvalid_1's l1: 0.228125\n",
      "[9000]\ttraining's l1: 0.200952\tvalid_1's l1: 0.227572\n",
      "[9500]\ttraining's l1: 0.199508\tvalid_1's l1: 0.227129\n",
      "[10000]\ttraining's l1: 0.198147\tvalid_1's l1: 0.226711\n",
      "[10500]\ttraining's l1: 0.196813\tvalid_1's l1: 0.226349\n",
      "[11000]\ttraining's l1: 0.195473\tvalid_1's l1: 0.225908\n",
      "[11500]\ttraining's l1: 0.194136\tvalid_1's l1: 0.225497\n",
      "[12000]\ttraining's l1: 0.192917\tvalid_1's l1: 0.225201\n",
      "[12500]\ttraining's l1: 0.191743\tvalid_1's l1: 0.224946\n",
      "[13000]\ttraining's l1: 0.19049\tvalid_1's l1: 0.22456\n",
      "[13500]\ttraining's l1: 0.189348\tvalid_1's l1: 0.224264\n",
      "[14000]\ttraining's l1: 0.188181\tvalid_1's l1: 0.223918\n",
      "[14500]\ttraining's l1: 0.187094\tvalid_1's l1: 0.22365\n",
      "[15000]\ttraining's l1: 0.186016\tvalid_1's l1: 0.223393\n",
      "[15500]\ttraining's l1: 0.18491\tvalid_1's l1: 0.223073\n",
      "[16000]\ttraining's l1: 0.183949\tvalid_1's l1: 0.222928\n",
      "[16500]\ttraining's l1: 0.182938\tvalid_1's l1: 0.222703\n",
      "[17000]\ttraining's l1: 0.182007\tvalid_1's l1: 0.22256\n",
      "[17500]\ttraining's l1: 0.181102\tvalid_1's l1: 0.222438\n",
      "[18000]\ttraining's l1: 0.180221\tvalid_1's l1: 0.22233\n",
      "[18500]\ttraining's l1: 0.17936\tvalid_1's l1: 0.22222\n",
      "[19000]\ttraining's l1: 0.178446\tvalid_1's l1: 0.222018\n",
      "[19500]\ttraining's l1: 0.177596\tvalid_1's l1: 0.221866\n",
      "[20000]\ttraining's l1: 0.176786\tvalid_1's l1: 0.22173\n",
      "[20500]\ttraining's l1: 0.175967\tvalid_1's l1: 0.221591\n",
      "[21000]\ttraining's l1: 0.175178\tvalid_1's l1: 0.221477\n",
      "[21500]\ttraining's l1: 0.174395\tvalid_1's l1: 0.221401\n",
      "[22000]\ttraining's l1: 0.173621\tvalid_1's l1: 0.221321\n",
      "[22500]\ttraining's l1: 0.172887\tvalid_1's l1: 0.221238\n",
      "[23000]\ttraining's l1: 0.172178\tvalid_1's l1: 0.221162\n",
      "[23500]\ttraining's l1: 0.171456\tvalid_1's l1: 0.221074\n",
      "[24000]\ttraining's l1: 0.170742\tvalid_1's l1: 0.221006\n",
      "[24500]\ttraining's l1: 0.170031\tvalid_1's l1: 0.220946\n",
      "[25000]\ttraining's l1: 0.169339\tvalid_1's l1: 0.22086\n",
      "[25500]\ttraining's l1: 0.168658\tvalid_1's l1: 0.22082\n",
      "[26000]\ttraining's l1: 0.168003\tvalid_1's l1: 0.220786\n",
      "[26500]\ttraining's l1: 0.16736\tvalid_1's l1: 0.220735\n",
      "[27000]\ttraining's l1: 0.166716\tvalid_1's l1: 0.22066\n",
      "[27500]\ttraining's l1: 0.166058\tvalid_1's l1: 0.22059\n",
      "[28000]\ttraining's l1: 0.165423\tvalid_1's l1: 0.220537\n",
      "[28500]\ttraining's l1: 0.164798\tvalid_1's l1: 0.220502\n",
      "[29000]\ttraining's l1: 0.164185\tvalid_1's l1: 0.220451\n",
      "[29500]\ttraining's l1: 0.163578\tvalid_1's l1: 0.220407\n",
      "[30000]\ttraining's l1: 0.162954\tvalid_1's l1: 0.220328\n",
      "[30500]\ttraining's l1: 0.162354\tvalid_1's l1: 0.220268\n",
      "[31000]\ttraining's l1: 0.161733\tvalid_1's l1: 0.220186\n",
      "[31500]\ttraining's l1: 0.161147\tvalid_1's l1: 0.220138\n",
      "[32000]\ttraining's l1: 0.160566\tvalid_1's l1: 0.220073\n",
      "[32500]\ttraining's l1: 0.159976\tvalid_1's l1: 0.220002\n",
      "[33000]\ttraining's l1: 0.159392\tvalid_1's l1: 0.219923\n",
      "[33500]\ttraining's l1: 0.158823\tvalid_1's l1: 0.21984\n",
      "[34000]\ttraining's l1: 0.158244\tvalid_1's l1: 0.219745\n",
      "[34500]\ttraining's l1: 0.157628\tvalid_1's l1: 0.219617\n",
      "[35000]\ttraining's l1: 0.157055\tvalid_1's l1: 0.219532\n",
      "[35500]\ttraining's l1: 0.156502\tvalid_1's l1: 0.21947\n",
      "[36000]\ttraining's l1: 0.155937\tvalid_1's l1: 0.219408\n",
      "[36500]\ttraining's l1: 0.155359\tvalid_1's l1: 0.21932\n",
      "[37000]\ttraining's l1: 0.154789\tvalid_1's l1: 0.219256\n",
      "[37500]\ttraining's l1: 0.154238\tvalid_1's l1: 0.219192\n",
      "[38000]\ttraining's l1: 0.15367\tvalid_1's l1: 0.219126\n",
      "[38500]\ttraining's l1: 0.153137\tvalid_1's l1: 0.219083\n",
      "[39000]\ttraining's l1: 0.152616\tvalid_1's l1: 0.219026\n",
      "[39500]\ttraining's l1: 0.152093\tvalid_1's l1: 0.218979\n",
      "[40000]\ttraining's l1: 0.151583\tvalid_1's l1: 0.218945\n",
      "[40500]\ttraining's l1: 0.15107\tvalid_1's l1: 0.218896\n",
      "[41000]\ttraining's l1: 0.150576\tvalid_1's l1: 0.218872\n",
      "[41500]\ttraining's l1: 0.150048\tvalid_1's l1: 0.218805\n",
      "[42000]\ttraining's l1: 0.149488\tvalid_1's l1: 0.218697\n",
      "[42500]\ttraining's l1: 0.148938\tvalid_1's l1: 0.218592\n",
      "[43000]\ttraining's l1: 0.148427\tvalid_1's l1: 0.218522\n",
      "[43500]\ttraining's l1: 0.147926\tvalid_1's l1: 0.21847\n",
      "[44000]\ttraining's l1: 0.147419\tvalid_1's l1: 0.218406\n",
      "[44500]\ttraining's l1: 0.14696\tvalid_1's l1: 0.218375\n",
      "[45000]\ttraining's l1: 0.146471\tvalid_1's l1: 0.218334\n",
      "[45500]\ttraining's l1: 0.146017\tvalid_1's l1: 0.218309\n",
      "[46000]\ttraining's l1: 0.145543\tvalid_1's l1: 0.21825\n",
      "[46500]\ttraining's l1: 0.145065\tvalid_1's l1: 0.218221\n",
      "[47000]\ttraining's l1: 0.144547\tvalid_1's l1: 0.218135\n",
      "[47500]\ttraining's l1: 0.144063\tvalid_1's l1: 0.21809\n",
      "[48000]\ttraining's l1: 0.14361\tvalid_1's l1: 0.218056\n",
      "[48500]\ttraining's l1: 0.143161\tvalid_1's l1: 0.218032\n",
      "[49000]\ttraining's l1: 0.142713\tvalid_1's l1: 0.218005\n",
      "[49500]\ttraining's l1: 0.142261\tvalid_1's l1: 0.217973\n",
      "[50000]\ttraining's l1: 0.141827\tvalid_1's l1: 0.217949\n",
      "[50500]\ttraining's l1: 0.141385\tvalid_1's l1: 0.217911\n",
      "[51000]\ttraining's l1: 0.140951\tvalid_1's l1: 0.217876\n",
      "[51500]\ttraining's l1: 0.140525\tvalid_1's l1: 0.217851\n",
      "[52000]\ttraining's l1: 0.140104\tvalid_1's l1: 0.217825\n",
      "[52500]\ttraining's l1: 0.139681\tvalid_1's l1: 0.217794\n",
      "[53000]\ttraining's l1: 0.139253\tvalid_1's l1: 0.217756\n",
      "[53500]\ttraining's l1: 0.138848\tvalid_1's l1: 0.217754\n",
      "[54000]\ttraining's l1: 0.138436\tvalid_1's l1: 0.217745\n",
      "[54500]\ttraining's l1: 0.13799\tvalid_1's l1: 0.217727\n",
      "[55000]\ttraining's l1: 0.137537\tvalid_1's l1: 0.217681\n",
      "[55500]\ttraining's l1: 0.137135\tvalid_1's l1: 0.217662\n",
      "[56000]\ttraining's l1: 0.136707\tvalid_1's l1: 0.217596\n",
      "[56500]\ttraining's l1: 0.136311\tvalid_1's l1: 0.217571\n",
      "[57000]\ttraining's l1: 0.135909\tvalid_1's l1: 0.217546\n",
      "[57500]\ttraining's l1: 0.13551\tvalid_1's l1: 0.21752\n",
      "[58000]\ttraining's l1: 0.135123\tvalid_1's l1: 0.217486\n",
      "[58500]\ttraining's l1: 0.134716\tvalid_1's l1: 0.21743\n",
      "[59000]\ttraining's l1: 0.134236\tvalid_1's l1: 0.21736\n",
      "[59500]\ttraining's l1: 0.133813\tvalid_1's l1: 0.21729\n",
      "[60000]\ttraining's l1: 0.133404\tvalid_1's l1: 0.217236\n",
      "[60500]\ttraining's l1: 0.133009\tvalid_1's l1: 0.217209\n",
      "[61000]\ttraining's l1: 0.132631\tvalid_1's l1: 0.217183\n",
      "[61500]\ttraining's l1: 0.132248\tvalid_1's l1: 0.217162\n",
      "[62000]\ttraining's l1: 0.131885\tvalid_1's l1: 0.217136\n",
      "[62500]\ttraining's l1: 0.131507\tvalid_1's l1: 0.217093\n",
      "[63000]\ttraining's l1: 0.131125\tvalid_1's l1: 0.21707\n",
      "[63500]\ttraining's l1: 0.130764\tvalid_1's l1: 0.217054\n",
      "[64000]\ttraining's l1: 0.130405\tvalid_1's l1: 0.217025\n",
      "[64500]\ttraining's l1: 0.130039\tvalid_1's l1: 0.216995\n",
      "[65000]\ttraining's l1: 0.12969\tvalid_1's l1: 0.216975\n",
      "[65500]\ttraining's l1: 0.129316\tvalid_1's l1: 0.216931\n",
      "[66000]\ttraining's l1: 0.128961\tvalid_1's l1: 0.216916\n",
      "[66500]\ttraining's l1: 0.128618\tvalid_1's l1: 0.216901\n",
      "[67000]\ttraining's l1: 0.128284\tvalid_1's l1: 0.216889\n",
      "[67500]\ttraining's l1: 0.127942\tvalid_1's l1: 0.21688\n",
      "[68000]\ttraining's l1: 0.127608\tvalid_1's l1: 0.216855\n",
      "[68500]\ttraining's l1: 0.127263\tvalid_1's l1: 0.216835\n",
      "[69000]\ttraining's l1: 0.126913\tvalid_1's l1: 0.216812\n",
      "[69500]\ttraining's l1: 0.126568\tvalid_1's l1: 0.216795\n",
      "[70000]\ttraining's l1: 0.126237\tvalid_1's l1: 0.216781\n",
      "[70500]\ttraining's l1: 0.125904\tvalid_1's l1: 0.216766\n",
      "[71000]\ttraining's l1: 0.125577\tvalid_1's l1: 0.216752\n",
      "[71500]\ttraining's l1: 0.12526\tvalid_1's l1: 0.216748\n",
      "[72000]\ttraining's l1: 0.12495\tvalid_1's l1: 0.216733\n",
      "[72500]\ttraining's l1: 0.124627\tvalid_1's l1: 0.216723\n",
      "[73000]\ttraining's l1: 0.124306\tvalid_1's l1: 0.216713\n",
      "[73500]\ttraining's l1: 0.123986\tvalid_1's l1: 0.216697\n",
      "[74000]\ttraining's l1: 0.123659\tvalid_1's l1: 0.216689\n",
      "[74500]\ttraining's l1: 0.123335\tvalid_1's l1: 0.216681\n",
      "0.216677387349384\n",
      "fold3: [500]\ttraining's l1: 0.335489\tvalid_1's l1: 0.334422\n",
      "[1000]\ttraining's l1: 0.281528\tvalid_1's l1: 0.28201\n",
      "[1500]\ttraining's l1: 0.260734\tvalid_1's l1: 0.263229\n",
      "[2000]\ttraining's l1: 0.247735\tvalid_1's l1: 0.251893\n",
      "[2500]\ttraining's l1: 0.238832\tvalid_1's l1: 0.244728\n",
      "[3000]\ttraining's l1: 0.232443\tvalid_1's l1: 0.240048\n",
      "[3500]\ttraining's l1: 0.227799\tvalid_1's l1: 0.237036\n",
      "[4000]\ttraining's l1: 0.224284\tvalid_1's l1: 0.235031\n",
      "[4500]\ttraining's l1: 0.221239\tvalid_1's l1: 0.233389\n",
      "[5000]\ttraining's l1: 0.218245\tvalid_1's l1: 0.231758\n",
      "[5500]\ttraining's l1: 0.215881\tvalid_1's l1: 0.230584\n",
      "[6000]\ttraining's l1: 0.213569\tvalid_1's l1: 0.229481\n",
      "[6500]\ttraining's l1: 0.211353\tvalid_1's l1: 0.228433\n",
      "[7000]\ttraining's l1: 0.209273\tvalid_1's l1: 0.227481\n",
      "[7500]\ttraining's l1: 0.207345\tvalid_1's l1: 0.226649\n",
      "[8000]\ttraining's l1: 0.205495\tvalid_1's l1: 0.225854\n",
      "[8500]\ttraining's l1: 0.203874\tvalid_1's l1: 0.225298\n",
      "[9000]\ttraining's l1: 0.202159\tvalid_1's l1: 0.224588\n",
      "[9500]\ttraining's l1: 0.200452\tvalid_1's l1: 0.223794\n",
      "[10000]\ttraining's l1: 0.19903\tvalid_1's l1: 0.22332\n",
      "[10500]\ttraining's l1: 0.19752\tvalid_1's l1: 0.222748\n",
      "[11000]\ttraining's l1: 0.196209\tvalid_1's l1: 0.222385\n",
      "[11500]\ttraining's l1: 0.194922\tvalid_1's l1: 0.222038\n",
      "[12000]\ttraining's l1: 0.193645\tvalid_1's l1: 0.22169\n",
      "[12500]\ttraining's l1: 0.192506\tvalid_1's l1: 0.221465\n",
      "[13000]\ttraining's l1: 0.191431\tvalid_1's l1: 0.221271\n",
      "[13500]\ttraining's l1: 0.190361\tvalid_1's l1: 0.221037\n",
      "[14000]\ttraining's l1: 0.189372\tvalid_1's l1: 0.220865\n",
      "[14500]\ttraining's l1: 0.188385\tvalid_1's l1: 0.220722\n",
      "[15000]\ttraining's l1: 0.187437\tvalid_1's l1: 0.220564\n",
      "[15500]\ttraining's l1: 0.18648\tvalid_1's l1: 0.220435\n",
      "[16000]\ttraining's l1: 0.185544\tvalid_1's l1: 0.220312\n",
      "[16500]\ttraining's l1: 0.184596\tvalid_1's l1: 0.220154\n",
      "[17000]\ttraining's l1: 0.183697\tvalid_1's l1: 0.220022\n",
      "[17500]\ttraining's l1: 0.182827\tvalid_1's l1: 0.219871\n",
      "[18000]\ttraining's l1: 0.181793\tvalid_1's l1: 0.219579\n",
      "[18500]\ttraining's l1: 0.180858\tvalid_1's l1: 0.219348\n",
      "[19000]\ttraining's l1: 0.179957\tvalid_1's l1: 0.219164\n",
      "[19500]\ttraining's l1: 0.179094\tvalid_1's l1: 0.219013\n",
      "[20000]\ttraining's l1: 0.178258\tvalid_1's l1: 0.218897\n",
      "[20500]\ttraining's l1: 0.177468\tvalid_1's l1: 0.218792\n",
      "[21000]\ttraining's l1: 0.176695\tvalid_1's l1: 0.218691\n",
      "[21500]\ttraining's l1: 0.175903\tvalid_1's l1: 0.218583\n",
      "[22000]\ttraining's l1: 0.17508\tvalid_1's l1: 0.218461\n",
      "[22500]\ttraining's l1: 0.174283\tvalid_1's l1: 0.218377\n",
      "[23000]\ttraining's l1: 0.173266\tvalid_1's l1: 0.21799\n",
      "[23500]\ttraining's l1: 0.172381\tvalid_1's l1: 0.217739\n",
      "[24000]\ttraining's l1: 0.171617\tvalid_1's l1: 0.217662\n",
      "[24500]\ttraining's l1: 0.17081\tvalid_1's l1: 0.217489\n",
      "[25000]\ttraining's l1: 0.170084\tvalid_1's l1: 0.217384\n",
      "[25500]\ttraining's l1: 0.169288\tvalid_1's l1: 0.217203\n",
      "[26000]\ttraining's l1: 0.168561\tvalid_1's l1: 0.217077\n",
      "[26500]\ttraining's l1: 0.167831\tvalid_1's l1: 0.216964\n",
      "[27000]\ttraining's l1: 0.16714\tvalid_1's l1: 0.216892\n",
      "[27500]\ttraining's l1: 0.16649\tvalid_1's l1: 0.216854\n",
      "[28000]\ttraining's l1: 0.165796\tvalid_1's l1: 0.216745\n",
      "[28500]\ttraining's l1: 0.165063\tvalid_1's l1: 0.216588\n",
      "[29000]\ttraining's l1: 0.164407\tvalid_1's l1: 0.216492\n",
      "[29500]\ttraining's l1: 0.163779\tvalid_1's l1: 0.216437\n",
      "[30000]\ttraining's l1: 0.163167\tvalid_1's l1: 0.216398\n",
      "[30500]\ttraining's l1: 0.162532\tvalid_1's l1: 0.216328\n",
      "[31000]\ttraining's l1: 0.161912\tvalid_1's l1: 0.216263\n",
      "[31500]\ttraining's l1: 0.161299\tvalid_1's l1: 0.216201\n",
      "[32000]\ttraining's l1: 0.160666\tvalid_1's l1: 0.216103\n",
      "[32500]\ttraining's l1: 0.160055\tvalid_1's l1: 0.216033\n",
      "[33000]\ttraining's l1: 0.159462\tvalid_1's l1: 0.215968\n",
      "[33500]\ttraining's l1: 0.158887\tvalid_1's l1: 0.215923\n",
      "[34000]\ttraining's l1: 0.158292\tvalid_1's l1: 0.215871\n",
      "[34500]\ttraining's l1: 0.157666\tvalid_1's l1: 0.215744\n",
      "[35000]\ttraining's l1: 0.157061\tvalid_1's l1: 0.21568\n",
      "[35500]\ttraining's l1: 0.15645\tvalid_1's l1: 0.215595\n",
      "[36000]\ttraining's l1: 0.155914\tvalid_1's l1: 0.215561\n",
      "[36500]\ttraining's l1: 0.155402\tvalid_1's l1: 0.215557\n",
      "[37000]\ttraining's l1: 0.154881\tvalid_1's l1: 0.21551\n",
      "[37500]\ttraining's l1: 0.154383\tvalid_1's l1: 0.215499\n",
      "[38000]\ttraining's l1: 0.153871\tvalid_1's l1: 0.215478\n",
      "[38500]\ttraining's l1: 0.153359\tvalid_1's l1: 0.215444\n",
      "[39000]\ttraining's l1: 0.152837\tvalid_1's l1: 0.215429\n",
      "[39500]\ttraining's l1: 0.152327\tvalid_1's l1: 0.215412\n",
      "[40000]\ttraining's l1: 0.151801\tvalid_1's l1: 0.215393\n",
      "[40500]\ttraining's l1: 0.151308\tvalid_1's l1: 0.21537\n",
      "[41000]\ttraining's l1: 0.150815\tvalid_1's l1: 0.215348\n",
      "[41500]\ttraining's l1: 0.150328\tvalid_1's l1: 0.215309\n",
      "[42000]\ttraining's l1: 0.149848\tvalid_1's l1: 0.215283\n",
      "[42500]\ttraining's l1: 0.149375\tvalid_1's l1: 0.215259\n",
      "[43000]\ttraining's l1: 0.148859\tvalid_1's l1: 0.215195\n",
      "[43500]\ttraining's l1: 0.148347\tvalid_1's l1: 0.215154\n",
      "[44000]\ttraining's l1: 0.147888\tvalid_1's l1: 0.215143\n",
      "[44500]\ttraining's l1: 0.147422\tvalid_1's l1: 0.215117\n",
      "[45000]\ttraining's l1: 0.146947\tvalid_1's l1: 0.215095\n",
      "[45500]\ttraining's l1: 0.1465\tvalid_1's l1: 0.215065\n",
      "[46000]\ttraining's l1: 0.146046\tvalid_1's l1: 0.215039\n",
      "[46500]\ttraining's l1: 0.145594\tvalid_1's l1: 0.215015\n",
      "[47000]\ttraining's l1: 0.145126\tvalid_1's l1: 0.214971\n",
      "[47500]\ttraining's l1: 0.144675\tvalid_1's l1: 0.214937\n",
      "[48000]\ttraining's l1: 0.144216\tvalid_1's l1: 0.214917\n",
      "[48500]\ttraining's l1: 0.143756\tvalid_1's l1: 0.214894\n",
      "[49000]\ttraining's l1: 0.143326\tvalid_1's l1: 0.214883\n",
      "[49500]\ttraining's l1: 0.142907\tvalid_1's l1: 0.214872\n",
      "[50000]\ttraining's l1: 0.142491\tvalid_1's l1: 0.214858\n",
      "[50500]\ttraining's l1: 0.142083\tvalid_1's l1: 0.214841\n",
      "[51000]\ttraining's l1: 0.141651\tvalid_1's l1: 0.214809\n",
      "[51500]\ttraining's l1: 0.141238\tvalid_1's l1: 0.214789\n",
      "[52000]\ttraining's l1: 0.140832\tvalid_1's l1: 0.214781\n",
      "[52500]\ttraining's l1: 0.14043\tvalid_1's l1: 0.214755\n",
      "[53000]\ttraining's l1: 0.140006\tvalid_1's l1: 0.214723\n",
      "[53500]\ttraining's l1: 0.139611\tvalid_1's l1: 0.21471\n",
      "[54000]\ttraining's l1: 0.139195\tvalid_1's l1: 0.214657\n",
      "[54500]\ttraining's l1: 0.13877\tvalid_1's l1: 0.214623\n",
      "[55000]\ttraining's l1: 0.138387\tvalid_1's l1: 0.214605\n",
      "[55500]\ttraining's l1: 0.137958\tvalid_1's l1: 0.21457\n",
      "[56000]\ttraining's l1: 0.137547\tvalid_1's l1: 0.214539\n",
      "[56500]\ttraining's l1: 0.137155\tvalid_1's l1: 0.214515\n",
      "[57000]\ttraining's l1: 0.136762\tvalid_1's l1: 0.214483\n",
      "[57500]\ttraining's l1: 0.136383\tvalid_1's l1: 0.214457\n",
      "[58000]\ttraining's l1: 0.135993\tvalid_1's l1: 0.214434\n",
      "[58500]\ttraining's l1: 0.135598\tvalid_1's l1: 0.214405\n",
      "[59000]\ttraining's l1: 0.13521\tvalid_1's l1: 0.214388\n",
      "[59500]\ttraining's l1: 0.134814\tvalid_1's l1: 0.214357\n",
      "[60000]\ttraining's l1: 0.134455\tvalid_1's l1: 0.214353\n",
      "[60500]\ttraining's l1: 0.134088\tvalid_1's l1: 0.214337\n",
      "[61000]\ttraining's l1: 0.133718\tvalid_1's l1: 0.214316\n",
      "[61500]\ttraining's l1: 0.133356\tvalid_1's l1: 0.214306\n",
      "[62000]\ttraining's l1: 0.133002\tvalid_1's l1: 0.214303\n",
      "[62500]\ttraining's l1: 0.132642\tvalid_1's l1: 0.214289\n",
      "[63000]\ttraining's l1: 0.132299\tvalid_1's l1: 0.214267\n",
      "[63500]\ttraining's l1: 0.131949\tvalid_1's l1: 0.214251\n",
      "[64000]\ttraining's l1: 0.131577\tvalid_1's l1: 0.214231\n",
      "[64500]\ttraining's l1: 0.131222\tvalid_1's l1: 0.21421\n",
      "[65000]\ttraining's l1: 0.130849\tvalid_1's l1: 0.214191\n",
      "[65500]\ttraining's l1: 0.130481\tvalid_1's l1: 0.214164\n",
      "[66000]\ttraining's l1: 0.130135\tvalid_1's l1: 0.214155\n",
      "[66500]\ttraining's l1: 0.129794\tvalid_1's l1: 0.214146\n",
      "[67000]\ttraining's l1: 0.129436\tvalid_1's l1: 0.214127\n",
      "[67500]\ttraining's l1: 0.129106\tvalid_1's l1: 0.214125\n",
      "[68000]\ttraining's l1: 0.128768\tvalid_1's l1: 0.214124\n",
      "[68500]\ttraining's l1: 0.128431\tvalid_1's l1: 0.214111\n",
      "[69000]\ttraining's l1: 0.128113\tvalid_1's l1: 0.214105\n",
      "[69500]\ttraining's l1: 0.127767\tvalid_1's l1: 0.214088\n",
      "[70000]\ttraining's l1: 0.12743\tvalid_1's l1: 0.214064\n",
      "[70500]\ttraining's l1: 0.127107\tvalid_1's l1: 0.214067\n",
      "[71000]\ttraining's l1: 0.126788\tvalid_1's l1: 0.214062\n",
      "[71500]\ttraining's l1: 0.126471\tvalid_1's l1: 0.214056\n",
      "[72000]\ttraining's l1: 0.126141\tvalid_1's l1: 0.214046\n",
      "[72500]\ttraining's l1: 0.125825\tvalid_1's l1: 0.214034\n",
      "[73000]\ttraining's l1: 0.125503\tvalid_1's l1: 0.214017\n",
      "[73500]\ttraining's l1: 0.125184\tvalid_1's l1: 0.214012\n",
      "[74000]\ttraining's l1: 0.124872\tvalid_1's l1: 0.214008\n",
      "[74500]\ttraining's l1: 0.124509\tvalid_1's l1: 0.213973\n",
      "[75000]\ttraining's l1: 0.124169\tvalid_1's l1: 0.21394\n",
      "[75500]\ttraining's l1: 0.123852\tvalid_1's l1: 0.21393\n",
      "[76000]\ttraining's l1: 0.123537\tvalid_1's l1: 0.213922\n",
      "[76500]\ttraining's l1: 0.123203\tvalid_1's l1: 0.213901\n",
      "[77000]\ttraining's l1: 0.122888\tvalid_1's l1: 0.213878\n",
      "[77500]\ttraining's l1: 0.122577\tvalid_1's l1: 0.213858\n",
      "[78000]\ttraining's l1: 0.122264\tvalid_1's l1: 0.213846\n",
      "[78500]\ttraining's l1: 0.121945\tvalid_1's l1: 0.213834\n",
      "[79000]\ttraining's l1: 0.12164\tvalid_1's l1: 0.213822\n",
      "[79500]\ttraining's l1: 0.121336\tvalid_1's l1: 0.213799\n",
      "[80000]\ttraining's l1: 0.121023\tvalid_1's l1: 0.21378\n",
      "[80500]\ttraining's l1: 0.120735\tvalid_1's l1: 0.213758\n",
      "[81000]\ttraining's l1: 0.120452\tvalid_1's l1: 0.21374\n",
      "[81500]\ttraining's l1: 0.120173\tvalid_1's l1: 0.213728\n",
      "[82000]\ttraining's l1: 0.119881\tvalid_1's l1: 0.213718\n",
      "[82500]\ttraining's l1: 0.119572\tvalid_1's l1: 0.213705\n",
      "[83000]\ttraining's l1: 0.119276\tvalid_1's l1: 0.213686\n",
      "[83500]\ttraining's l1: 0.118961\tvalid_1's l1: 0.213664\n",
      "[84000]\ttraining's l1: 0.118652\tvalid_1's l1: 0.213647\n",
      "[84500]\ttraining's l1: 0.118358\tvalid_1's l1: 0.213636\n",
      "[85000]\ttraining's l1: 0.118062\tvalid_1's l1: 0.213617\n",
      "[85500]\ttraining's l1: 0.117767\tvalid_1's l1: 0.213596\n",
      "[86000]\ttraining's l1: 0.117478\tvalid_1's l1: 0.213572\n",
      "[86500]\ttraining's l1: 0.117194\tvalid_1's l1: 0.213559\n",
      "[87000]\ttraining's l1: 0.116895\tvalid_1's l1: 0.21355\n",
      "[87500]\ttraining's l1: 0.116615\tvalid_1's l1: 0.213535\n",
      "[88000]\ttraining's l1: 0.11633\tvalid_1's l1: 0.213524\n",
      "[88500]\ttraining's l1: 0.116058\tvalid_1's l1: 0.213504\n",
      "[89000]\ttraining's l1: 0.115774\tvalid_1's l1: 0.213487\n",
      "[89500]\ttraining's l1: 0.115492\tvalid_1's l1: 0.213474\n",
      "[90000]\ttraining's l1: 0.115209\tvalid_1's l1: 0.213461\n",
      "[90500]\ttraining's l1: 0.114931\tvalid_1's l1: 0.213448\n",
      "[91000]\ttraining's l1: 0.114658\tvalid_1's l1: 0.213436\n",
      "[91500]\ttraining's l1: 0.114383\tvalid_1's l1: 0.213418\n",
      "[92000]\ttraining's l1: 0.114108\tvalid_1's l1: 0.213407\n",
      "[92500]\ttraining's l1: 0.113833\tvalid_1's l1: 0.2134\n",
      "[93000]\ttraining's l1: 0.113563\tvalid_1's l1: 0.21339\n",
      "[93500]\ttraining's l1: 0.113254\tvalid_1's l1: 0.213352\n",
      "[94000]\ttraining's l1: 0.112977\tvalid_1's l1: 0.213328\n",
      "[94500]\ttraining's l1: 0.112718\tvalid_1's l1: 0.213311\n",
      "[95000]\ttraining's l1: 0.112466\tvalid_1's l1: 0.213304\n",
      "[95500]\ttraining's l1: 0.112209\tvalid_1's l1: 0.213301\n",
      "[96000]\ttraining's l1: 0.111965\tvalid_1's l1: 0.213291\n",
      "[96500]\ttraining's l1: 0.111701\tvalid_1's l1: 0.21328\n",
      "[97000]\ttraining's l1: 0.111441\tvalid_1's l1: 0.213277\n",
      "[97500]\ttraining's l1: 0.111183\tvalid_1's l1: 0.213271\n",
      "[98000]\ttraining's l1: 0.110929\tvalid_1's l1: 0.213257\n",
      "[98500]\ttraining's l1: 0.110666\tvalid_1's l1: 0.213248\n",
      "[99000]\ttraining's l1: 0.1104\tvalid_1's l1: 0.213227\n",
      "[99500]\ttraining's l1: 0.110132\tvalid_1's l1: 0.213215\n",
      "[100000]\ttraining's l1: 0.10987\tvalid_1's l1: 0.213207\n",
      "0.21320671897202298\n",
      "fold4: [500]\ttraining's l1: 0.332414\tvalid_1's l1: 0.338801\n",
      "[1000]\ttraining's l1: 0.277993\tvalid_1's l1: 0.285912\n",
      "[1500]\ttraining's l1: 0.256836\tvalid_1's l1: 0.2662\n",
      "[2000]\ttraining's l1: 0.244781\tvalid_1's l1: 0.255729\n",
      "[2500]\ttraining's l1: 0.236466\tvalid_1's l1: 0.24857\n",
      "[3000]\ttraining's l1: 0.230711\tvalid_1's l1: 0.244125\n",
      "[3500]\ttraining's l1: 0.226092\tvalid_1's l1: 0.240919\n",
      "[4000]\ttraining's l1: 0.222621\tvalid_1's l1: 0.238721\n",
      "[4500]\ttraining's l1: 0.219565\tvalid_1's l1: 0.236984\n",
      "[5000]\ttraining's l1: 0.216765\tvalid_1's l1: 0.23538\n",
      "[5500]\ttraining's l1: 0.214324\tvalid_1's l1: 0.234207\n",
      "[6000]\ttraining's l1: 0.211979\tvalid_1's l1: 0.233035\n",
      "[6500]\ttraining's l1: 0.210014\tvalid_1's l1: 0.23226\n",
      "[7000]\ttraining's l1: 0.208136\tvalid_1's l1: 0.231516\n",
      "[7500]\ttraining's l1: 0.206243\tvalid_1's l1: 0.230729\n",
      "[8000]\ttraining's l1: 0.204411\tvalid_1's l1: 0.229989\n",
      "[8500]\ttraining's l1: 0.202594\tvalid_1's l1: 0.229262\n",
      "[9000]\ttraining's l1: 0.200915\tvalid_1's l1: 0.228651\n",
      "[9500]\ttraining's l1: 0.199394\tvalid_1's l1: 0.22813\n",
      "[10000]\ttraining's l1: 0.198011\tvalid_1's l1: 0.227728\n",
      "[10500]\ttraining's l1: 0.196648\tvalid_1's l1: 0.227336\n",
      "[11000]\ttraining's l1: 0.195338\tvalid_1's l1: 0.226974\n",
      "[11500]\ttraining's l1: 0.194105\tvalid_1's l1: 0.226679\n",
      "[12000]\ttraining's l1: 0.192881\tvalid_1's l1: 0.226344\n",
      "[12500]\ttraining's l1: 0.191706\tvalid_1's l1: 0.226078\n",
      "[13000]\ttraining's l1: 0.190582\tvalid_1's l1: 0.225838\n",
      "[13500]\ttraining's l1: 0.189446\tvalid_1's l1: 0.225602\n",
      "[14000]\ttraining's l1: 0.188407\tvalid_1's l1: 0.225433\n",
      "[14500]\ttraining's l1: 0.187389\tvalid_1's l1: 0.225257\n",
      "[15000]\ttraining's l1: 0.186323\tvalid_1's l1: 0.22501\n",
      "[15500]\ttraining's l1: 0.185357\tvalid_1's l1: 0.224859\n",
      "[16000]\ttraining's l1: 0.184403\tvalid_1's l1: 0.224711\n",
      "[16500]\ttraining's l1: 0.183418\tvalid_1's l1: 0.224503\n",
      "[17000]\ttraining's l1: 0.182504\tvalid_1's l1: 0.224369\n",
      "[17500]\ttraining's l1: 0.181292\tvalid_1's l1: 0.223906\n",
      "[18000]\ttraining's l1: 0.179809\tvalid_1's l1: 0.223198\n",
      "[18500]\ttraining's l1: 0.178786\tvalid_1's l1: 0.222877\n",
      "[19000]\ttraining's l1: 0.177915\tvalid_1's l1: 0.222727\n",
      "[19500]\ttraining's l1: 0.177121\tvalid_1's l1: 0.222636\n",
      "[20000]\ttraining's l1: 0.176298\tvalid_1's l1: 0.222523\n",
      "[20500]\ttraining's l1: 0.175429\tvalid_1's l1: 0.222362\n",
      "[21000]\ttraining's l1: 0.174654\tvalid_1's l1: 0.222277\n",
      "[21500]\ttraining's l1: 0.173887\tvalid_1's l1: 0.222216\n",
      "[22000]\ttraining's l1: 0.173133\tvalid_1's l1: 0.222146\n",
      "[22500]\ttraining's l1: 0.172424\tvalid_1's l1: 0.222087\n",
      "[23000]\ttraining's l1: 0.171675\tvalid_1's l1: 0.222015\n",
      "[23500]\ttraining's l1: 0.170968\tvalid_1's l1: 0.221942\n",
      "[24000]\ttraining's l1: 0.170203\tvalid_1's l1: 0.221837\n",
      "[24500]\ttraining's l1: 0.169435\tvalid_1's l1: 0.221682\n",
      "[25000]\ttraining's l1: 0.168732\tvalid_1's l1: 0.221608\n",
      "[25500]\ttraining's l1: 0.168025\tvalid_1's l1: 0.221535\n",
      "[26000]\ttraining's l1: 0.167338\tvalid_1's l1: 0.22146\n",
      "[26500]\ttraining's l1: 0.166706\tvalid_1's l1: 0.221406\n",
      "[27000]\ttraining's l1: 0.166044\tvalid_1's l1: 0.221364\n",
      "[27500]\ttraining's l1: 0.165422\tvalid_1's l1: 0.221342\n",
      "[28000]\ttraining's l1: 0.164798\tvalid_1's l1: 0.221316\n",
      "[28500]\ttraining's l1: 0.164151\tvalid_1's l1: 0.221255\n",
      "[29000]\ttraining's l1: 0.1635\tvalid_1's l1: 0.221184\n",
      "[29500]\ttraining's l1: 0.162893\tvalid_1's l1: 0.221135\n",
      "[30000]\ttraining's l1: 0.162267\tvalid_1's l1: 0.221066\n",
      "[30500]\ttraining's l1: 0.161666\tvalid_1's l1: 0.22102\n",
      "[31000]\ttraining's l1: 0.161074\tvalid_1's l1: 0.22098\n",
      "[31500]\ttraining's l1: 0.160462\tvalid_1's l1: 0.22092\n",
      "[32000]\ttraining's l1: 0.159888\tvalid_1's l1: 0.220878\n",
      "[32500]\ttraining's l1: 0.159277\tvalid_1's l1: 0.220781\n",
      "[33000]\ttraining's l1: 0.15866\tvalid_1's l1: 0.220707\n",
      "[33500]\ttraining's l1: 0.158054\tvalid_1's l1: 0.220629\n",
      "[34000]\ttraining's l1: 0.157509\tvalid_1's l1: 0.220604\n",
      "[34500]\ttraining's l1: 0.156962\tvalid_1's l1: 0.22057\n",
      "[35000]\ttraining's l1: 0.156334\tvalid_1's l1: 0.220444\n",
      "[35500]\ttraining's l1: 0.155751\tvalid_1's l1: 0.220374\n",
      "[36000]\ttraining's l1: 0.155154\tvalid_1's l1: 0.220293\n",
      "[36500]\ttraining's l1: 0.154588\tvalid_1's l1: 0.220219\n",
      "[37000]\ttraining's l1: 0.154028\tvalid_1's l1: 0.220165\n",
      "[37500]\ttraining's l1: 0.153483\tvalid_1's l1: 0.220127\n",
      "[38000]\ttraining's l1: 0.152932\tvalid_1's l1: 0.220083\n",
      "[38500]\ttraining's l1: 0.152411\tvalid_1's l1: 0.220048\n",
      "[39000]\ttraining's l1: 0.151921\tvalid_1's l1: 0.220024\n",
      "[39500]\ttraining's l1: 0.151412\tvalid_1's l1: 0.21998\n",
      "[40000]\ttraining's l1: 0.150898\tvalid_1's l1: 0.219929\n",
      "[40500]\ttraining's l1: 0.150379\tvalid_1's l1: 0.219868\n",
      "[41000]\ttraining's l1: 0.149861\tvalid_1's l1: 0.219817\n",
      "[41500]\ttraining's l1: 0.149356\tvalid_1's l1: 0.219755\n",
      "[42000]\ttraining's l1: 0.148874\tvalid_1's l1: 0.219715\n",
      "[42500]\ttraining's l1: 0.148384\tvalid_1's l1: 0.219672\n",
      "[43000]\ttraining's l1: 0.147877\tvalid_1's l1: 0.219616\n",
      "[43500]\ttraining's l1: 0.147399\tvalid_1's l1: 0.219566\n",
      "[44000]\ttraining's l1: 0.146935\tvalid_1's l1: 0.219534\n",
      "[44500]\ttraining's l1: 0.146469\tvalid_1's l1: 0.219517\n",
      "[45000]\ttraining's l1: 0.146012\tvalid_1's l1: 0.219488\n",
      "[45500]\ttraining's l1: 0.145573\tvalid_1's l1: 0.219458\n",
      "[46000]\ttraining's l1: 0.145129\tvalid_1's l1: 0.219428\n",
      "[46500]\ttraining's l1: 0.144681\tvalid_1's l1: 0.219394\n",
      "[47000]\ttraining's l1: 0.144229\tvalid_1's l1: 0.219374\n",
      "[47500]\ttraining's l1: 0.143789\tvalid_1's l1: 0.219362\n",
      "[48000]\ttraining's l1: 0.143329\tvalid_1's l1: 0.219325\n",
      "[48500]\ttraining's l1: 0.142848\tvalid_1's l1: 0.219275\n",
      "[49000]\ttraining's l1: 0.1424\tvalid_1's l1: 0.219238\n",
      "[49500]\ttraining's l1: 0.141971\tvalid_1's l1: 0.219214\n",
      "[50000]\ttraining's l1: 0.141542\tvalid_1's l1: 0.219188\n",
      "[50500]\ttraining's l1: 0.141113\tvalid_1's l1: 0.219162\n",
      "[51000]\ttraining's l1: 0.140686\tvalid_1's l1: 0.219135\n",
      "[51500]\ttraining's l1: 0.140251\tvalid_1's l1: 0.219102\n",
      "[52000]\ttraining's l1: 0.139832\tvalid_1's l1: 0.219082\n",
      "[52500]\ttraining's l1: 0.139425\tvalid_1's l1: 0.219067\n",
      "[53000]\ttraining's l1: 0.13902\tvalid_1's l1: 0.219063\n",
      "[53500]\ttraining's l1: 0.138617\tvalid_1's l1: 0.219049\n",
      "[54000]\ttraining's l1: 0.138194\tvalid_1's l1: 0.219032\n",
      "[54500]\ttraining's l1: 0.137796\tvalid_1's l1: 0.219006\n",
      "[55000]\ttraining's l1: 0.137375\tvalid_1's l1: 0.218988\n",
      "[55500]\ttraining's l1: 0.136948\tvalid_1's l1: 0.218953\n",
      "[56000]\ttraining's l1: 0.136564\tvalid_1's l1: 0.218929\n",
      "[56500]\ttraining's l1: 0.13617\tvalid_1's l1: 0.218888\n",
      "[57000]\ttraining's l1: 0.135774\tvalid_1's l1: 0.218876\n",
      "[57500]\ttraining's l1: 0.135375\tvalid_1's l1: 0.218843\n",
      "[58000]\ttraining's l1: 0.135\tvalid_1's l1: 0.218818\n",
      "[58500]\ttraining's l1: 0.134634\tvalid_1's l1: 0.218789\n",
      "[59000]\ttraining's l1: 0.134259\tvalid_1's l1: 0.218764\n",
      "[59500]\ttraining's l1: 0.133842\tvalid_1's l1: 0.218726\n",
      "[60000]\ttraining's l1: 0.133455\tvalid_1's l1: 0.218698\n",
      "[60500]\ttraining's l1: 0.133081\tvalid_1's l1: 0.218681\n",
      "[61000]\ttraining's l1: 0.132717\tvalid_1's l1: 0.218665\n",
      "[61500]\ttraining's l1: 0.132342\tvalid_1's l1: 0.218636\n",
      "[62000]\ttraining's l1: 0.131974\tvalid_1's l1: 0.2186\n",
      "[62500]\ttraining's l1: 0.13164\tvalid_1's l1: 0.218588\n",
      "[63000]\ttraining's l1: 0.131301\tvalid_1's l1: 0.21858\n",
      "[63500]\ttraining's l1: 0.130964\tvalid_1's l1: 0.218572\n",
      "[64000]\ttraining's l1: 0.13061\tvalid_1's l1: 0.218557\n",
      "[64500]\ttraining's l1: 0.130265\tvalid_1's l1: 0.218537\n",
      "[65000]\ttraining's l1: 0.129925\tvalid_1's l1: 0.218518\n",
      "[65500]\ttraining's l1: 0.12958\tvalid_1's l1: 0.218501\n",
      "[66000]\ttraining's l1: 0.129237\tvalid_1's l1: 0.218485\n",
      "[66500]\ttraining's l1: 0.128897\tvalid_1's l1: 0.218473\n",
      "[67000]\ttraining's l1: 0.128561\tvalid_1's l1: 0.218455\n",
      "[67500]\ttraining's l1: 0.128239\tvalid_1's l1: 0.218447\n",
      "[68000]\ttraining's l1: 0.127919\tvalid_1's l1: 0.218435\n",
      "[68500]\ttraining's l1: 0.12757\tvalid_1's l1: 0.218419\n",
      "[69000]\ttraining's l1: 0.127219\tvalid_1's l1: 0.218388\n",
      "[69500]\ttraining's l1: 0.126887\tvalid_1's l1: 0.218369\n",
      "[70000]\ttraining's l1: 0.12656\tvalid_1's l1: 0.218362\n",
      "[70500]\ttraining's l1: 0.126227\tvalid_1's l1: 0.218348\n",
      "[71000]\ttraining's l1: 0.1259\tvalid_1's l1: 0.218343\n",
      "[71500]\ttraining's l1: 0.125575\tvalid_1's l1: 0.218329\n",
      "[72000]\ttraining's l1: 0.125263\tvalid_1's l1: 0.218317\n",
      "[72500]\ttraining's l1: 0.124924\tvalid_1's l1: 0.218292\n",
      "[73000]\ttraining's l1: 0.124618\tvalid_1's l1: 0.218283\n",
      "[73500]\ttraining's l1: 0.12431\tvalid_1's l1: 0.218268\n",
      "[74000]\ttraining's l1: 0.124002\tvalid_1's l1: 0.218248\n",
      "[74500]\ttraining's l1: 0.123676\tvalid_1's l1: 0.218225\n",
      "[75000]\ttraining's l1: 0.123362\tvalid_1's l1: 0.218201\n",
      "[75500]\ttraining's l1: 0.123047\tvalid_1's l1: 0.218174\n",
      "[76000]\ttraining's l1: 0.122729\tvalid_1's l1: 0.218161\n",
      "[76500]\ttraining's l1: 0.122429\tvalid_1's l1: 0.21816\n",
      "[77000]\ttraining's l1: 0.122129\tvalid_1's l1: 0.218147\n",
      "[77500]\ttraining's l1: 0.121822\tvalid_1's l1: 0.218134\n",
      "[78000]\ttraining's l1: 0.121525\tvalid_1's l1: 0.218123\n",
      "[78500]\ttraining's l1: 0.121209\tvalid_1's l1: 0.218114\n",
      "[79000]\ttraining's l1: 0.120903\tvalid_1's l1: 0.21811\n",
      "[79500]\ttraining's l1: 0.120613\tvalid_1's l1: 0.218103\n",
      "[80000]\ttraining's l1: 0.120326\tvalid_1's l1: 0.218093\n",
      "[80500]\ttraining's l1: 0.120042\tvalid_1's l1: 0.218082\n",
      "[81000]\ttraining's l1: 0.119744\tvalid_1's l1: 0.218075\n",
      "[81500]\ttraining's l1: 0.11945\tvalid_1's l1: 0.218065\n",
      "[82000]\ttraining's l1: 0.119155\tvalid_1's l1: 0.218057\n",
      "[82500]\ttraining's l1: 0.118879\tvalid_1's l1: 0.218046\n",
      "[83000]\ttraining's l1: 0.118588\tvalid_1's l1: 0.218035\n",
      "[83500]\ttraining's l1: 0.118315\tvalid_1's l1: 0.218028\n",
      "[84000]\ttraining's l1: 0.118036\tvalid_1's l1: 0.218026\n",
      "0.21802316980629582\n",
      "OOF score is 0.21539047265501782\n"
     ]
    }
   ],
   "source": [
    "# def add_dt_features(train: pl.DataFrame):\n",
    "#     \"\"\"dt秒後の特徴\"\"\"\n",
    "#     train = train.with_columns(\n",
    "#         # vt\n",
    "#         (pl.col(\"vEgo\") * pl.col(\"dt\").cast(pl.Float32)).alias(\"linear_movement@dt\"),\n",
    "#         # vt + 0.5at^2\n",
    "#         ((pl.col(\"vEgo\") + 0.5 * pl.col(\"aEgo\") * pl.col(\"dt\").cast(pl.Float32) ** 2).alias(\"movement@dt\")),\n",
    "#         # v + at\n",
    "#         (pl.col(\"vEgo\") + pl.col(\"aEgo\") * pl.col(\"dt\").cast(pl.Float32)).alias(\"velocity@dt\"),\n",
    "#     )\n",
    "#     return train\n",
    "\n",
    "\n",
    "# # dt features\n",
    "# dt = float(target.split(\"_\")[-1]) * 0.5 + 0.5\n",
    "# train_df = train_df.with_columns(pl.lit(dt).alias(\"dt\"))\n",
    "# test_df = test_df.with_columns(pl.lit(dt).alias(\"dt\"))\n",
    "# train_df = add_dt_features(train_df)\n",
    "# test_df = add_dt_features(test_df)\n",
    "# features = list(set(features) | set([\"linear_movement@dt\", \"movement@dt\", \"velocity@dt\"]))\n",
    "\n",
    "oof_preds_partial, y_pred_partial, models_partial = train_lgbm(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred = oof_preds_partial.reshape(18, -1).T\n",
    "test_pred = y_pred_partial.reshape(18, -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21539047265501785"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(train_df[targets].to_numpy(), np.vstack(oof_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:54<00:00, 18.18it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(7, 3))\n",
    "public_maes = []\n",
    "private_maes = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    random_idx = np.random.choice(range(len(oof_pred)), 500)\n",
    "    public_maes.append(evaluation(train_df[targets].to_numpy()[random_idx], np.vstack(oof_pred)[random_idx]))\n",
    "\n",
    "    random_idx = np.random.choice(range(len(oof_pred)), 1200)\n",
    "    private_maes.append(evaluation(train_df[targets].to_numpy()[random_idx], np.vstack(oof_pred)[random_idx]))\n",
    "axs[0].hist(public_maes, bins=np.linspace(0.20, 0.23, 20))\n",
    "axs[0].grid()\n",
    "axs[0].set_title(\"public\")\n",
    "\n",
    "axs[1].hist(private_maes, bins=np.linspace(0.20, 0.23, 20))\n",
    "axs[1].grid()\n",
    "axs[1].set_title(\"private\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit ファイル作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_727, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th><th>ID</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>1.4574</td><td>-0.079014</td><td>-0.032647</td><td>3.071899</td><td>-0.137671</td><td>-0.032889</td><td>4.524695</td><td>-0.181302</td><td>-0.050281</td><td>5.886816</td><td>-0.18872</td><td>-0.067151</td><td>7.15981</td><td>-0.319218</td><td>-0.046156</td><td>8.374101</td><td>-0.456937</td><td>-0.03019</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>0.949536</td><td>0.40581</td><td>0.06588</td><td>1.904321</td><td>1.010808</td><td>0.076189</td><td>2.65619</td><td>1.756382</td><td>0.078897</td><td>3.272162</td><td>2.550617</td><td>0.086895</td><td>3.67508</td><td>3.482885</td><td>0.105149</td><td>4.162672</td><td>4.442993</td><td>0.113294</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>1.625899</td><td>0.048176</td><td>0.020384</td><td>3.302721</td><td>0.076652</td><td>0.017574</td><td>4.838215</td><td>0.100614</td><td>0.005851</td><td>6.444947</td><td>0.076797</td><td>0.000201</td><td>7.859782</td><td>0.100696</td><td>0.000866</td><td>9.210332</td><td>0.132605</td><td>0.005004</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>0.833911</td><td>0.120808</td><td>0.026599</td><td>1.693729</td><td>0.34621</td><td>0.025359</td><td>2.543839</td><td>0.566324</td><td>0.007868</td><td>3.151052</td><td>0.951239</td><td>-0.012863</td><td>3.802002</td><td>1.468163</td><td>-0.043749</td><td>4.416948</td><td>2.285877</td><td>-0.083978</td><td>&quot;012baccc145d400c896cb82065a93d…</td></tr><tr><td>0.811287</td><td>-0.034538</td><td>-0.057028</td><td>1.446939</td><td>-0.050585</td><td>-0.071612</td><td>1.838146</td><td>-0.042985</td><td>-0.083291</td><td>1.982069</td><td>-0.032198</td><td>-0.090126</td><td>1.65992</td><td>-0.051194</td><td>-0.103227</td><td>1.144788</td><td>-0.050607</td><td>-0.112473</td><td>&quot;01d738e799d260a10f6324f78023b3…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6.545174</td><td>0.034973</td><td>0.018795</td><td>13.799386</td><td>0.090381</td><td>0.028749</td><td>21.052995</td><td>0.159874</td><td>0.034772</td><td>28.22664</td><td>0.25767</td><td>0.052277</td><td>35.57229</td><td>0.361826</td><td>0.057327</td><td>42.984538</td><td>0.540827</td><td>0.070431</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>6.916087</td><td>-0.07006</td><td>-0.062843</td><td>14.798537</td><td>-0.105103</td><td>-0.06679</td><td>22.761678</td><td>-0.166527</td><td>-0.104159</td><td>30.799746</td><td>-0.204345</td><td>-0.194008</td><td>39.03662</td><td>-0.292833</td><td>-0.324984</td><td>47.11961</td><td>-0.444525</td><td>-0.519515</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>7.393678</td><td>-0.060088</td><td>-0.039158</td><td>15.63527</td><td>-0.073403</td><td>-0.026429</td><td>23.770483</td><td>-0.111459</td><td>0.012047</td><td>31.815545</td><td>-0.15291</td><td>0.063158</td><td>39.772715</td><td>-0.167981</td><td>0.129529</td><td>47.725898</td><td>-0.189908</td><td>0.202011</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>6.603924</td><td>0.150402</td><td>0.166895</td><td>13.765165</td><td>0.15879</td><td>0.184314</td><td>20.849713</td><td>0.146678</td><td>0.246161</td><td>27.826103</td><td>0.186255</td><td>0.395003</td><td>34.928298</td><td>0.248471</td><td>0.633504</td><td>41.890822</td><td>0.474701</td><td>0.901962</td><td>&quot;ff4f00a76fbf4db0cb15579c7c6086…</td></tr><tr><td>5.725908</td><td>-0.318253</td><td>-0.06578</td><td>12.209723</td><td>-1.079999</td><td>-0.073779</td><td>18.86135</td><td>-2.386975</td><td>-0.103237</td><td>25.459847</td><td>-4.359704</td><td>-0.100876</td><td>31.932595</td><td>-6.912414</td><td>-0.09735</td><td>38.181623</td><td>-9.770046</td><td>-0.092238</td><td>&quot;ffc9272ee663f281a5f0ac533e97a1…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_727, 19)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ x_0      ┆ y_0       ┆ z_0       ┆ x_1       ┆ … ┆ x_5       ┆ y_5       ┆ z_5       ┆ ID        │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ str       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.4574   ┆ -0.079014 ┆ -0.032647 ┆ 3.071899  ┆ … ┆ 8.374101  ┆ -0.456937 ┆ -0.03019  ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 0.949536 ┆ 0.40581   ┆ 0.06588   ┆ 1.904321  ┆ … ┆ 4.162672  ┆ 4.442993  ┆ 0.113294  ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 1.625899 ┆ 0.048176  ┆ 0.020384  ┆ 3.302721  ┆ … ┆ 9.210332  ┆ 0.132605  ┆ 0.005004  ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 0.833911 ┆ 0.120808  ┆ 0.026599  ┆ 1.693729  ┆ … ┆ 4.416948  ┆ 2.285877  ┆ -0.083978 ┆ 012baccc1 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 45d400c89 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6cb82065a │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 93d…      │\n",
       "│ 0.811287 ┆ -0.034538 ┆ -0.057028 ┆ 1.446939  ┆ … ┆ 1.144788  ┆ -0.050607 ┆ -0.112473 ┆ 01d738e79 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 9d260a10f │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 6324f7802 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 3b3…      │\n",
       "│ …        ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 6.545174 ┆ 0.034973  ┆ 0.018795  ┆ 13.799386 ┆ … ┆ 42.984538 ┆ 0.540827  ┆ 0.070431  ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 6.916087 ┆ -0.07006  ┆ -0.062843 ┆ 14.798537 ┆ … ┆ 47.11961  ┆ -0.444525 ┆ -0.519515 ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 7.393678 ┆ -0.060088 ┆ -0.039158 ┆ 15.63527  ┆ … ┆ 47.725898 ┆ -0.189908 ┆ 0.202011  ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 6.603924 ┆ 0.150402  ┆ 0.166895  ┆ 13.765165 ┆ … ┆ 41.890822 ┆ 0.474701  ┆ 0.901962  ┆ ff4f00a76 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ fbf4db0cb │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 15579c7c6 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 086…      │\n",
       "│ 5.725908 ┆ -0.318253 ┆ -0.06578  ┆ 12.209723 ┆ … ┆ 38.181623 ┆ -9.770046 ┆ -0.092238 ┆ ffc9272ee │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 663f281a5 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f0ac533e9 │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7a1…      │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_col_names = [\n",
    "    \"x_0\",\n",
    "    \"y_0\",\n",
    "    \"z_0\",\n",
    "    \"x_1\",\n",
    "    \"y_1\",\n",
    "    \"z_1\",\n",
    "    \"x_2\",\n",
    "    \"y_2\",\n",
    "    \"z_2\",\n",
    "    \"x_3\",\n",
    "    \"y_3\",\n",
    "    \"z_3\",\n",
    "    \"x_4\",\n",
    "    \"y_4\",\n",
    "    \"z_4\",\n",
    "    \"x_5\",\n",
    "    \"y_5\",\n",
    "    \"z_5\",\n",
    "]\n",
    "sub_df = pl.DataFrame(np.vstack(test_pred), schema=sub_col_names)\n",
    "sub_df = sub_df.with_columns(pl.Series(\"ID\", test_df[\"ID\"]))\n",
    "sub_df.write_csv(os.path.join(CFG[\"output_dir\"], \"submission.csv\"))\n",
    "\n",
    "oof_df = pl.DataFrame(np.vstack(oof_pred), schema=sub_col_names)\n",
    "oof_df = oof_df.with_columns(pl.Series(\"ID\", train_df[\"ID\"]))\n",
    "oof_df.write_csv(os.path.join(CFG[\"output_dir\"], \"oof.csv\"))\n",
    "\n",
    "display(sub_df)\n",
    "sub_df.drop(\"ID\").write_csv(os.path.join(CFG[\"output_dir\"], \"submission_wo_ID.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
